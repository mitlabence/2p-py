{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ea0b7d",
   "metadata": {},
   "source": [
    "# Pure Python Pipeline\n",
    "Ripple noise removal, motion correction, trace deconvoloution and extraction in one notebook. This should replace demo_pipeline as the standard analysis notebook! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa2fc9",
   "metadata": {},
   "source": [
    "## TODO list (from demo_pipeline)\n",
    "- TODO: hdf5_to_numpy as reverse of numpy_to_hdf5 (RNR export step)\n",
    "- TODO: check demo_motion_correction.ipynb for evaluation of motion correction\n",
    "- TODO: appropriate file variable names (fname_new ... are NOT appropriate).\n",
    "- TODO: save file names should be more meaningful, for easier cleanup.\n",
    "- TODO: rnr save file: should have rnr in the hdf5 file name, otherwise too confusing!\n",
    "- TODO: create a small txt file with the file names and their purpose (whether they can be deleted, how to use them, what do they contain) at some point (early) in the analysis, save it in export folder.\n",
    "- TODO: cnm.estimates.idx_components and idx_components_bad are removed at one step. Instead, there is cnm.estimates.discarded_components. Do we need manual accept/reject?\n",
    "- FIXME: _pars.json and _results.hdf5 contain nd2 file name twice: T301_tmev_d1T301_tmev_d1.270820.1110_22-10-20_14-18-40_pars.json and T301_tmev_d1T301_tmev_d1.270820.1110_22-10-20_14-18-40_results.hdf5\n",
    "- IMPORTANT: make it more convenient to enter pipeline from any point. This includes defining parameters in one location, naming variables appropriately (F memmap, C memmap, nd2 file, hd5 file...) so user is aware which file they are supposed to open at which point of entry into analysis!\n",
    "- memmap_ results in conflicting names if recordings are from same day. Include date time of analysis in name? Not a big problem as it is temporary file\n",
    "- Study parallel processing of caiman (start server step, cleaning up server). It might be useful for RNR too.\n",
    "- Evaluating components: cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview), the contents of model/ in CaImAn are used but looking for the model files in another directory (in my case, Users/Bence/caiman_data/model/)\n",
    "- Export h5 file should have date time in filename to avoid overwriting. Both raw data and final results!\n",
    "- Plot with slider: watch all the frames, compare RNR and original, then MC and original/RNR... QC\n",
    "- Save RNR directly to memmap (opening as caiman movie, save to memmap?)? Although the problem is how slow RNR is...\n",
    "- Maybe working with numpy array in motion correction (movie.motion_correct) is not that bad? Although no parameters...\n",
    "- Plot frame before RNR and after RNR to set parameters... Interactive?\n",
    "- Read Tips on analysis: https://caiman.readthedocs.io/en/master/CaImAn_Tips.html#motion-correction-tips\n",
    "- RNR results in 4x size (uint16 to float64)! Need to clean up or use uint16 again.\n",
    "- Check 2-channel recordings. Might want to save red channel, too, for matching?\n",
    "- Save memmap files is inconsistent in naming (C order is memmap__d1_512_d2_512_d3_1_order_C_frames_577_ instead of T386_20211202_green_ex_els__d1_512_d2_512_d3_1_order_C_frames_577_)\n",
    "- Include nd2 to h5 here (from nd2 to multipage tiff test.ipynb)\n",
    "- It takes a lot of time to open nd2 file. Useful to copy data to be analyzed to local HDD on a previous day?\n",
    "- way to manually reject/accept components\n",
    "- IMPORTANT: https://caiman.readthedocs.io/en/master/On_file_types_and_sizes.html caiman works best when files are 1-2 GB big! It means we might want to split them in small pieces, or make sure they are multi-page tiff files!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd663b68",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace0a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df788f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n",
       "  const css_urls = [];\n",
       "  \n",
       "\n",
       "  const inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n  const css_urls = [];\n  \n\n  const inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from RippleNoiseRemoval import RNR\n",
    "import labrotation.file_handling as fh\n",
    "import h5py\n",
    "from time import time\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "import cv2\n",
    "import glob\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "\n",
    "from movie_splitting import numpy_to_hdf5\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd274d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving log file to\n",
      "D:\\Presentation\\mocofail\\caim_log_22-12-06_00-07-19.txt\n"
     ]
    }
   ],
   "source": [
    "log_fname = fh.choose_dir_for_saving_file(\"Select folder to save log file\", fh.get_filename_with_date(\"caim_log\", \".txt\"))\n",
    "print(f\"Saving log file to\\n{log_fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87dc936",
   "metadata": {},
   "source": [
    "\n",
    "## Set up logging (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1836eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\\\n",
    "                    filename=log_fname,\n",
    "                    level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add761f",
   "metadata": {},
   "source": [
    "## Set input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dee969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file selected: Y:\\AG-Wenzel\\Group\\tmev\\T333\\T333_tmev_d2\\T333_tmev_d2_21102020_FOV_005.nd2\n"
     ]
    }
   ],
   "source": [
    "nd2_fpath = fh.open_file(\"Select nd2 file\") #\"D:/PhD/Data/T386_MatlabTest/T386_20211202_green.nd2\"\n",
    "print(f\"Input file selected: {nd2_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbdd89f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export file selected: D:\\Presentation\\mocofail\\T333_tmev_d2_21102020_FOV_005_rnr__22-12-06_00-07-50.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save in same folder as nd2 file\n",
    "export_folder = fh.open_dir(\"Select folder to save results\", True)\n",
    "# export_fname: get rid of .nd2 extension, append date and .h5 extension\n",
    "export_fname = fh.get_filename_with_date(os.path.splitext(os.path.split(nd2_fpath)[1])[0] + \"_rnr_\", \".hdf5\")\n",
    "export_hd5_fpath = os.path.join(export_folder, export_fname) # nd2_fpath.split(\"/\")[-1][:-4] + \"_exp.h5\"\n",
    "print(f\"Export file selected: {export_hd5_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9af84",
   "metadata": {},
   "source": [
    "## Ripple Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c992111",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 40\n",
    "amplitude_threshold = 10.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13631d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnr = RNR(win, amplitude_threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41056913",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_end_frames = [10287,10972]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf57982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bence\\anaconda3\\envs\\2p-py\\lib\\site-packages\\pims\\base_frames.py:472: UserWarning: Please call FramesSequenceND.__init__() at the start of thethe reader initialization.\n",
      "  warn(\"Please call FramesSequenceND.__init__() at the start of the\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened recording 512x512, 686 frames. Initialized empty results array.\n",
      "File opened in 96.94191336631775 s\n"
     ]
    }
   ],
   "source": [
    "#begin_end_frames = None  # (begin, end): if want to work with part of the file\n",
    "t0_open = time()\n",
    "rnr.open_recording(nd2_fpath, begin_end_frames)  # opens usual recording size (8.8-9 GB) in about 830 s\n",
    "print(f\"File opened in {time() - t0_open} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d186c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Codebase\\2p-py\\RippleNoiseRemoval.py:45: RuntimeWarning: divide by zero encountered in log\n",
      "  ampl_image = np.log(np.abs(freq_image))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNR completed.\n",
      "RNR single thread finished in 18.964435577392578 s\n",
      "Result is a <class 'numpy.ndarray'> with datatype float64\n",
      "Shape: 686 frames of 512x512 pixels\n"
     ]
    }
   ],
   "source": [
    "t0_single = time()\n",
    "rnr_data = rnr.rnr_singlethread()  # a bit faster than opening file, around 500s for 8.8-9 GB\n",
    "t1_single = time()\n",
    "print(f\"RNR single thread finished in {t1_single - t0_single} s\")\n",
    "print(f\"Result is a {type(rnr_data)} with datatype {rnr_data.dtype}\")\n",
    "print(f\"Shape: {rnr_data.shape[0]} frames of {rnr_data.shape[1]}x{rnr_data.shape[2]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c54b85",
   "metadata": {},
   "source": [
    "### Export RNR movie to hd5 file.\n",
    "The reason to this otherwise unnecessary step is that motion correction cannot work from numpy array... Or at least the movie.motion_correct() does not have many options. See https://caiman.readthedocs.io/en/master/core_functions.html#movie-handling motion_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2118f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy_to_hdf5: Single output filename detected.\n",
      "numpy_to_hdf5: No splitting will be performed.\n",
      "Creating 1 file(s):\n",
      "\tD:\\Presentation\\mocofail\\T333_tmev_d2_21102020_FOV_005_rnr__22-12-06_00-07-50.hdf5\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['D:\\\\Presentation\\\\mocofail\\\\T333_tmev_d2_21102020_FOV_005_rnr__22-12-06_00-07-50.hdf5']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_to_hdf5(rnr_data, export_hd5_fpath)\n",
    "#dataset_name = \"mov\"  # var_name_hdf5 in various functions refers to this name! Default is always mov.\n",
    "#with h5py.File(export_hd5_fpath, 'w') as hf:\n",
    "#    dataset = hf.create_dataset(dataset_name, shape=rnr_data.shape, dtype=np.float64)  # TODO: float64 is much larger file!\n",
    "#    for i_frame in range(rnr_data.shape[0]):\n",
    "#        dataset[i_frame] = rnr_data[i_frame]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35566572",
   "metadata": {},
   "source": [
    "## Motion Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c82e8",
   "metadata": {},
   "source": [
    "### Optional: split up video into segments to process and skip\n",
    "Important: the numbering should correspond to the nd2 indexing, i.e. from 1 to n_frames! No zero-indexing here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3920b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames_begin_end = [(1,109),(110,135),(136,448),(449,499), (500, 577)]\n",
    "#flag_moco = [True, False, True, False, True]\n",
    "# t333 tmev d2 fiv 005\n",
    "#frames_begin_end = [(1, 9862), (9863,9908), (9909, 10085), (10086, 10115), (10115, 10241), (10242, 10276), (10277, 10290), (10291, 10551), (10552, 10620), (10621, 11748), (11749, 17628)]\n",
    "#flag_moco = [True, False, True, False, True, False, True, False, True, False, True]\n",
    "# TODO: check here for consistency of these variables!\n",
    "# (9800, 12200)\n",
    "#frames_begin_end = [(1, 491), (492, 752), (753, 821), (822, 1949), (1950, 2400)]\n",
    "#flag_moco = [True, False, True, False, True]\n",
    "frames_begin_end = [(1, )]\n",
    "flag_moco = [True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f63cd",
   "metadata": {},
   "source": [
    "### Set output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0d75572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to perform MoCo on ['D:\\\\Presentation\\\\mocofail\\\\T333_tmev_d2_21102020_FOV_005_rnr__22-12-06_00-07-50.hdf5']\n"
     ]
    }
   ],
   "source": [
    "if not(\"export_hd5_fpath\" in locals()):\n",
    "    export_hd5_fpath = fh.open_file(\"Choose hd5 file to open\")\n",
    "if export_hd5_fpath.split(\".\")[-1] != \"hdf5\":\n",
    "    print(f\"Invalid hd5 file:\\n{export_hd5_fpath}\\nChoose a valid hd5 file!\")\n",
    "    export_hd5_fpath = fh.open_file(\"Choose hd5 file to open\")\n",
    "fnames = [export_hd5_fpath]\n",
    "print(f\"Going to perform MoCo on {fnames}\")\n",
    "assert export_hd5_fpath.split(\".\")[-1] == \"hdf5\", f\"Invalid file extension: .{export_hd5_fpath.split('.')[-1]}, expected .hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9809c7f",
   "metadata": {},
   "source": [
    "### Optional: Play the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ae6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_movie = False\n",
    "if display_movie:\n",
    "    ds_ratio = 0.2\n",
    "    movie.resize(1, 1, ds_ratio).play(\n",
    "        q_max=99.5, fr=30, magnification=2)  # this should not change size of movie itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11be371",
   "metadata": {},
   "source": [
    "### Setup some parameters\n",
    "We set some parameters that are relevant to the file, and then parameters for motion correction, processing with CNMF and component quality evaluation. Note that the dataset `Sue_2x_3000_40_-46.tif` has been spatially downsampled by a factor of 2 and has a lower than usual spatial resolution (2um/pixel). As a result several parameters (`gSig, strides, max_shifts, rf, stride_cnmf`) have lower values (halved compared to a dataset with spatial resolution 1um/pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b80c0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = 15                             # imaging rate in frames per second\n",
    "decay_time = 0.4                    # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)         # overlap between pathes (size of patch strides+overlaps)\n",
    "max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels)\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # order of the autoregressive system\n",
    "gnb = 2                     # number of global background components\n",
    "merge_thr = 0.85            # merging threshold, max correlation allowed\n",
    "rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "K = 4                       # number of components per patch\n",
    "gSig = [4, 4]               # expected half size of neurons in pixels\n",
    "method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18361e",
   "metadata": {},
   "source": [
    "### Create a parameters object\n",
    "You can creating a parameters object by passing all the parameters as a single dictionary. Parameters not defined in the dictionary will assume their default values. The resulting `params` object is a collection of subdictionaries pertaining to the dataset to be analyzed `(params.data)`, motion correction `(params.motion)`, data pre-processing `(params.preprocess)`, initialization `(params.init)`, patch processing `(params.patch)`, spatial and temporal component `(params.spatial), (params.temporal)`, quality evaluation `(params.quality)` and online processing `(params.online)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ce0cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fnames\" not in locals():\n",
    "    fnames = fh.open_file(\"No hd5 file selected. Choose corresponding hd5 file!\")\n",
    "opts_dict = {'fnames': fnames, \n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest,\n",
    "            'var_name_hdf5': 'data',}  # FIXME: does not work! Check where does this setting get lost?\n",
    "\n",
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7deefe1",
   "metadata": {},
   "source": [
    "### Setup a cluster\n",
    "To enable parallel processing a (local) cluster needs to be set up. This is done with a cell below. The variable `backend` determines the type of cluster used. The default value `'local'` uses the multiprocessing package. The `ipyparallel` option is also available. More information on these choices can be found [here](https://github.com/flatironinstitute/CaImAn/blob/master/CLUSTER.md). The resulting variable `dview` expresses the cluster option. If you use `dview=dview` in the downstream analysis then parallel processing will be used. If you use `dview=None` then no parallel processing will be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d971b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fce27b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c63bec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nArgs:\\n            max_shift_w,max_shift_h: maximum pixel shifts allowed when correcting\\n                                     in the width and height direction\\n\\n            template: if a good template for frame by frame correlation exists\\n                      it can be passed. If None it is automatically computed\\n\\n            method: depends on what is installed 'opencv' or 'skimage'. 'skimage'\\n                    is an order of magnitude slower\\n\\n            num_frames_template: if only a subset of the movies needs to be loaded\\n                                 for efficiency/speed reasons\\n                                 \\nmax_shift_w=5,\\nmax_shift_h=5,\\nnum_frames_template=None,\\ntemplate=None,\\nmethod: str = 'opencv',\\nremove_blanks: bool = False,\\ninterpolation: str = 'cubic'\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALTERNATIVE to exporting h5 and importing it again!\n",
    "\"\"\"\n",
    "Args:\n",
    "            max_shift_w,max_shift_h: maximum pixel shifts allowed when correcting\n",
    "                                     in the width and height direction\n",
    "\n",
    "            template: if a good template for frame by frame correlation exists\n",
    "                      it can be passed. If None it is automatically computed\n",
    "\n",
    "            method: depends on what is installed 'opencv' or 'skimage'. 'skimage'\n",
    "                    is an order of magnitude slower\n",
    "\n",
    "            num_frames_template: if only a subset of the movies needs to be loaded\n",
    "                                 for efficiency/speed reasons\n",
    "                                 \n",
    "max_shift_w=5,\n",
    "max_shift_h=5,\n",
    "num_frames_template=None,\n",
    "template=None,\n",
    "method: str = 'opencv',\n",
    "remove_blanks: bool = False,\n",
    "interpolation: str = 'cubic'\n",
    "\"\"\"\n",
    "\n",
    "# movie.motion_correct()   # this might change movie itself! Alternative: extract_shifts, apply_shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ab322",
   "metadata": {},
   "source": [
    "### Perform motion correction and save as C-order memmap\n",
    "The filename is mc.fname_tot_els"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b3419d",
   "metadata": {},
   "source": [
    "## Perform MoCo on whole movie first, do not save the results yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41f48163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<caiman.motion_correction.MotionCorrect at 0x1c709dfd610>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%capture\n",
    "#%% Run piecewise-rigid motion correction using NoRMCorre\n",
    "mc.motion_correct(save_movie=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cec4f0",
   "metadata": {},
   "source": [
    "## Drop calculated shift values for frames where MoCo should not be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1bd7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d997a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shifts_els = deepcopy(mc.x_shifts_els)\n",
    "y_shifts_els = deepcopy(mc.y_shifts_els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dff377c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = x_shifts_els[0].shape\n",
    "y_shape = y_shifts_els[0].shape\n",
    "for i_piece, frames_tuple in enumerate(frames_begin_end):\n",
    "    if not flag_moco[i_piece]:  # skip this piece = set shifts to zero\n",
    "         for i_frame in range(frames_tuple[0] -1 , frames_tuple[1]):  # include last frame as well\n",
    "            x_shifts_els[i_frame] = np.zeros(x_shape)\n",
    "            y_shifts_els[i_frame] = np.zeros(y_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa07eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.x_shifts_els = x_shifts_els\n",
    "mc.y_shifts_els = y_shifts_els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10f39cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing work folder to D:\\Presentation\\mocofail, this is where moco result will be saved\n"
     ]
    }
   ],
   "source": [
    "work_folder = os.path.split(fnames[0])[0]\n",
    "print(f\"Changing work folder to {work_folder}, this is where moco result will be saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af44e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(work_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3116d102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC_d1_512_d2_512_d3_1_order_F_frames_686_.mmap\n"
     ]
    }
   ],
   "source": [
    "# should save in C order because cm.load_memmap() takes C-memmap. However, as the opening and closing of memmap files is \n",
    "# so confusing, I decided to try to copy the original demo_pipeline jupyter notebook as closely as I can.\n",
    "exp_fname = mc.apply_shifts_movie(fnames, save_memmap=True,order=\"F\")\n",
    "print(exp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29a1cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_mmap = os.path.join(work_folder, exp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "116bf8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Bence\\AppData\\Local\\Temp\\ipykernel_1620\\1449429027.py:2: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  border_to_0 = 0 if mc.border_nan is 'copy' else mc.border_to_0  # FIXME: gives warning, should use \"==\" with literals\n"
     ]
    }
   ],
   "source": [
    "m_els = cm.load(mc_mmap)\n",
    "border_to_0 = 0 if mc.border_nan is 'copy' else mc.border_to_0  # FIXME: gives warning, should use \"==\" with literals\n",
    "    # maximum shift to be used for trimming against NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe6516",
   "metadata": {},
   "source": [
    "# Save tif file (Optional, for checking MoCo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beca8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: float64 causes 4x file size! (35-36 GB instead of 8-9 GB)\n",
    "m_els.save(os.path.join(work_folder, 'movie_mocofail2.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72ba3f",
   "metadata": {},
   "source": [
    "### Optional: show comparison with original movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475845b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compare with original movie\n",
    "display_movie = False  # TODO: does not seem to work. Create own function to show result?\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(fnames)\n",
    "    ds_ratio = 0.2\n",
    "    cm.concatenate([m_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie,\n",
    "                    m_els.resize(1, 1, ds_ratio)], \n",
    "                   axis=2).play(fr=60, gain=15, magnification=2, offset=0)  # press q to exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1fbd3f",
   "metadata": {},
   "source": [
    "## Save now as C memmap, apply border_to_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862369e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a very stupid step, basically save the results again (mc_mmap) but with border_to_0 param in addition\n",
    "moco_full_c_memmap = cm.save_memmap([mc_mmap], base_name='memmap', order='C',border_to_0=border_to_0, dview=dview) # exclude borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_full_c_memmap  # this is the split file that swe can handle just the same as fname_new in the original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ccce38",
   "metadata": {},
   "source": [
    "# Work with MoCo-exported C memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_new = moco_full_c_memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512badb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fname_new' not in locals():\n",
    "    fname_new = fh.open_file(\"Select C-memmap file.\")\n",
    "print(f\"Working with C-memmap\\n{fname_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10177b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "    #load frames in python format (T x X x Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb881c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = images[0].shape\n",
    "resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c804fa",
   "metadata": {},
   "source": [
    "### Create ndarray for concatenated \"moco\" segments\n",
    "i.e. parts of the video where moco was used. The other segments contain weird signal that hinder the moco and CNMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a929e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = 0\n",
    "len_concat = 0  # length of concatenated moco-segments video\n",
    "for i_segment, frames_tuple in enumerate(frames_begin_end):\n",
    "    len_segment = frames_tuple[1] - frames_tuple[0] + 1\n",
    "    if flag_moco[i_segment]:  # if moco was applied, add segment\n",
    "        len_concat += len_segment\n",
    "        \n",
    "    total_len += len_segment\n",
    "        \n",
    "len_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cccaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_split_memmap_fname = cm.paths.memmap_frames_filename(\"moco_split\", resolution, len_concat, \"C\")\n",
    "moco_split_memmap_fpath = os.path.join(work_folder, moco_split_memmap_fname)\n",
    "print(f\"Split-up moco C memmap for CNMF will be saved as\\n\\t{moco_split_memmap_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6402ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_concatenated = np.zeros(shape=(len_concat, resolution[0], resolution[1]), dtype=images.dtype)\n",
    "i_concat = 0  # index of frame in concatenated data\n",
    "for i_seq, sequence in enumerate(frames_begin_end):  # loop through split parts, moco and non-moco\n",
    "    if flag_moco[i_seq]:  # if moco part, append frames to concatenated data\n",
    "        for i_frame in range(sequence[0] - 1, sequence[1]):  # the tuples are indices starting with 1, so subtract 1. Also both inclusive, ccf. range() which is [inclusive, exclusive)\n",
    "            data_concatenated[i_concat] = images[i_frame]\n",
    "            i_concat += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6189c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: try to save C-type memmap, then use cell below to open, then compare images2 and images. Should have same dimensions (except T 500 instead of 577)\n",
    "moco_split_c_memmap = cm.save_memmap([data_concatenated], base_name='mmsplit', order='C',border_to_0=border_to_0, dview=dview) # exclude borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_split_c_memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the file\n",
    "Yr2, dims2, T2 = cm.load_memmap(moco_split_c_memmap)\n",
    "images2 = np.reshape(Yr2.T, [T2] + list(dims2), order='F') \n",
    "    #load frames in python format (T x X x Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410bce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to save data with non-moco cut out as separate mmap file:\n",
    "# if does not work, from caiman.mmapping import save_memmap\n",
    "#FIXME: this does not work, saves 2D data\n",
    "#concat_fname = cm.save_memmap(filenames = [data_concatenated], base_name=\"concat\", order=\"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c678e",
   "metadata": {},
   "source": [
    "### Clean up memory now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434eceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "if \"dview\" in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485225a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_images = images  # images2 if split data is used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5098551",
   "metadata": {},
   "source": [
    "### Run CNMF on patches in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RUN CNMF ON PATCHES\n",
    "# First extract spatial and temporal components on patches and combine them\n",
    "# for this step deconvolution is turned off (p=0). If you want to have\n",
    "# deconvolution within each patch change params.patch['p_patch'] to a\n",
    "# nonzero value\n",
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview, nb_patch = 4)\n",
    "cnm = cnm.fit(cnmf_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot contours of found components\n",
    "Cn = cm.local_correlations(cnmf_images.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f726f4",
   "metadata": {},
   "source": [
    "### Inspecting the results\n",
    "Briefly inspect the results by plotting contours of identified components against correlation image.\n",
    "The results of the algorithm are stored in the object `cnm.estimates`. More information can be found in the definition of the `estimates` object and in the [wiki](https://github.com/flatironinstitute/CaImAn/wiki/Interpreting-Results)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f92cc",
   "metadata": {},
   "source": [
    "## Re-run (seeded) CNMF  on the full Field of View  \n",
    "You can re-run the CNMF algorithm seeded on just the selected components from the previous step. Be careful, because components rejected on the previous step will not be recovered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589132f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
    "cnm2 = cnm.refit(cnmf_images, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa170f",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "# if performed re-run:\n",
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.evaluate_components(cnmf_images, cnm2.params, dview=dview)\n",
    "else:\n",
    "    cnm.estimates.evaluate_components(cnmf_images, cnm.params, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8ab3e",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components)\n",
    "else:\n",
    "    cnm.estimates.plot_contours_nb(img=Cn, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22338682",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components)\n",
    "else:\n",
    "    cnm.estimates.nb_view_components(img=Cn, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "if \"cnm2\" in locals():\n",
    "    if len(cnm2.estimates.idx_components_bad) > 0:\n",
    "        cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components_bad)\n",
    "    else:\n",
    "        print(\"No components were rejected.\")\n",
    "else:\n",
    "    if len(cnm.estimates.idx_components_bad) > 0:\n",
    "        cnm.estimates.nb_view_components(img=Cn, idx=cnm.estimates.idx_components_bad)\n",
    "    else:\n",
    "        print(\"No components were rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d505d",
   "metadata": {},
   "source": [
    "### Extract DF/F values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4969205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "#FIXME: \"Oops!\" printed when cnm2 not in locals (i.e. no refitting was done). Possibly this function never returns.\n",
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)\n",
    "else:\n",
    "    cnm.estimates.detrend_df_f(quantileMin=8, frames_window=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85965e4",
   "metadata": {},
   "source": [
    "### Select only high quality components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.select_components(use_object=True)\n",
    "else:\n",
    "    cnm.estimates.select_components(use_object=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5363a",
   "metadata": {},
   "source": [
    "## Display final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fade4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.nb_view_components(img=Cn, denoised_color='red')\n",
    "else:\n",
    "    cnm.estimates.nb_view_components(img=Cn, denoised_color='red')\n",
    "print('you may need to change the data rate to generate this one: use jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 before opening jupyter notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031a099",
   "metadata": {},
   "source": [
    "## Saving, closing, and creating denoised version\n",
    "### You can save an hdf5 file with all the fields of the cnmf object. Use load_CNMF() to open the results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b763da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = True\n",
    "save_path = os.path.splitext(export_hd5_fpath)[0] + \"_results.hdf5\"\n",
    "if save_results:\n",
    "    if \"cnm2\" in locals():\n",
    "        cnm2.save(save_path)\n",
    "    else:\n",
    "        cnm.save(save_path)\n",
    "    print(f\"saved to\\n{save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2075472",
   "metadata": {},
   "source": [
    "### Stop cluster and clean up log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d445936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3c392",
   "metadata": {},
   "source": [
    "### Export parameters and metadata as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927054d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = opts_dict.copy()\n",
    "json_dict[\"original_fnames\"] = nd2_fpath\n",
    "json_dict[\"rnr_win\"] = win\n",
    "json_dict[\"amplitude_threshold\"] = amplitude_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a58103",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_export_dir, json_fname = os.path.split(export_hd5_fpath)\n",
    "json_fname = \".\".join(json_fname.split(\".\")[:-1]) + \"_pars.json\"\n",
    "json_fpath = os.path.join(json_export_dir, json_fname)\n",
    "print(f\"Parameters will be saved under\\n{json_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8925391",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_fpath, 'w') as f:\n",
    "    json.dump(json_dict, f, indent=4)\n",
    "print(f\"Saved parameters to\\n{json_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b46207",
   "metadata": {},
   "source": [
    "### View movie with the results\n",
    "We can inspect the denoised results by reconstructing the movie and playing alongside the original data and the resulting (amplified) residual movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224db7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.play_movie(images, q_max=99.9, gain_res=2,\n",
    "                                      magnification=2,\n",
    "                                      bpx=border_to_0,\n",
    "                                      include_bck=False)\n",
    "else:\n",
    "    cnm.estimates.play_movie(images, q_max=99.9, gain_res=2,\n",
    "                                  magnification=2,\n",
    "                                  bpx=border_to_0,\n",
    "                                  include_bck=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028f7eb",
   "metadata": {},
   "source": [
    "The denoised movie can also be explicitly constructed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99359cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie\n",
    "if \"cnm2\" in locals():\n",
    "    denoised = cm.movie(cnm2.estimates.A.dot(cnm2.estimates.C) + \\\n",
    "                        cnm2.estimates.b.dot(cnm2.estimates.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])\n",
    "else:\n",
    "    denoised = cm.movie(cnm.estimates.A.dot(cnm.estimates.C) + \\\n",
    "                        cnm.estimates.b.dot(cnm.estimates.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5f911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

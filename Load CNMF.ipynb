{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7331f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caiman as cm\n",
    "import labrotation.file_handling as fh\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os.path\n",
    "import json\n",
    "from nd2_to_caiman import np_arr_from_nd2\n",
    "import scipy\n",
    "from RippleNoiseRemoval import RNR\n",
    "from time import time\n",
    "from movie_splitting import numpy_to_hdf5\n",
    "from numba import njit, prange\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633848d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO in nb_view_components, the blue is raw trace, yellow is smooth (inferred?). Use blue trace for matching with manual extraction! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b81d12",
   "metadata": {},
   "source": [
    "* TODO: in caiman/base/movies.py, motion_correct() is available, returning self, shifts, xcorrs, template! Does this make things easier? Also, extract_shifts() is similar. Apply_shifts is the other way around.\n",
    "* TODO: movies.py, extract_traces_from_masks might be useful\n",
    "* TODO: so, a movie object can be instantiated from an nd2 array or h5py dataset or mmap or tif file. It cannot be saved, but traces can be extracted with masking, moco shifts can be applied... So it might be still useful in the context of extracting traces! But need to check if this moco is the same moco as the moco moco, as this one does not use that library... So confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a47245",
   "metadata": {},
   "source": [
    "# Open h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78327be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_fpath = fh.open_file(\"Open hdf5 caiman file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf = cm.source_extraction.cnmf.cnmf.load_CNMF(cnmf_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb08535",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_uuid = None\n",
    "with h5py.File(cnmf_fpath, 'r') as hf:\n",
    "    session_uuid = hf.attrs[\"uuid\"]\n",
    "print(f\"UUID of session was {session_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876cccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e6ba872",
   "metadata": {},
   "source": [
    "### Open corresponding json CNMF parameters and moco parameters files. Change code if naming changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumed naming conventions:\n",
    "# CNMF results: xy_cnmf.hdf5\n",
    "# moco parameters: xy_moco_pars.h5\n",
    "# CNMF parameters: xy_pars.json\n",
    "\n",
    "# get root file name (and path)\n",
    "# get rid of extension and \"_cnmf\" at the end\n",
    "root_fpath = \"_\".join(os.path.splitext(cnmf_fpath)[0].split(\"_\")[:-1])\n",
    "\n",
    "\n",
    "pars_fpath = root_fpath + \"_pars.json\"\n",
    "moco_pars_fpath = root_fpath + \"_moco_pars.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bdcaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pars_fpath, \"r\") as json_file:\n",
    "    js = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_pars = dict()\n",
    "def bytesListToList(blist):\n",
    "    return list(map(lambda x: None if x == 'None' else x, blist.decode(\"utf-8\") .rstrip()[1:-1].split(\", \")))\n",
    "def bytesToVal(bs):\n",
    "    return None if bs == b'None' else bs.decode('utf-8') # TODO: convert to double?\n",
    "\n",
    "with h5py.File(moco_pars_fpath, \"r\") as hf:\n",
    "    for key in hf.keys():\n",
    "        print(key)\n",
    "        print(hf[key])\n",
    "\n",
    "    moco_pars[\"border_nan\"] = hf.attrs[\"border_nan\"]\n",
    "    moco_pars['uuid'] = hf.attrs[\"uuid\"]\n",
    "    moco_pars[\"var_name_hdf5\"] = hf.attrs[\"var_name_hdf5\"].decode(\"utf-8\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1578ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_fpath = js[\"original_fnames\"]\n",
    "print(nd2_fpath)\n",
    "print(f\"nd2 file available: {os.path.exists(nd2_fpath)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f4417",
   "metadata": {},
   "source": [
    "### (Optional) Open corresponding nd2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2875071",
   "metadata": {},
   "outputs": [],
   "source": [
    "nik_data = np_arr_from_nd2(nd2_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d76e7",
   "metadata": {},
   "source": [
    "# Test by plotting detected cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf.estimates.plot_contours_nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341513ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf.estimates.nb_view_components(denoised_color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d7340b",
   "metadata": {},
   "source": [
    "# Extract spatial coordinates in video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13e6e71",
   "metadata": {},
   "source": [
    "### scipy.sparse.csc_matrix (compressed sparse column matrix)\n",
    "To produce a CSC formatted matrix from a numpy matrix (np.ndarray), go through the matrix column by column, and note the row indices (0 = topmost element of a column) of non-zero elements. Append these to an array, `indices`, and their data values to another array, `data`. Then, create a new array `indptr`. The element `i` and `i+1` should form an interval `[x, y)` such that `indices[x:y]` are the elements of the i-th column.\n",
    "* `indices[indptr[i]:indptr[i+1]]` (note open interval on right! E.g. `[1:3] = {1, 2}`) contains the indices of the i-th column (i=0, ...) \n",
    "* `indptr` contains pointers to the column elements `indices`\n",
    "* `data` contains the corresponding value for each `indices` entry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_neuron = 467  # set a neuron by looking at cnmf.estimates.nb_view_components(). If the neuron there is i, write here i-1.\n",
    "                # Find one where any mirroring can be easily detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cnmf.estimates.A[:,i_neuron])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf.estimates.A[:,i_neuron].indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf.estimates.A[:,i_neuron].indptr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf.estimates.A[:,i_neuron].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf.estimates.A[:,i_neuron].indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf.estimates.A[:,i_neuron].data.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e49e91",
   "metadata": {},
   "source": [
    "# Test re-indexing into 2d array shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06856398",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal = cnmf.estimates.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a34988",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = cnmf.estimates.A.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1258bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = spatial[:,i_neuron].reshape((512,512)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21114679",
   "metadata": {},
   "source": [
    "### Check position of detected neuron. If mat is csc_matrix, then mat.nonzero() returns [x0, x1, ...], [y0, y1, ...] of (x, y) coordinates of nonzero elements. Need to check if these give back the original neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d465f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18));\n",
    "fig.suptitle(\"Reconstructed neuron; compare with nb_view_components() i+1 neuron\", fontsize=20);\n",
    "plt.imshow(neuron);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aea99fb",
   "metadata": {},
   "source": [
    "### Create binarized version of the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21aec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_binary = deepcopy(neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337187b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csc2 = scipy.sparse.csc_matrix(neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89009e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = csc2.nonzero()  # returns two lists: [x0, x1, ...], [y0, y1, ...] of [xi, yi] coordinates of non-zero entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c193cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = list(zip(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_coord in range(len(x)):  # loop through \n",
    "    i_x = x[i_coord]\n",
    "    i_y = y[i_coord]\n",
    "    neuron_binary[i_x, i_y] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2725cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18));\n",
    "fig.suptitle(\"Binarized neuron\", fontsize=20);\n",
    "plt.imshow(neuron_binary);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7747df35",
   "metadata": {},
   "source": [
    "# Create weighted average of signal\n",
    "The weights are the contents of the sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f15525",
   "metadata": {},
   "source": [
    "## RNR and MoCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = js[\"rnr_win\"]\n",
    "amplitude_threshold = js[\"amplitude_threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set export folder for temporary files\n",
    "export_folder = fh.open_dir(\"Select folder to save results\", True)\n",
    "# export_fname: get rid of .nd2 extension, append date and .h5 extension\n",
    "export_fname = fh.get_filename_with_date(os.path.splitext(os.path.split(nd2_fpath)[1])[0] + \"_rnr_\", \".hdf5\")\n",
    "export_hd5_fpath = os.path.join(export_folder, export_fname) # nd2_fpath.split(\"/\")[-1][:-4] + \"_exp.h5\"\n",
    "print(f\"Export file selected: {export_hd5_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnr = RNR(win, amplitude_threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cdc797",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_open = time()\n",
    "if \"begin_end_frames\" in locals():\n",
    "    rnr.open_recording(nd2_fpath, begin_end_frames)  # opens usual recording size (8.8-9 GB) in about 830 s\n",
    "else:\n",
    "    rnr.open_recording(nd2_fpath)\n",
    "print(f\"File opened in {time() - t0_open} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make sure CNMF object contains MoCo shifts (in Pure Python Pipeline / Splitting), then use apply_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52abe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_single = time()\n",
    "rnr_data = rnr.rnr_singlethread()  # a bit faster than opening file, around 500s for 8.8-9 GB\n",
    "t1_single = time()\n",
    "print(f\"RNR single thread finished in {t1_single - t0_single} s\")\n",
    "print(f\"Result is a {type(rnr_data)} with datatype {rnr_data.dtype}\")\n",
    "print(f\"Shape: {rnr_data.shape[0]} frames of {rnr_data.shape[1]}x{rnr_data.shape[2]} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1be948",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_to_hdf5(rnr_data, export_hd5_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f45444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version of saving intervals for MoCo and CNMF:\n",
    "if \"moco_intervals\" in js.keys():\n",
    "    moco_intervals = js[\"moco_intervals\"]\n",
    "    moco_flags = js[\"moco_flags\"]\n",
    "    cnmf_intervals = js[\"cnmf_intervals\"]\n",
    "    cnmf_flags = js[\"cnmf_flags\"]\n",
    "else:\n",
    "    with h5py.File(moco_pars_fpath, \"r\") as hf:\n",
    "        print(hf.keys())\n",
    "        print(hf.attrs.keys())\n",
    "        if \"moco_intervals\" in hf.keys():\n",
    "            moco_intervals = hf[\"moco_intervals\"][()]\n",
    "            moco_flags = hf[\"moco_flags\"][()]\n",
    "            cnmf_intervals = hf[\"cnmf_intervals\"][()]\n",
    "            cnmf_flags = hf[\"cnmf_flags\"][()]\n",
    "            begin_end_frames = hf[\"begin_end_frames\"][()]\n",
    "            border_to_0 = hf[\"border_to_0\"][()]\n",
    "        else:\n",
    "            raise Exception(\"No segmentation info found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_end_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c415c68",
   "metadata": {},
   "source": [
    "### Set output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d279464",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(\"export_hd5_fpath\" in locals()):\n",
    "    export_hd5_fpath = fh.open_file(\"Choose hd5 file to open\")\n",
    "if export_hd5_fpath.split(\".\")[-1] != \"hdf5\":\n",
    "    print(f\"Invalid hd5 file:\\n{export_hd5_fpath}\\nChoose a valid hd5 file!\")\n",
    "    export_hd5_fpath = fh.open_file(\"Choose hd5 file to open\")\n",
    "fnames = [export_hd5_fpath]\n",
    "print(f\"Going to perform MoCo on {fnames}\")\n",
    "assert export_hd5_fpath.split(\".\")[-1] == \"hdf5\", f\"Invalid file extension: .{export_hd5_fpath.split('.')[-1]}, expected .hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f825c",
   "metadata": {},
   "source": [
    "### Acquire parameters from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96321089",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in js.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "js[\"strides\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375a94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = js[\"fr\"]                             # imaging rate in frames per second\n",
    "decay_time = js[\"decay_time\"]                  # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "strides = tuple(js[\"strides\"])          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = tuple(js[\"overlaps\"])         # overlap between pathes (size of patch strides+overlaps)\n",
    "max_shifts = tuple(js[\"max_shifts\"])          # maximum allowed rigid shifts (in pixels)\n",
    "max_deviation_rigid = js[\"max_deviation_rigid\"]     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = js[\"pw_rigid\"]             # flag for performing non-rigid motion correction\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = js[\"p\"]                       # order of the autoregressive system\n",
    "gnb = js[\"nb\"]                     # number of global background components\n",
    "merge_thr = js[\"merge_thr\"]            # merging threshold, max correlation allowed\n",
    "rf = js[\"rf\"]                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = js[\"stride\"]             # amount of overlap between the patches in pixels\n",
    "K = js[\"K\"]                       # number of components per patch\n",
    "gSig = js[\"gSig\"]               # expected half size of neurons in pixels\n",
    "method_init = js[\"method_init\"]  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = js[\"ssub\"]                    # spatial subsampling during initialization\n",
    "tsub = js[\"tsub\"]                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = js[\"min_SNR\"]               # signal to noise ratio for accepting a component\n",
    "rval_thr = js[\"rval_thr\"]              # space correlation threshold for accepting a component\n",
    "cnn_thr = js[\"min_cnn_thr\"]              # threshold for CNN based classifier\n",
    "cnn_lowest = js[\"cnn_lowest\"] # neurons with cnn probability lower than this value are rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07573053",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fnames\" not in locals():\n",
    "    fnames = fh.open_file(\"No hd5 file selected. Choose corresponding hd5 file!\")\n",
    "opts_dict = {'fnames': fnames, \n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest,\n",
    "            'var_name_hdf5': 'data',\n",
    "            'gSig' :  gSig,}  # FIXME: does not work! Check where does this setting get lost?\n",
    "\n",
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4ed828",
   "metadata": {},
   "source": [
    "## Set up cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed02a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7135ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a353c0",
   "metadata": {},
   "source": [
    "### If shifts are contained in CNMF, apply them instead of performing MoCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c27c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ceaa8ec6",
   "metadata": {},
   "source": [
    "### Perform MoCo on whole movie first, do not save the results yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7dc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.motion_correct(save_movie=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7502d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shifts_els = deepcopy(mc.x_shifts_els)\n",
    "y_shifts_els = deepcopy(mc.y_shifts_els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e788a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = x_shifts_els[0].shape\n",
    "y_shape = y_shifts_els[0].shape\n",
    "for i_piece, frames_tuple in enumerate(moco_intervals):\n",
    "    if not moco_flags[i_piece]:  # skip this piece = set shifts to zero\n",
    "         for i_frame in range(frames_tuple[0] -1 , frames_tuple[1]):  # include last frame as well\n",
    "            x_shifts_els[i_frame] = np.zeros(x_shape)\n",
    "            y_shifts_els[i_frame] = np.zeros(y_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a585a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.x_shifts_els = x_shifts_els\n",
    "mc.y_shifts_els = y_shifts_els"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_folder = os.path.split(fnames[0])[0]\n",
    "print(f\"Changing work folder to {work_folder}, this is where moco result will be saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488fb503",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(work_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should save in C order because cm.load_memmap() takes C-memmap. However, as the opening and closing of memmap files is \n",
    "# so confusing, I decided to try to copy the original demo_pipeline jupyter notebook as closely as I can.\n",
    "exp_fname = mc.apply_shifts_movie(fnames, save_memmap=True,order=\"F\")\n",
    "print(exp_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5bf39",
   "metadata": {},
   "source": [
    "### At this point, we have the shifts for specific intervals in the recording, even if they were not saved before. We need to apply them to the whole recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if shifts in CNMF object, need to open file in MoCo, apply shifts, save to memmap and open memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_mmap = os.path.join(work_folder, exp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca45a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_fname2 = mc.apply_shifts_movie(fnames, save_memmap=True,order=\"C\")\n",
    "#mc_mmap2 = os.path.join(work_folder, exp_fname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_els = cm.load(mc_mmap)\n",
    "border_to_0 = 0 if mc.border_nan is 'copy' else mc.border_to_0  # FIXME: gives warning, should use \"==\" with literals\n",
    "    # maximum shift to be used for trimming against NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ffed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"mc_mmap\" not in locals():\n",
    "    mc_mmap = fh.open_file(\"Choose motion-corrected recording mmap!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a334f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_els_C = cm.load(mc_mmap2)\n",
    "m_els = cm.load(mc_mmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa54207",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_els.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb73778",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial.shape  # no. pixels (512x512) x no. neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7eaa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal.shape  # no. neurons x no. frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71813b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = temporal.shape[0]\n",
    "n_frames_cut = temporal.shape[1]\n",
    "n_frames_long = m_els.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f0dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check intervals are consistent with temporal size\n",
    "n_frs = 0\n",
    "for i_tup, tup in enumerate(js[\"cnmf_intervals\"]):\n",
    "    if js[\"cnmf_flags\"][i_tup]:\n",
    "        n_frs += tup[1] - tup[0] + 1\n",
    "print(n_frs)\n",
    "print(n_frs == n_frames_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab43e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_cut = np.zeros((n_neurons, n_frames_cut), dtype=m_els.dtype)  # same shape as temporal\n",
    "traces_whole = np.zeros((n_neurons, n_frames_long), dtype=m_els.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_signal_cut = np.zeros((n_neurons, n_frames_cut), dtype=m_els.dtype)  # same shape as temporal\n",
    "neuron_signal_whole = np.zeros((n_neurons, n_frames_long), dtype=m_els.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c331ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_weight = np.zeros(n_neurons, dtype=m_els.dtype)\n",
    "for i_neuron in range(n_neurons):\n",
    "    weight = 0\n",
    "    neuron_mask = spatial[:,i_neuron].reshape((512,512)).transpose()  # do not confuse with elon musk\n",
    "    pixels_x, pixels_y = scipy.sparse.csc_matrix(neuron_mask).nonzero()\n",
    "    for pix_x, pix_y in zip(pixels_x, pixels_y):\n",
    "        weight += neuron_mask[pix_x, pix_y]\n",
    "    neuron_weight[i_neuron] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8168560",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ffffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame-first method\n",
    "\n",
    "# extract whole trace per frame:\n",
    "# calculate for each neuron sum(pixels of neuron) {pixel weight}*{pixel temporal value}\n",
    "for i_frame in range(m_els.shape[0]):\n",
    "    print(i_frame)\n",
    "    for i_neuron in range(n_neurons):\n",
    "        neuron_mask = spatial[:,i_neuron].reshape((512,512)).transpose()  # do not confuse with elon musk\n",
    "        pixels_x, pixels_y = scipy.sparse.csc_matrix(neuron_mask).nonzero()\n",
    "        neuron_signal = 0  # the nominator\n",
    "        total_weight = 0  # the denominator\n",
    "        for pix_x, pix_y in zip(pixels_x, pixels_y):\n",
    "            neuron_signal += neuron_mask[pix_x, pix_y]*m_els[i_frame, pix_x, pix_y]  # add weight x trace of pixel to total\n",
    "        traces_whole[i_neuron, i_frame] = neuron_signal / neuron_weight[i_neuron]\n",
    "        neuron_signal_whole[i_neuron, i_frame] = neuron_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on this simple test, TXY order with F order in apply_shifts is the fastest way. I.e. the loop \n",
    "# over frames is the slowest-changing, Y the quickest.\n",
    "\n",
    "test_C_vs_F = False\n",
    "if test_C_vs_F:\n",
    "    # test reading various pixels throughout whole range\n",
    "    print(\"T-major approach\")\n",
    "    t0 = time()\n",
    "    s = 0\n",
    "    for i_x in range(30):\n",
    "        for i_y in range(30):\n",
    "            for i_frame in range(m_els.shape[0]):\n",
    "                s += m_els[i_frame, 10+i_x, 200+i_y]\n",
    "            s = 0\n",
    "    t1 = time()\n",
    "    print(f\"F order: {t1-t0}\")\n",
    "\n",
    "    t0C = time()\n",
    "    s = 0\n",
    "    for i_x in range(30):\n",
    "        for i_y in range(30):\n",
    "            for i_frame in range(m_els_C.shape[0]):\n",
    "                s += m_els_C[i_frame, 10+i_x, 200+i_y]\n",
    "            s = 0\n",
    "    t1C = time()\n",
    "\n",
    "    print(f\"C order: {t1C-t0C}\")\n",
    "    \n",
    "    print(\"XY-major approach\")\n",
    "    t0 = time()\n",
    "    s = 0\n",
    "    print(\"TXY\")\n",
    "    for i_frame in range(m_els.shape[0]):\n",
    "        for i_x in range(30):\n",
    "            for i_y in range(30):\n",
    "                s += m_els[i_frame, 10+i_x, 200+i_y]\n",
    "        s = 0\n",
    "    t1 = time()\n",
    "    print(f\"F order: {t1-t0}\")\n",
    "\n",
    "    t0C = time()\n",
    "    s = 0\n",
    "    for i_frame in range(m_els_C.shape[0]):\n",
    "        for i_x in range(30):\n",
    "            for i_y in range(30):\n",
    "                s += m_els_C[i_frame, 10+i_x, 200+i_y]\n",
    "        s = 0\n",
    "    t1C = time()\n",
    "    print(f\"C order: {t1C-t0C}\")\n",
    "    print(\"TYX\")\n",
    "    t0 = time()\n",
    "    s = 0\n",
    "    for i_frame in range(m_els.shape[0]):\n",
    "        for i_y in range(30):\n",
    "            for i_x in range(30):\n",
    "                s += m_els[i_frame, 10+i_x, 200+i_y]\n",
    "        s = 0\n",
    "    t1 = time()\n",
    "    print(f\"F order: {t1-t0}\")\n",
    "\n",
    "    t0C = time()\n",
    "    s = 0\n",
    "    for i_frame in range(m_els_C.shape[0]):\n",
    "        for i_y in range(30):\n",
    "            for i_x in range(30):\n",
    "                s += m_els_C[i_frame, 10+i_x, 200+i_y]\n",
    "        s = 0\n",
    "    t1C = time()\n",
    "    print(f\"C order: {t1C-t0C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel-first method\n",
    "\n",
    "# extract whole trace per frame:\n",
    "# calculate for each neuron sum(pixels of neuron) {pixel weight}*{pixel temporal value}\n",
    "for i_neuron in range(n_neurons):\n",
    "    print(i_neuron)\n",
    "    neuron_mask = spatial[:,i_neuron].reshape((512,512)).transpose()  # do not confuse with elon musk\n",
    "    pixels_x, pixels_y = scipy.sparse.csc_matrix(neuron_mask).nonzero()\n",
    "    for pix_x, pix_y in zip(pixels_x, pixels_y):\n",
    "        for i_frame in range(m_els.shape[0]):\n",
    "            pixel_signal = neuron_mask[pix_x, pix_y]*m_els[i_frame, pix_x, pix_y]\n",
    "            traces_whole[i_neuron, i_frame] += pixel_signal / neuron_weight[i_neuron]\n",
    "            neuron_signal_whole[i_neuron, i_frame] += pixel_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30690ea6",
   "metadata": {},
   "source": [
    "# Attempt at parallelizing the trace extraction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee878ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_data = np.asarray(m_els.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82104c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd2ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe66c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = np.array(spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb064264",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = np.reshape(spatial, (512, 512, 1166))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff99ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9912ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = np.transpose(spatial, axes=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16270885",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18));\n",
    "fig.suptitle(\"Reconstructed neuron; compare with nb_view_components() i+1 neuron\", fontsize=20);\n",
    "plt.imshow(spatial[:,:,222]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f973493",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_neu = 222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad16c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neu_mask = spatial[:,:,i_neu]\n",
    "pix_x, pix_y = scipy.sparse.csc_matrix(neu_mask).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_data[:, pix_x, pix_y].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial[:,0].reshape((512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial[pix_x, pix_y, i_neu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fcd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[0, 1], [2, 3], [4, 5], [6, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aec94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([10, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16481152",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "b*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(b*c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial[pix_x, pix_y, i_neu].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd674111",
   "metadata": {},
   "outputs": [],
   "source": [
    "(moco_data[:, pix_x, pix_y]*spatial[pix_x, pix_y, i_neu]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f16713",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d27635",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_x, pix_y = spatial[:,:,222].nonzero()\n",
    "np.sum(moco_data[:, pix_x, pix_y]*spatial[pix_x, pix_y, 222], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b54cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_pix in range(len(pix_x)):\n",
    "    x = pix_x[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59555852",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_par = np.sum(spatial, axis=(0,1))\n",
    "traces_par = np.zeros((n_neurons, n_frames_long), dtype=moco_data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc37446e",
   "metadata": {},
   "source": [
    "# The algorithm below seems to work well, and fast! (JIT + parallelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def extract_neuron_trace():  # neuron_xy = np.array[x0, x1, ..., xn; y0, y1, ..., yn], 2 rows, n columns\n",
    "    traces_par = np.zeros((n_neurons, n_frames_long), dtype=moco_data.dtype)    \n",
    "    for i_neuron in prange(n_neurons):\n",
    "        pixels_x, pixels_y = spatial[:,:,i_neuron].nonzero()\n",
    "        trace = np.zeros((n_frames_long,), dtype=moco_data.dtype)\n",
    "        for i_frame in range(n_frames_long):\n",
    "            trace_val = 0.\n",
    "            i_pix = 0\n",
    "            while i_pix < pixels_x.shape[0]:\n",
    "                trace_val = trace_val + spatial[pixels_x[i_pix], pixels_y[i_pix], i_neuron]*moco_data[i_frame, pixels_x[i_pix], pixels_y[i_pix]]\n",
    "                i_pix = i_pix + 1\n",
    "            traces_par[i_neuron, i_frame] = trace_val\n",
    "        #np.sum(moco_data[:, pixels_x, pixels_y]*spatial[pixels_x, pixels_y, i_neuron], axis=1)\n",
    "    return traces_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a378f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = extract_neuron_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1252b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_norm = np.divide(tr, weights_par[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74aadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_n = 222\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "#plt.plot(tr[i_n, :])\n",
    "plt.plot(tr_norm[i_n,:])\n",
    "plt.plot(temporal[i_n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169309f0",
   "metadata": {},
   "source": [
    "## Desperate attempt: try not to save moco, but try to access the data in the RAM somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926aa180",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935de3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_imp = mc.apply_shifts_movie(fnames, save_memmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f695c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_data = np.asarray(moco_imp.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8218f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_signal_cut = np.zeros((n_neurons, n_frames_cut), dtype=m_els.dtype)  # same shape as temporal\n",
    "neuron_signal_whole = np.zeros((n_neurons, n_frames_long), dtype=m_els.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812fc89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate for each neuron sum(pixels of neuron) {pixel weight}*{pixel temporal value}\n",
    "for i_neuron in range(n_neurons):\n",
    "    print(i_neuron)\n",
    "    neuron_mask = spatial[:,i_neuron].reshape((512,512)).transpose()  # do not confuse with elon musk\n",
    "    pixels_x, pixels_y = scipy.sparse.csc_matrix(neuron_mask).nonzero()\n",
    "    neuron_signal = 0  # the nominator\n",
    "    total_weight = 0  # the denominator\n",
    "    for pix_x, pix_y in zip(pixels_x, pixels_y):\n",
    "        for i_frame in range(moco_data.shape[0]):\n",
    "            neuron_signal_whole[i_neuron, i_frame] += neuron_mask[pix_x, pix_y]*moco_data[i_frame, pix_x, pix_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a141c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame-first method\n",
    "\n",
    "# extract whole trace per frame:\n",
    "# calculate for each neuron sum(pixels of neuron) {pixel weight}*{pixel temporal value}\n",
    "for i_frame in range(moco_data.shape[0]):\n",
    "    print(i_frame)\n",
    "    for i_neuron in range(n_neurons):\n",
    "        neuron_mask = spatial[:,i_neuron].reshape((512,512)).transpose()  # do not confuse with elon musk\n",
    "        pixels_x, pixels_y = scipy.sparse.csc_matrix(neuron_mask).nonzero()\n",
    "        neuron_signal = 0  # the nominator\n",
    "        total_weight = 0  # the denominator\n",
    "        for pix_x, pix_y in zip(pixels_x, pixels_y):\n",
    "            neuron_signal += neuron_mask[pix_x, pix_y]*m_els[i_frame, pix_x, pix_y]  # add weight x trace of pixel to total\n",
    "        #traces_whole[i_neuron, i_frame] = neuron_signal / neuron_weight[i_neuron]\n",
    "        neuron_signal_whole[i_neuron, i_frame] = neuron_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01046ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "plt.plot(neuron_signal_whole[440,:], label=\"manual extraction\")\n",
    "plt.plot(temporal[440,:], label=\"cnmf\")\n",
    "plt.xlim((7500,12000))\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a59bb6",
   "metadata": {},
   "source": [
    "# Show CNMF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(18,18))\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need C and \n",
    "cnmf.estimates.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "covmat = np.cov(cnmf.estimates.C)\n",
    "corrmat = np.corrcoef(cnmf.estimates.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "covmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd99705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "plt.imshow(corrmat, interpolation=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aee36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "plt.imshow(corrmat[:50, :50], interpolation=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e40b25",
   "metadata": {},
   "source": [
    "# Visualise connections as graph\n",
    "https://stackoverflow.com/questions/60392714/nodes-clusters-on-weighted-graph-visualization\n",
    "https://stackoverflow.com/questions/43541376/how-to-draw-communities-with-networkx/43541777#43541777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6dac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7005b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(height='750px', width='100%', bgcolor='#222222', font_color='white')\n",
    "net.force_atlas_2based()\n",
    "for i in range(n_neurons):\n",
    "    net.add_node(i)\n",
    "for i in range(n_neurons):\n",
    "    for j in range(i+1, n_neurons):\n",
    "        net.add_edge(i, j, weight=(covmat[i,j] + 1)/2)\n",
    "\n",
    "#net.toggle_physics(True)\n",
    "net.show(\"vis.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48577b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# installation easiest via pip:\n",
    "# pip install netgraph\n",
    "from netgraph import Graph\n",
    "\n",
    "# create a modular graph\n",
    "partition_sizes = [10, 20, 30, 40]\n",
    "g = nx.random_partition_graph(partition_sizes, 0.5, 0.1)\n",
    "\n",
    "# since we created the graph, we know the best partition:\n",
    "node_to_community = dict()\n",
    "node = 0\n",
    "for community_id, size in enumerate(partition_sizes):\n",
    "    for _ in range(size):\n",
    "        node_to_community[node] = community_id\n",
    "        node += 1\n",
    "\n",
    "# # alternatively, we can infer the best partition using Louvain:\n",
    "# from community import community_louvain\n",
    "# node_to_community = community_louvain.best_partition(g)\n",
    "\n",
    "community_to_color = {\n",
    "    0 : 'tab:blue',\n",
    "    1 : 'tab:orange',\n",
    "    2 : 'tab:green',\n",
    "    3 : 'tab:red',\n",
    "}\n",
    "node_color = {node: community_to_color[community_id] for node, community_id in node_to_community.items()}\n",
    "\n",
    "Graph(g,\n",
    "      node_color=node_color, node_edge_width=0, edge_alpha=0.1,\n",
    "      node_layout='community', node_layout_kwargs=dict(node_to_community=node_to_community),\n",
    "      edge_layout='bundled', edge_layout_kwargs=dict(k=2000),\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ed972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use igraph to plot graph? https://igraph.org/python/tutorial/latest/tutorial.html#layout-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f30f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get physical distance of neurons, too? Then we can plot distance-correlation as scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20230c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #TODO: useful links:\n",
    "    # https://stackoverflow.com/questions/3081066/what-techniques-exists-in-r-to-visualize-a-distance-matrix\n",
    "    # https://igraph.org/python/doc/tutorial/tutorial.html\n",
    "    # https://stats.stackexchange.com/questions/165194/using-correlation-as-distance-metric-for-hierarchical-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.array([[0, 0, 0, 1, 0, 0], [0, 2, 0, 0, 3, 0], [0, 4, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 7, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e246da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4bf930",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_sparse = scipy.sparse.csc_matrix(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025304b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_sparse.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_sparse.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd35550",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_sparse.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c28318",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf.estimates.shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b6558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9978d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"D:\\\\Interpolation_test\\\\Load_CNMF\\\\extracted_temporal.h5py\", 'w') as hf:\n",
    "    hf.create_dataset(\"neuron_signal_whole\", data=neuron_signal_whole)\n",
    "    hf.create_dataset(\"neuron_weight\", data=neuron_weight)\n",
    "    hf.create_dataset(\"x_shifts_els\", data=x_shifts_els)\n",
    "    hf.create_dataset(\"y_shifts_els\", data=y_shifts_els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locomotion during seizure vs during SD\n",
    "Compare the locomotion (same quantities as in Locomotion analysis 3.0) during optically visible seizure that ends when the SD appears in the window, with a same interval directly following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metric_label = OrderedDict([(\"totdist_abs\", \"Total (absolute) distance, a.u.\"),\n",
    "                                (\"running%\", \"% of time spent with locomotion\"), \n",
    "                                (\"running_episodes\", \"Number of running episodes\"),\n",
    "                                (\"avg_speed\", \"Average of locomotion velocity\"),\n",
    "                                (\"running_episodes_mean_length\", \"Mean length of running episodes, a.u.\"),\n",
    "                                (\"max_speed\", \"Max velocity of locomotion, a.u.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT_METRICS = [\"totdist_abs\", \"running%\", \"running_episodes\", \"avg_speed\", \"running_episodes_mean_length\", \"max_speed\"]  # metrics to test for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMPL_THRESHOLD = 0.2  # threshold that one element within the running episode candidate has to be reached for the episode to not be discarded.\n",
    "TEMP_THRESHOLD = 15  # in number of frames. In 15 Hz, this amounts to 1 s threshold that a candidate episode has to reach to not be discarded. \n",
    "EPISODE_MERGE_THRESHOLD_FRAMES = 8  # merge running episodes if temporal distance distance smaller than this many frames or equal (15 Hz!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up export figure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = False  # export results of this script?\n",
    "save_sanity_check = False  # make sure to set save_figs to True as well\n",
    "save_waterfall = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True  # set to True to save the figures created\n",
    "save_as_eps = False\n",
    "save_as_pdf = True\n",
    "if save_as_pdf:\n",
    "    file_format = \".pdf\"\n",
    "elif save_as_eps:\n",
    "    file_format = \".eps\"\n",
    "else:\n",
    "    file_format = \".jpg\"\n",
    "if save_figs:\n",
    "    print(f\"Going to save figures as {file_format} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labrotation.file_handling as fh\n",
    "import h5py\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps\n",
    "import seaborn as sns\n",
    "import uuid  # for unique labeling of sessions and coupling arrays (mouse velocity, distance, ...) to sessions in dataframe \n",
    "from matplotlib import cm  # colormap\n",
    "import datadoc_util\n",
    "from labrotation import two_photon_session as tps\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from math import floor\n",
    "import matlab.engine  # for saving data to workspace\n",
    "from scipy.stats import ttest_rel\n",
    "import json\n",
    "from loco_functions import apply_threshold, get_episodes, calculate_avg_speed, calculate_max_speed, get_trace_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seaborn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=3)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If exists, load environmental variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data documentation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: inside the documentation folder, the subfolders carry the id of each mouse (not exact necessarily, but they \n",
    "# can be identified by the name of the subfolder). \n",
    "# Inside the subfolder xy (for mouse xy), xy_grouping.xlsx and xy_segmentation.xlsx can be found.\n",
    "# xy_grouping.xlsx serves the purpose of finding the recordings belonging together, and has columns:\n",
    "# folder, nd2, labview, lfp, face_cam_last, nikon_meta, experiment_type, day\n",
    "# xy_segmentation.xlsx contains frame-by-frame (given by a set of disjoint intervals forming a cover for the whole recording) \n",
    "# classification of the events in the recording (\"normal\", seizure (\"sz\"), sd wave (\"sd_wave\") etc.). The columns:\n",
    "# folder, interval_type, frame_begin, frame_end.\n",
    "\n",
    "# TODO: write documentation on contents of xlsx files (what the columns are etc.)\n",
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    docu_folder = fh.open_dir(\"Choose folder containing folders for each mouse!\")\n",
    "print(f\"Selected folder:\\n\\t{docu_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"documentation\" in os.listdir(docu_folder):\n",
    "    mouse_folder = os.path.join(docu_folder, \"documentation\")\n",
    "else:\n",
    "    mouse_folder = docu_folder\n",
    "mouse_names = os.listdir(mouse_folder)\n",
    "print(f\"Mice detected:\")\n",
    "for mouse in mouse_names:\n",
    "    print(f\"\\t{mouse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = datetime.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = env_dict[\"DOWNLOADS_FOLDER\"]\n",
    "print(f\"Output files will be saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set a uniform datetime string for output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dtime = get_datetime_for_fname()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load matlab-2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"MATLAB_2P_FOLDER\" in env_dict.keys():\n",
    "    matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]\n",
    "else:\n",
    "    matlab_2p_folder = fh.open_dir(\"Choose matlab-2p folder\")\n",
    "print(f\"matlab-2p folder set to:\\n\\t{matlab_2p_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = datadoc_util.DataDocumentation(docu_folder)\n",
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up color coding\n",
    "for now, only possible to assign a color to each mouse. Later, when event uuids available, need to map event uuid to color code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colors = ddoc.getColorings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_colors_mouse = df_colors[[\"mouse_id\", \"color\"]].to_dict(orient=\"list\")\n",
    "dict_colors_mouse = dict(zip(dict_colors_mouse[\"mouse_id\"], dict_colors_mouse[\"color\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_colors_mouse[\"T413\"] = \"#000000\"  # set one to black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load events_list dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list_fpath = os.path.join(docu_folder, \"events_list.xlsx\")\n",
    "assert os.path.exists(events_list_fpath)\n",
    "\n",
    "df_events_list = pd.read_excel(events_list_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_traces_fpath = fh.open_file(\"Open assembled_traces h5 file!\")\n",
    "print(assembled_traces_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_chr2 = False\n",
    "is_bilat = False\n",
    "if \"chr2\" in assembled_traces_fpath.lower():\n",
    "    is_chr2 = True\n",
    "    print(\"ChR2 dataset detected\")\n",
    "elif \"bilat\" in assembled_traces_fpath.lower():\n",
    "    is_bilat = True\n",
    "    print(\"Bilat stim dataset detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chr2:\n",
    "    used_mouse_ids = [\"OPI-2239\", \"WEZ-8917\", \"WEZ-8924\", \"WEZ-8922\"]\n",
    "elif is_bilat:\n",
    "    used_mouse_ids = [\"WEZ-8946\", \"WEZ-8960\", \"WEZ-8961\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"chr2\" if is_chr2 else \"bilat\" if is_bilat else \"tmev\" \n",
    "if not is_chr2:  # for TMEV, also save pooled CA1+NC statistics\n",
    "    pool_tmev = True\n",
    "else:\n",
    "    pool_tmev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_dict = dict()  \n",
    "traces_meta_dict = dict()\n",
    "# first keys are event uuids, inside the following dataset names:\n",
    "# 'lfp_mov_t', 'lfp_mov_y', 'lfp_t', 'lfp_y', 'lv_dist', 'lv_rounds', \n",
    "# 'lv_running', 'lv_speed', 'lv_t_s', 'lv_totdist', 'mean_fluo'\n",
    "with h5py.File(assembled_traces_fpath, \"r\") as hf:\n",
    "    for uuid in hf.keys():\n",
    "        if (not is_chr2) or (hf[uuid].attrs[\"mouse_id\"] in used_mouse_ids):\n",
    "            session_dataset_dict = dict() \n",
    "            session_meta_dict = dict()\n",
    "            for dataset_name in hf[uuid].keys():\n",
    "                session_dataset_dict[dataset_name] = np.array(hf[uuid][dataset_name])\n",
    "            for attr_name in hf[uuid].attrs:\n",
    "                session_meta_dict[attr_name] = hf[uuid].attrs[attr_name]\n",
    "            traces_dict[uuid] = session_dataset_dict.copy()\n",
    "            traces_meta_dict[uuid] = session_meta_dict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get locomotion amplitude by finding min and max LabView speed entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_speed = np.inf\n",
    "max_speed = -np.inf\n",
    "for e_uuid in traces_dict.keys():\n",
    "    speed = traces_dict[e_uuid][\"lv_speed\"]\n",
    "    min_candidate = np.min(speed)\n",
    "    max_candidate = np.max(speed)\n",
    "    if min_candidate < min_speed:\n",
    "        min_speed = min_candidate\n",
    "    if max_candidate > max_speed:\n",
    "        max_speed = max_candidate\n",
    "print(f\"Speed range: {min_speed} to {max_speed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LV_SPEED_AMPL = max_speed - min_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for TMEV, there should be frames 0, start of SZ (5000, the length of baseline in each trace), start of SD (i.e. start of aftermath) as segment type break points.\n",
    "# for ChR2, there should be frames 0, stim start, stim end+1, and other, variable number of entries as segment type break points, depending on stim type and observed number of SD \n",
    "# so ChR2 needs adaptation...\n",
    "for uuid in traces_meta_dict.keys():\n",
    "    assert len(traces_meta_dict[uuid][\"segment_type_break_points\"]) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get windows for comparison\n",
    "For TMEV, start of seizure until start of SD (i.e. segment_type_break_points[1], [2]) mark beginning and end of seizure; then need to take the same length window starting with [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each entry (row) should have columns: \n",
    "# uuid of event, mouse id, window type, segment type (bl/sz/am), segment length in frames, totdist, running, speed\n",
    "list_statistics = []  \n",
    "dict_episodes = {}\n",
    "loco_binary_traces = {}  # contains the post-filtering \"running\" trace, of which the running% is calculated (divided by segment length)\n",
    "loco_episodes = {}  # contains the first and last indices of the locomotion episodes\n",
    "dict_begin_end_frames = {}\n",
    "\n",
    "for e_uuid in traces_dict.keys():\n",
    "    mouse_id = traces_meta_dict[e_uuid][\"mouse_id\"]\n",
    "    win_type = traces_meta_dict[e_uuid][\"window_type\"]\n",
    "    if \"exp_type\" in traces_meta_dict[e_uuid].keys():\n",
    "        exp_type = traces_meta_dict[e_uuid][\"exp_type\"]\n",
    "        if \"sz\" not in exp_type:\n",
    "            print(f\"{exp_type} does not contain seizure... Skipping...\")\n",
    "    else:\n",
    "        exp_type = \"tmev\"\n",
    "        \n",
    "    i_begin_sz_frame = traces_meta_dict[e_uuid][\"segment_type_break_points\"][1]\n",
    "    i_begin_sd_frame = traces_meta_dict[e_uuid][\"segment_type_break_points\"][2]\n",
    "    dict_begin_end_frames[e_uuid] = (i_begin_sz_frame, i_begin_sd_frame)\n",
    "    n_segment_frames = i_begin_sd_frame - i_begin_sz_frame\n",
    "\n",
    "    \n",
    "    lv_totdist = traces_dict[e_uuid][\"lv_totdist\"]\n",
    "    lv_totdist_abs = traces_dict[e_uuid][\"lv_totdist_abs\"]\n",
    "    lv_running = traces_dict[e_uuid][\"lv_running\"]\n",
    "    lv_speed = traces_dict[e_uuid][\"lv_speed\"]\n",
    "\n",
    "    lv_speed_sz = lv_speed[i_begin_sz_frame:i_begin_sz_frame+n_segment_frames]\n",
    "    lv_speed_sd = lv_speed[i_begin_sd_frame:i_begin_sd_frame+n_segment_frames]\n",
    "\n",
    "    lv_running_sz = lv_running[i_begin_sz_frame:i_begin_sz_frame+n_segment_frames]\n",
    "    lv_running_sd = lv_running[i_begin_sd_frame:i_begin_sd_frame+n_segment_frames]\n",
    "\n",
    "\n",
    "    # get metrics for sz and sd segments\n",
    "    totdist_sz = get_trace_delta(lv_totdist, i_begin_sz_frame, i_begin_sz_frame+n_segment_frames)\n",
    "    totdist_sd = get_trace_delta(lv_totdist, i_begin_sd_frame, i_begin_sd_frame+n_segment_frames)\n",
    "\n",
    "    totdist_abs_sz = get_trace_delta(lv_totdist_abs, i_begin_sz_frame, i_begin_sz_frame+n_segment_frames)\n",
    "    totdist_abs_sd = get_trace_delta(lv_totdist_abs, i_begin_sd_frame, i_begin_sd_frame+n_segment_frames)\n",
    "\n",
    "    # number of episodes\n",
    "    list_episodes_sz = get_episodes(lv_running_sz, True, EPISODE_MERGE_THRESHOLD_FRAMES, return_begin_end_frames=True )  # 15 frames in 15 Hz is 1 s.\n",
    "    list_episodes_sd = get_episodes(lv_running_sd, True, EPISODE_MERGE_THRESHOLD_FRAMES, return_begin_end_frames=True )  # 15 frames in 15 Hz is 1 s.\n",
    "    \n",
    "    list_episodes_sz = apply_threshold(lv_speed_sz, list_episodes_sz, TEMP_THRESHOLD, AMPL_THRESHOLD, )\n",
    "    list_episodes_sd = apply_threshold(lv_speed_sd, list_episodes_sd, TEMP_THRESHOLD, AMPL_THRESHOLD, )\n",
    "    \n",
    "    list_episode_lengths_sz = np.array([ep[1]-ep[0] + 1 for ep in list_episodes_sz])\n",
    "    n_episodes_sz = len(list_episodes_sz)\n",
    "    \n",
    "    list_episode_lengths_sd = np.array([ep[1]-ep[0] + 1 for ep in list_episodes_sd])\n",
    "    n_episodes_sd = len(list_episodes_sd)\n",
    "\n",
    "    # running %\n",
    "    running_sz = np.sum(list_episode_lengths_sz)\n",
    "    running_sd = np.sum(list_episode_lengths_sd)\n",
    "\n",
    "    # speed\n",
    "    speed_sz = sum(lv_speed_sz)\n",
    "    speed_sd = sum(lv_speed_sd)\n",
    "    \n",
    "    # avg speed\n",
    "    avg_speed_sz = calculate_avg_speed(lv_speed_sz)\n",
    "    avg_speed_sd = calculate_avg_speed(lv_speed_sd)\n",
    "\n",
    "    # max speed\n",
    "    max_speed_sz = calculate_max_speed(lv_speed_sz)\n",
    "    max_speed_sd = calculate_max_speed(lv_speed_sd)\n",
    "\n",
    "    # episode mean length, std\n",
    "    episode_mean_len_sz = list_episode_lengths_sz.mean() if len(list_episode_lengths_sz) > 0 else 0\n",
    "    episode_std_sz = list_episode_lengths_sz.std()\n",
    "    episode_mean_len_sd = list_episode_lengths_sd.mean() if len(list_episode_lengths_sd) > 0 else 0\n",
    "    episode_std_sd = list_episode_lengths_sd.std()\n",
    "\n",
    "    #apply_threshold, get_episodes, calculate_avg_speed, calculate_max_speed\n",
    "    list_statistics.append([e_uuid, mouse_id, win_type, exp_type, \"sz\", n_segment_frames, totdist_sz, totdist_abs_sz, running_sz, speed_sz, avg_speed_sz, n_episodes_sz, episode_mean_len_sz, episode_std_sz, max_speed_sz, ])\n",
    "    list_statistics.append([e_uuid, mouse_id, win_type, exp_type, \"sd\", n_segment_frames, totdist_sd, totdist_abs_sd, running_sd, speed_sd, avg_speed_sd, n_episodes_sd, episode_mean_len_sd, episode_std_sd, max_speed_sd, ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(data=list_statistics, columns=[\"event_uuid\", \"mouse_id\", \"window_type\", \"exp_type\", \"segment_type\",  \"segment_length\", \"totdist\", \"totdist_abs\", \"running\", \"speed\", \"avg_speed\", \"running_episodes\", \"running_episodes_mean_length\", \"running_episodes_length_std\", \"max_speed\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[\"avg_speed\"] = df_stats[\"avg_speed\"].fillna(0)\n",
    "df_stats[\"running_episodes_mean_length\"] = df_stats[\"running_episodes_mean_length\"].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of time spent running\n",
    "df_stats[\"running%\"] = 100.*df_stats[\"running\"]/df_stats[\"segment_length\"]  # get value as true % instead of [0, 1] float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_factor = 10000\n",
    "\n",
    "#df_stats[\"totdist_norm\"] = scale_factor*df_stats[\"totdist\"]/df_stats[\"segment_length\"]\n",
    "#df_stats[\"totdist_abs_norm\"] = scale_factor*df_stats[\"totdist_abs\"]/df_stats[\"segment_length\"]\n",
    "#df_stats[\"running_norm\"] = scale_factor*df_stats[\"running\"]/df_stats[\"segment_length\"]\n",
    "#df_stats[\"speed_norm\"] = scale_factor*df_stats[\"speed\"]/df_stats[\"segment_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[\"color\"] = df_stats.apply(lambda row: dict_colors_mouse[row[\"mouse_id\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_colors_event = df_stats[[\"event_uuid\", \"color\"]].to_dict(orient=\"list\")\n",
    "dict_colors_event = dict(zip(dict_colors_event[\"event_uuid\"], dict_colors_event[\"color\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[\"window_type\"] = df_stats[\"window_type\"].replace({\"Cx\" : \"NC\", \"ca1\": \"CA1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    output_fpath = os.path.join(output_folder, f\"loco_tmev_sz-vs-sd_{output_dtime}.xlsx\")\n",
    "    df_stats.to_excel(output_fpath, index=False)\n",
    "    print(f\"Results exported to {output_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create deltas\n",
    "Group by event uuid,  get Sz values, get SD values, subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_df_deltas = []\n",
    "\n",
    "for i, metric in enumerate(STAT_METRICS):  # fill each row\n",
    "    #if group_by_colname == \"event_uuid\":\n",
    "    group_by_colname = \"event_uuid\"\n",
    "    df_metric_pivot = df_stats.pivot(columns=\"segment_type\", index=group_by_colname, values=metric).reset_index()\n",
    "    #else:  # mouse_id may not be unique (multiple experiment types, like chr2_ctl, chr2_sd, for one mouse)\n",
    "    #    df_metric_pivot = df_stat_data.pivot(columns=\"segment_type\", index=[group_by_colname, \"exp_type\"], values=metric).reset_index()\n",
    "    # 1 window per mouse\n",
    "    df_metric_pivot[\"window_type\"] = df_metric_pivot.apply(lambda row: df_stats[df_stats[group_by_colname] == row[group_by_colname]].window_type.iloc[0], axis=1)   \n",
    "    df_metric_pivot[\"mouse_id\"] = df_metric_pivot.apply(lambda row: df_stats[df_stats[group_by_colname] == row[group_by_colname]].mouse_id.iloc[0], axis=1) \n",
    "    if \"exp_type\" not in df_metric_pivot.columns:\n",
    "        df_metric_pivot[\"exp_type\"] = df_metric_pivot.apply(lambda row: df_stats[df_stats[group_by_colname] == row[group_by_colname]].exp_type.iloc[0], axis=1)   \n",
    "    metric_diff_name = f\"delta_{metric}\"\n",
    "    df_metric_pivot[metric_diff_name] = df_metric_pivot[\"sd\"] - df_metric_pivot[\"sz\"]\n",
    "    # only keep the change (delta), drop the quantities themselves\n",
    "    df_metric_pivot = df_metric_pivot.drop([\"sz\", \"sd\"], axis=1)\n",
    "    l_df_deltas.append(df_metric_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deltas_combined = l_df_deltas[0]\n",
    "for df_delta in l_df_deltas[1:]:\n",
    "    df_deltas_combined = pd.merge(df_deltas_combined, df_delta, on=[\"event_uuid\", \"window_type\", \"mouse_id\", \"exp_type\"], how=\"outer\")\n",
    "if save_data:\n",
    "    output_fpath = os.path.join(output_folder, f\"loco_tmev_sz-vs-sd_delta_{output_dtime}.xlsx\")\n",
    "    df_deltas_combined.to_excel(output_fpath, index=False)\n",
    "    print(f\"Results exported to {output_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(STAT_METRICS) == 6\n",
    "n_rows = 2\n",
    "n_cols = 3\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(12*n_cols, 10*n_rows))\n",
    "for i_metric, stat_metric in enumerate(STAT_METRICS):\n",
    "    sns.boxplot(data=df_deltas_combined, x=\"window_type\", y=\"delta_\"+stat_metric, ax=axs[i_metric//n_cols][i_metric%n_cols])\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs:\n",
    "    fig_fpath = os.path.join(output_folder, f'loco_tmev_sz-vs-sd_deltas_{output_dtime}{file_format}')\n",
    "    plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "    print(f\"Saved to {fig_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create waterfall plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMPLITUDE = LV_SPEED_AMPL\n",
    "offset = 0\n",
    "mouse_ids = df_stats.mouse_id.unique()\n",
    "\n",
    "n_recordings = len(mouse_ids)\n",
    "fig = plt.figure(figsize=(18,n_recordings*3))\n",
    "prev_range = 0.0\n",
    "\n",
    "for mouse_id in mouse_ids: \n",
    "    for e_uuid in df_stats[df_stats[\"mouse_id\"]==mouse_id].event_uuid.unique():\n",
    "        # this script does not work with chr2 out of the box, but in case of future update, leave this already in\n",
    "        if is_chr2:  # chr2 experiments contain the whole session in one file\n",
    "            df_segments = ddoc.getSegmentsForUUID(e_uuid)\n",
    "            i_frame_stim_begin = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_begin.iloc[0] - 1\n",
    "            i_frame_stim_end = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_end.iloc[0] - 1  # in 1 indexing, inclusive\n",
    "        else:  # in tmev recordings, there is no stim, but it is the seizure segment (see value_mapping)\n",
    "            metadata_dict = traces_meta_dict[e_uuid]\n",
    "            i_frame_stim_begin = metadata_dict[\"n_bl_frames\"]\n",
    "            i_frame_stim_end = metadata_dict[\"n_frames\"] - metadata_dict[\"n_am_frames\"]\n",
    "            \n",
    "\n",
    "        # add vlines marking the two windows\n",
    "        i_sz_begin, i_sd_begin = dict_begin_end_frames[e_uuid]\n",
    "        n_segment_frames = int(i_sd_begin - i_sz_begin)\n",
    "        \n",
    "        if e_uuid == \"f0442bebcd1a4291a8d0559eb47df08e\":\n",
    "            print(n_segment_frames)\n",
    "        t = traces_dict[e_uuid][\"lv_t_s\"]\n",
    "        t = t - t[0]\n",
    "\n",
    "        sz_stats = df_stats[(df_stats[\"event_uuid\"] == e_uuid) & (df_stats[\"segment_type\"] == \"sz\")].iloc[0]\n",
    "        sd_stats = df_stats[(df_stats[\"event_uuid\"] == e_uuid) & (df_stats[\"segment_type\"] == \"sd\")].iloc[0]\n",
    "\n",
    "        \n",
    "        \n",
    "        labview_trace = traces_dict[e_uuid][\"lv_speed\"]\n",
    "        min_lv = min(labview_trace)\n",
    "        max_lv = max(labview_trace)\n",
    "\n",
    "        mean_fluo = traces_dict[e_uuid][\"mean_fluo\"]\n",
    "        min_fluo = min(mean_fluo)\n",
    "        max_fluo = max(mean_fluo)\n",
    "        mean_fluo = 0.95*AMPLITUDE*(mean_fluo - min_fluo)/(max_fluo - min_fluo)\n",
    "\n",
    "        plt.vlines([t[i_sz_begin], t[i_sd_begin], t[i_sd_begin+n_segment_frames]], offset, offset+2*AMPLITUDE, color=\"black\", linestyle=\"-\")\n",
    "        plt.text(t[i_sz_begin], offset+0.2*AMPLITUDE, f'd={sz_stats[\"totdist_abs\"]:.3f}, {sz_stats[\"running%\"]:.2f}%, eps={sz_stats[\"running_episodes\"]} mean {sz_stats[\"running_episodes_mean_length\"]:.2f},\\nv={sz_stats[\"avg_speed\"]:.3f}', fontsize=10, color=\"red\")\n",
    "        plt.text(t[i_sd_begin+60], offset+0.2*AMPLITUDE, f'd={sd_stats[\"totdist_abs\"]:.3f}, {sd_stats[\"running%\"]:.2f}%, eps={sd_stats[\"running_episodes\"]} mean {sd_stats[\"running_episodes_mean_length\"]:.2f},\\nv={sd_stats[\"avg_speed\"]:.3f}, uuid: {e_uuid}', fontsize=10, color=\"red\")\n",
    "\n",
    "        t = t[i_sz_begin-30:i_sd_begin+n_segment_frames+30]\n",
    "        mean_fluo = mean_fluo[i_sz_begin-30:i_sd_begin+n_segment_frames+30]\n",
    "        labview_trace = labview_trace[i_sz_begin-30:i_sd_begin+n_segment_frames+30]\n",
    "\n",
    "\n",
    "        color = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "        plt.plot(t, labview_trace - min_lv+offset, color=color)\n",
    "        offset +=AMPLITUDE\n",
    "        plt.plot(t, mean_fluo+offset, color=color)\n",
    "        offset +=1.3*AMPLITUDE\n",
    "\n",
    "\n",
    "plt.suptitle(exp_type, fontsize=22)\n",
    "#plt.axis(\"off\")\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"Time (s)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "#plt.xlim((300, 460))  # 250, 500\n",
    "if save_figs:\n",
    "    out_fpath = os.path.join(output_folder, f\"loco_tmev_sz-vs-sd_waterfall_{exp_type}_{output_dtime}{file_format}\")\n",
    "    plt.savefig(out_fpath,bbox_inches='tight', dpi=300)\n",
    "    print(f\"Saved as {out_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2p-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

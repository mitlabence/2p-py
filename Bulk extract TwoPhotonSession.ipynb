{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2007d7a6",
   "metadata": {},
   "source": [
    "# Bulk extract mean fluorescence and process labview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0494129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097300d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import labrotation.file_handling as fh\n",
    "import os\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results_folder = fh.open_dir(\"Choose folder to save results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_docu_folder = fh.open_dir(\"Open Data Documentation folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d77d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_2p_folder = fh.open_dir(\"Open matlab-2p folder\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b02c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docu_grp_files_list = []\n",
    "docu_seg_files_list = []\n",
    "dframes_grouping = []\n",
    "dframes_segmentation = []\n",
    "\n",
    "session_uuid = None\n",
    "for root, dirs, files in os.walk(data_docu_folder):\n",
    "    for name in files:\n",
    "        if \"grouping\" in name:\n",
    "            if \"~\" in name: # \"~\" on windows is used for temporary files that are opened in excel\n",
    "                docu_grp_files_list = []\n",
    "                docu_seg_files_list = []\n",
    "                dframes_grouping = []\n",
    "                dframes_segmentation = []\n",
    "                raise Exception(f\"Please close all excel files and try again. Found temporary file in:\\n{os.path.join(root, name)}\")\n",
    "            else:\n",
    "                fpath = os.path.join(root, name)\n",
    "                df = pd.read_excel(fpath)\n",
    "                docu_grp_files_list.append(fpath)\n",
    "                dframes_grouping.append(df)\n",
    "        elif \"segmentation\" in name:\n",
    "            if \"~\" in name: # \"~\" on windows is used for temporary files that are opened in excel\n",
    "                docu_grp_files_list = []\n",
    "                docu_seg_files_list = []\n",
    "                dframes_grouping = []\n",
    "                dframes_segmentation = []\n",
    "                raise Exception(f\"Please close all excel files and try again. Found temporary file in:\\n{os.path.join(root, name)}\")\n",
    "            else:\n",
    "                fpath = os.path.join(root, name)\n",
    "                df = pd.read_excel(fpath)\n",
    "                docu_seg_files_list.append(fpath)\n",
    "                dframes_segmentation.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32710605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping = pd.concat(dframes_grouping)\n",
    "df_segmentation = pd.concat(dframes_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21914cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iterrow in df_grouping.iterrows():  # tuple of (index, row)\n",
    "    i_row, row = iterrow\n",
    "    uuid = row[\"uuid\"]\n",
    "    export_h5fpath = os.path.join(export_results_folder, str(uuid) + \"_FluLoco.h5\")\n",
    "    \n",
    "    \n",
    "    if os.path.exists(export_h5fpath):\n",
    "        print(f\"Results file for {uuid} already exists; skipping session.\")\n",
    "        continue\n",
    "    if type(row[\"nd2\"]) is not float:  # NaN entries are of type float\n",
    "        nd2_fpath = os.path.join(row[\"folder\"], row[\"nd2\"])\n",
    "        assert os.path.exists(nd2_fpath)\n",
    "    else:\n",
    "        nd2_fpath = None\n",
    "    if type(row[\"labview\"]) is not float:  # NaN entries are of type float\n",
    "        labview_fpath = os.path.join(row[\"folder\"], row[\"labview\"])\n",
    "        labview_tstamps_fpath = os.path.join(row[\"folder\"], os.path.splitext(row[\"labview\"])[0] + \"time.txt\")  # infer labview timestamps file name\n",
    "        assert os.path.exists(labview_fpath)\n",
    "    else:\n",
    "        labview_fpath = None\n",
    "        labview_tstamps_fpath = None\n",
    "    if type(row[\"nikon_meta\"]) is not float:  # NaN entries are of type float\n",
    "        nikmeta_fpath = os.path.join(row[\"folder\"], row[\"nikon_meta\"])\n",
    "        assert os.path.exists(nikmeta_fpath)\n",
    "    else:\n",
    "        nikmeta_fpath = None\n",
    "    if type(row[\"lfp\"]) is not float:  # NaN entries are of type float\n",
    "        lfp_fpath = os.path.join(row[\"folder\"], row[\"lfp\"])\n",
    "        assert os.path.exists(lfp_fpath)\n",
    "    else:\n",
    "        lfp_fpath = None\n",
    "    \n",
    "    has_nd2 = \" \" if nd2_fpath is None else \"x\"\n",
    "    has_lv = \" \" if labview_fpath is None else \"x\"\n",
    "    has_nikmeta = \" \" if nikmeta_fpath is None else \"x\"\n",
    "    has_lfp = \" \" if lfp_fpath is None else \"x\"\n",
    "    print(f\"{uuid}\\nnd2: [{has_nd2}] lv: [{has_lv}] nik ts: [{has_nikmeta}] lfp: [{has_lfp}]\")\n",
    "    \n",
    "    experiment_type = row[\"experiment_type\"]\n",
    "    \n",
    "    \n",
    "    # process labview data (if present)\n",
    "    ses = tps.TwoPhotonSession.init_and_process(nd2_path=nd2_fpath, nd2_timestamps_path=nikmeta_fpath, labview_path=labview_fpath, labview_timestamps_path = labview_tstamps_fpath, lfp_path = lfp_fpath, matlab_2p_folder=matlab_2p_folder)\n",
    "    \n",
    "    # extract mean fluorescence signal\n",
    "    if nd2_fpath is not None:\n",
    "        mean_fluo = ses.return_nikon_mean()\n",
    "    \n",
    "    \n",
    "    delete_file = True\n",
    "    try:\n",
    "        with h5py.File(export_h5fpath, 'w') as hf:\n",
    "            hf.attrs[\"uuid\"] = uuid\n",
    "            if nd2_fpath is not None:\n",
    "                hf.create_dataset(\"mean_fluo\", data=mean_fluo)\n",
    "                if labview_fpath is not None:  # matching of Nikon and LabView can only happen if nd2 recording AND labview recording exist.\n",
    "                    # Do not write NaN or pupil/reward/airpuff-related data, as we are not using them.\n",
    "                    hf.create_dataset(\"round\", data=ses.belt_dict[\"round\"])\n",
    "                    hf.create_dataset(\"speed\", data=ses.belt_dict[\"speed\"])            \n",
    "                    hf.create_dataset(\"distance\", data=ses.belt_dict[\"distance\"])            \n",
    "                    hf.create_dataset(\"distancePR\", data=ses.belt_dict[\"distancePR\"])            \n",
    "                    hf.create_dataset(\"reflect\", data=ses.belt_dict[\"reflect\"])            \n",
    "                    hf.create_dataset(\"licking\", data=ses.belt_dict[\"licking\"])            \n",
    "                    hf.create_dataset(\"stripes\", data=ses.belt_dict[\"stripes\"])   \n",
    "                    hf.create_dataset(\"stripesPR\", data=ses.belt_dict[\"stripesPR\"])            \n",
    "                    hf.create_dataset(\"time\", data=ses.belt_dict[\"time\"])            \n",
    "                    hf.create_dataset(\"timePR\", data=ses.belt_dict[\"timePR\"])            \n",
    "                    hf.create_dataset(\"tsscn\", data=ses.belt_dict[\"tsscn\"])  \n",
    "                    hf.create_dataset(\"running\", data=ses.belt_dict[\"running\"])            \n",
    "                    hf.create_dataset(\"runtime\", data=ses.belt_dict[\"runtime\"])  # Warning: empty dataset if the mouse did not run\n",
    "\n",
    "                    hf.create_dataset(\"running_scn\", data=ses.belt_scn_dict[\"running\"])\n",
    "                    hf.create_dataset(\"round_scn\", data=ses.belt_scn_dict[\"rounds\"])\n",
    "                    hf.create_dataset(\"speed_scn\", data=ses.belt_scn_dict[\"speed\"])\n",
    "                    hf.create_dataset(\"totdistscn\", data=ses.belt_scn_dict[\"totdist\"])\n",
    "                    hf.create_dataset(\"distance_scn\", data=ses.belt_scn_dict[\"distance\"])\n",
    "                \n",
    "        delete_file = False\n",
    "        print(f\"Saved file {export_h5fpath}.\")\n",
    "    finally:  # TODO: improve this handling of errors by looking up what kind of errors happen in try block\n",
    "        if delete_file and os.path.exists(export_h5fpath):\n",
    "            print(f\"Attempting to delete incomplete file {export_h5fpath}...\")\n",
    "            os.remove(export_h5fpath)\n",
    "            print(f\"Success.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iterrow in df_grouping.iterrows():  # tuple of (index, row)\n",
    "    i_row, row = iterrow\n",
    "    uuid = row[\"uuid\"]\n",
    "    export_h5fpath = os.path.join(export_results_folder, str(uuid) + \"_tps.h5\")\n",
    "    \n",
    "    if os.path.exists(export_h5fpath):\n",
    "        print(f\"Results file for {uuid} already exists; skipping session.\")\n",
    "        continue\n",
    "    if type(row[\"nd2\"]) is not float:  # NaN entries are of type float\n",
    "        nd2_fpath = os.path.join(row[\"folder\"], row[\"nd2\"])\n",
    "        assert os.path.exists(nd2_fpath)\n",
    "    else:\n",
    "        nd2_fpath = None\n",
    "    if type(row[\"labview\"]) is not float:  # NaN entries are of type float\n",
    "        labview_fpath = os.path.join(row[\"folder\"], row[\"labview\"])\n",
    "        labview_tstamps_fpath = os.path.join(row[\"folder\"], os.path.splitext(row[\"labview\"])[0] + \"time.txt\")  # infer labview timestamps file name\n",
    "        assert os.path.exists(labview_fpath)\n",
    "    else:\n",
    "        labview_fpath = None\n",
    "        labview_tstamps_fpath = None\n",
    "    if type(row[\"nikon_meta\"]) is not float:  # NaN entries are of type float\n",
    "        nikmeta_fpath = os.path.join(row[\"folder\"], row[\"nikon_meta\"])\n",
    "        assert os.path.exists(nikmeta_fpath)\n",
    "    else:\n",
    "        nikmeta_fpath = None\n",
    "    if type(row[\"lfp\"]) is not float:  # NaN entries are of type float\n",
    "        lfp_fpath = os.path.join(row[\"folder\"], row[\"lfp\"])\n",
    "        assert os.path.exists(lfp_fpath)\n",
    "    else:\n",
    "        lfp_fpath = None\n",
    "    \n",
    "    has_nd2 = \" \" if nd2_fpath is None else \"x\"\n",
    "    has_lv = \" \" if labview_fpath is None else \"x\"\n",
    "    has_nikmeta = \" \" if nikmeta_fpath is None else \"x\"\n",
    "    has_lfp = \" \" if lfp_fpath is None else \"x\"\n",
    "    print(f\"{uuid}\\nnd2: [{has_nd2}] lv: [{has_lv}] nik ts: [{has_nikmeta}] lfp: [{has_lfp}]\")\n",
    "    \n",
    "    experiment_type = row[\"experiment_type\"]\n",
    "    \n",
    "    \n",
    "    # process labview data (if present)\n",
    "    ses = tps.TwoPhotonSession.init_and_process(nd2_path=nd2_fpath, nd2_timestamps_path=nikmeta_fpath, labview_path=labview_fpath, labview_timestamps_path = labview_tstamps_fpath, lfp_path = lfp_fpath, matlab_2p_folder=matlab_2p_folder, uuid=uuid)\n",
    "    \n",
    "    delete_file = True\n",
    "    try:\n",
    "        ses.export_hdf5(fpath=export_h5fpath)\n",
    "        delete_file = False\n",
    "        print(f\"Saved file {export_h5fpath}.\")\n",
    "    finally:  # TODO: improve this handling of errors by looking up what kind of errors happen when saving to hdf5\n",
    "        if delete_file and os.path.exists(export_h5fpath):\n",
    "            print(f\"Attempting to delete incomplete file {export_h5fpath}...\")\n",
    "            os.remove(export_h5fpath)\n",
    "            print(f\"Success.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = df_grouping.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbf8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_nd2_fpath = os.path.join(example_row[\"folder\"], example_row[\"nd2\"])\n",
    "ex_labview_fpath = os.path.join(example_row[\"folder\"], example_row[\"labview\"])\n",
    "ex_nikmeta_fpath = os.path.join(example_row[\"folder\"], example_row[\"nikon_meta\"])\n",
    "ex_labview_tstamps_fpath = os.path.join(example_row[\"folder\"], os.path.splitext(example_row[\"labview\"])[0] + \"time.txt\")\n",
    "if type(example_row[\"lfp\"]) is not float:\n",
    "    ex_lfp_fpath = os.path.join(example_row[\"folder\"], example_row[\"lfp\"])\n",
    "else:\n",
    "    ex_lfp_fpath = None\n",
    "ex_experiment_type = example_row[\"experiment_type\"]\n",
    "ex_uuid = example_row[\"uuid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses = tps.TwoPhotonSession.init_and_process(nd2_path=ex_nd2_fpath, nd2_timestamps_path=ex_nikmeta_fpath, labview_path=ex_labview_fpath, labview_timestamps_path = ex_labview_tstamps_fpath, lfp_path = ex_lfp_fpath, matlab_2p_folder=matlab_2p_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8726dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses.belt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20963d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses.belt_scn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses.belt_dict[\"runtime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010cf43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2007d7a6",
   "metadata": {},
   "source": [
    "# Bulk extract mean fluorescence and process labview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0494129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "097300d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import labrotation.file_handling as fh\n",
    "import os\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76c03b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results_folder = fh.open_dir(\"Choose folder to save results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0776d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_docu_folder = fh.open_dir(\"Open Data Documentation folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d77d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_2p_folder = fh.open_dir(\"Open matlab-2p folder\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b02c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docu_grp_files_list = []\n",
    "docu_seg_files_list = []\n",
    "dframes_grouping = []\n",
    "dframes_segmentation = []\n",
    "\n",
    "session_uuid = None\n",
    "for root, dirs, files in os.walk(data_docu_folder):\n",
    "    for name in files:\n",
    "        if \"grouping\" in name:\n",
    "            if \"~\" in name: # \"~\" on windows is used for temporary files that are opened in excel\n",
    "                docu_grp_files_list = []\n",
    "                docu_seg_files_list = []\n",
    "                dframes_grouping = []\n",
    "                dframes_segmentation = []\n",
    "                raise Exception(f\"Please close all excel files and try again. Found temporary file in:\\n{os.path.join(root, name)}\")\n",
    "            else:\n",
    "                fpath = os.path.join(root, name)\n",
    "                df = pd.read_excel(fpath)\n",
    "                docu_grp_files_list.append(fpath)\n",
    "                dframes_grouping.append(df)\n",
    "        elif \"segmentation\" in name:\n",
    "            if \"~\" in name: # \"~\" on windows is used for temporary files that are opened in excel\n",
    "                docu_grp_files_list = []\n",
    "                docu_seg_files_list = []\n",
    "                dframes_grouping = []\n",
    "                dframes_segmentation = []\n",
    "                raise Exception(f\"Please close all excel files and try again. Found temporary file in:\\n{os.path.join(root, name)}\")\n",
    "            else:\n",
    "                fpath = os.path.join(root, name)\n",
    "                df = pd.read_excel(fpath)\n",
    "                docu_seg_files_list.append(fpath)\n",
    "                dframes_segmentation.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32710605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping = pd.concat(dframes_grouping)\n",
    "df_segmentation = pd.concat(dframes_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8f21f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>nd2</th>\n",
       "      <th>labview</th>\n",
       "      <th>lfp</th>\n",
       "      <th>face_cam_last</th>\n",
       "      <th>nikon_meta</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>day</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1</td>\n",
       "      <td>T301_base_d1.180820.1614.nd2</td>\n",
       "      <td>T301_base_d1.180820.1614.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T301_base_d1.180820.1614_2.avi</td>\n",
       "      <td>T301_base_d1.180820.1614_nik.txt</td>\n",
       "      <td>tmev_bl</td>\n",
       "      <td>bl1</td>\n",
       "      <td>3183503d487f428fbbfe3b8bb4fb2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1</td>\n",
       "      <td>T301_base_d1.180820.1636.nd2</td>\n",
       "      <td>T301_base_d1.180820.1636.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T301_base_d1.180820.1636_2.avi</td>\n",
       "      <td>T301_base_d1.180820.1636_nik.txt</td>\n",
       "      <td>tmev_bl</td>\n",
       "      <td>bl1</td>\n",
       "      <td>3bc014442e4f42cbaf7f24ec71508b6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1</td>\n",
       "      <td>T301_dual_color_zstack_01.nd2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tmev_stack_dual_2</td>\n",
       "      <td>bl1</td>\n",
       "      <td>1b22fe5249484fe59c5cf24591ba5fd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1</td>\n",
       "      <td>T301_dual_color_zstack_02.nd2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tmev_stack_dual_8</td>\n",
       "      <td>bl1</td>\n",
       "      <td>89eac973f25b4d4a9db404cae5ef3f10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1</td>\n",
       "      <td>T301_dual_color_tseries_2min.nd2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fov_dual</td>\n",
       "      <td>bl1</td>\n",
       "      <td>c5f402a018cc4359b5cdb80586102647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      folder  \\\n",
       "0  Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1   \n",
       "1  Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1   \n",
       "2  Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1   \n",
       "3  Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1   \n",
       "4  Y:\\AG-Wenzel\\Group\\tmev\\T301\\T301_base_d1   \n",
       "\n",
       "                                nd2                       labview  lfp  \\\n",
       "0      T301_base_d1.180820.1614.nd2  T301_base_d1.180820.1614.txt  NaN   \n",
       "1      T301_base_d1.180820.1636.nd2  T301_base_d1.180820.1636.txt  NaN   \n",
       "2     T301_dual_color_zstack_01.nd2                           NaN  NaN   \n",
       "3     T301_dual_color_zstack_02.nd2                           NaN  NaN   \n",
       "4  T301_dual_color_tseries_2min.nd2                           NaN  NaN   \n",
       "\n",
       "                    face_cam_last                        nikon_meta  \\\n",
       "0  T301_base_d1.180820.1614_2.avi  T301_base_d1.180820.1614_nik.txt   \n",
       "1  T301_base_d1.180820.1636_2.avi  T301_base_d1.180820.1636_nik.txt   \n",
       "2                             NaN                               NaN   \n",
       "3                             NaN                               NaN   \n",
       "4                             NaN                               NaN   \n",
       "\n",
       "     experiment_type  day                              uuid  \n",
       "0            tmev_bl  bl1  3183503d487f428fbbfe3b8bb4fb2292  \n",
       "1            tmev_bl  bl1  3bc014442e4f42cbaf7f24ec71508b6b  \n",
       "2  tmev_stack_dual_2  bl1  1b22fe5249484fe59c5cf24591ba5fd0  \n",
       "3  tmev_stack_dual_8  bl1  89eac973f25b4d4a9db404cae5ef3f10  \n",
       "4           fov_dual  bl1  c5f402a018cc4359b5cdb80586102647  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21914cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results file for 171693d0988c458a96c8198c7b8cfc28 already exists; skipping session.\n",
      "Results file for a6099849121f44ccbec237037971ab57 already exists; skipping session.\n",
      "Results file for e40f26d410ab452e8f8d59e5394ae0fe already exists; skipping session.\n",
      "Results file for ae564f8c867f4f35aa971b6562c33a7c already exists; skipping session.\n",
      "Results file for 65bff16a4cf04930a5cb14f489a8f99b already exists; skipping session.\n",
      "Results file for 30dc55d1a5dc4b0286d132e72f208ca6 already exists; skipping session.\n",
      "Results file for d7a5ac8e2bc74382b3db503a6a5a07a5 already exists; skipping session.\n",
      "Results file for 5ea6fd9c4cb542dbbc1f65305725cede already exists; skipping session.\n",
      "Results file for 06ebcf354f5c41519669f187e16de364 already exists; skipping session.\n",
      "Results file for 73a27053f4bf4ae1b4ad96064b6dabc0 already exists; skipping session.\n",
      "Results file for 2aa75aa234a749668eb896e7e00aa87a already exists; skipping session.\n",
      "Results file for 79fb974821f34e3abdcf5ca650e1c0f4 already exists; skipping session.\n",
      "Results file for 4fe45b25dc854453880cd868fe77e9d4 already exists; skipping session.\n",
      "Results file for ba6bb6298c474451be3237a6afe7ffe9 already exists; skipping session.\n",
      "Results file for 8dd54649e47046239ebafc56eeb8b5b2 already exists; skipping session.\n",
      "Results file for 44ca941252064dcabb0fe3d24a8dab49 already exists; skipping session.\n",
      "Results file for 3dd896d33a0f42c698228fbe254ebd60 already exists; skipping session.\n",
      "Results file for a9694ce2973349cb9cb6b51f77c46b49 already exists; skipping session.\n",
      "Results file for b8f31023d2c042c2a7f95b54d9807cb7 already exists; skipping session.\n",
      "Results file for 757c430daa2349e198ddefa7a0277769 already exists; skipping session.\n",
      "Results file for 92062a977958443e83011619b34eabb8 already exists; skipping session.\n"
     ]
    }
   ],
   "source": [
    "uuids_sz = [\"171693d0988c458a96c8198c7b8cfc28\",\n",
    "\"171693d0988c458a96c8198c7b8cfc28\",\n",
    "\"a6099849121f44ccbec237037971ab57\",\n",
    "\"a6099849121f44ccbec237037971ab57\",\n",
    "\"a6099849121f44ccbec237037971ab57\",\n",
    "\"e40f26d410ab452e8f8d59e5394ae0fe\",\n",
    "\"e40f26d410ab452e8f8d59e5394ae0fe\",\n",
    "\"e40f26d410ab452e8f8d59e5394ae0fe\",\n",
    "\"ae564f8c867f4f35aa971b6562c33a7c\",\n",
    "\"ae564f8c867f4f35aa971b6562c33a7c\",\n",
    "\"ae564f8c867f4f35aa971b6562c33a7c\",\n",
    "\"65bff16a4cf04930a5cb14f489a8f99b\",\n",
    "\"30dc55d1a5dc4b0286d132e72f208ca6\",\n",
    "\"30dc55d1a5dc4b0286d132e72f208ca6\",\n",
    "\"30dc55d1a5dc4b0286d132e72f208ca6\",\n",
    "\"d7a5ac8e2bc74382b3db503a6a5a07a5\",\n",
    "\"d7a5ac8e2bc74382b3db503a6a5a07a5\",\n",
    "\"d7a5ac8e2bc74382b3db503a6a5a07a5\",\n",
    "\"5ea6fd9c4cb542dbbc1f65305725cede\",\n",
    "\"5ea6fd9c4cb542dbbc1f65305725cede\",\n",
    "\"5ea6fd9c4cb542dbbc1f65305725cede\",\n",
    "\"06ebcf354f5c41519669f187e16de364\",\n",
    "\"06ebcf354f5c41519669f187e16de364\",\n",
    "\"06ebcf354f5c41519669f187e16de364\",\n",
    "\"73a27053f4bf4ae1b4ad96064b6dabc0\",\n",
    "\"73a27053f4bf4ae1b4ad96064b6dabc0\",\n",
    "\"73a27053f4bf4ae1b4ad96064b6dabc0\",\n",
    "\"2aa75aa234a749668eb896e7e00aa87a\",\n",
    "\"2aa75aa234a749668eb896e7e00aa87a\",\n",
    "\"79fb974821f34e3abdcf5ca650e1c0f4\",\n",
    "\"79fb974821f34e3abdcf5ca650e1c0f4\",\n",
    "\"79fb974821f34e3abdcf5ca650e1c0f4\",\n",
    "\"4fe45b25dc854453880cd868fe77e9d4\",\n",
    "\"4fe45b25dc854453880cd868fe77e9d4\",\n",
    "\"4fe45b25dc854453880cd868fe77e9d4\",\n",
    "\"4fe45b25dc854453880cd868fe77e9d4\",\n",
    "\"4fe45b25dc854453880cd868fe77e9d4\",\n",
    "\"4fe45b25dc854453880cd868fe77e9d4\",\n",
    "\"ba6bb6298c474451be3237a6afe7ffe9\",\n",
    "\"ba6bb6298c474451be3237a6afe7ffe9\",\n",
    "\"ba6bb6298c474451be3237a6afe7ffe9\",\n",
    "\"8dd54649e47046239ebafc56eeb8b5b2\",\n",
    "\"44ca941252064dcabb0fe3d24a8dab49\",\n",
    "\"3dd896d33a0f42c698228fbe254ebd60\",\n",
    "\"a9694ce2973349cb9cb6b51f77c46b49\",\n",
    "\"b8f31023d2c042c2a7f95b54d9807cb7\",\n",
    "\"757c430daa2349e198ddefa7a0277769\",\n",
    "\"92062a977958443e83011619b34eabb8\"]\n",
    "\n",
    "for iterrow in df_grouping.iterrows():  # tuple of (index, row)\n",
    "    i_row, row = iterrow\n",
    "    uuid = row[\"uuid\"]\n",
    "    if uuid not in uuids_sz:\n",
    "        continue\n",
    "    export_h5fpath = os.path.join(export_results_folder, str(uuid) + \"_FluLoco.h5\")\n",
    "    \n",
    "    \n",
    "    if os.path.exists(export_h5fpath):\n",
    "        print(f\"Results file for {uuid} already exists; skipping session.\")\n",
    "        continue\n",
    "    if type(row[\"nd2\"]) is not float:  # NaN entries are of type float\n",
    "        nd2_fpath = os.path.join(row[\"folder\"], row[\"nd2\"])\n",
    "        assert os.path.exists(nd2_fpath)\n",
    "    else:\n",
    "        nd2_fpath = None\n",
    "    if type(row[\"labview\"]) is not float:  # NaN entries are of type float\n",
    "        labview_fpath = os.path.join(row[\"folder\"], row[\"labview\"])\n",
    "        labview_tstamps_fpath = os.path.join(row[\"folder\"], os.path.splitext(row[\"labview\"])[0] + \"time.txt\")  # infer labview timestamps file name\n",
    "        assert os.path.exists(labview_fpath)\n",
    "    else:\n",
    "        labview_fpath = None\n",
    "        labview_tstamps_fpath = None\n",
    "    if type(row[\"nikon_meta\"]) is not float:  # NaN entries are of type float\n",
    "        nikmeta_fpath = os.path.join(row[\"folder\"], row[\"nikon_meta\"])\n",
    "        assert os.path.exists(nikmeta_fpath)\n",
    "    else:\n",
    "        nikmeta_fpath = None\n",
    "    if type(row[\"lfp\"]) is not float:  # NaN entries are of type float\n",
    "        lfp_fpath = os.path.join(row[\"folder\"], row[\"lfp\"])\n",
    "        assert os.path.exists(lfp_fpath)\n",
    "    else:\n",
    "        lfp_fpath = None\n",
    "    \n",
    "    has_nd2 = \" \" if nd2_fpath is None else \"x\"\n",
    "    has_lv = \" \" if labview_fpath is None else \"x\"\n",
    "    has_nikmeta = \" \" if nikmeta_fpath is None else \"x\"\n",
    "    has_lfp = \" \" if lfp_fpath is None else \"x\"\n",
    "    print(f\"{uuid}\\nnd2: [{has_nd2}] lv: [{has_lv}] nik ts: [{has_nikmeta}] lfp: [{has_lfp}]\")\n",
    "    \n",
    "    experiment_type = row[\"experiment_type\"]\n",
    "    \n",
    "    \n",
    "    # process labview data (if present)\n",
    "    ses = tps.TwoPhotonSession.init_and_process(nd2_path=nd2_fpath, nd2_timestamps_path=nikmeta_fpath, labview_path=labview_fpath, labview_timestamps_path = labview_tstamps_fpath, lfp_path = lfp_fpath, matlab_2p_folder=matlab_2p_folder)\n",
    "    \n",
    "    # extract mean fluorescence signal\n",
    "    if nd2_fpath is not None:\n",
    "        mean_fluo = ses.return_nikon_mean()\n",
    "    \n",
    "    \n",
    "    delete_file = True\n",
    "    try:\n",
    "        with h5py.File(export_h5fpath, 'w') as hf:\n",
    "            hf.attrs[\"uuid\"] = uuid\n",
    "            if nd2_fpath is not None:\n",
    "                hf.create_dataset(\"mean_fluo\", data=mean_fluo)\n",
    "                if labview_fpath is not None:  # matching of Nikon and LabView can only happen if nd2 recording AND labview recording exist.\n",
    "                    # Do not write NaN or pupil/reward/airpuff-related data, as we are not using them.\n",
    "                    hf.create_dataset(\"round\", data=ses.belt_dict[\"round\"])\n",
    "                    hf.create_dataset(\"speed\", data=ses.belt_dict[\"speed\"])            \n",
    "                    hf.create_dataset(\"distance\", data=ses.belt_dict[\"distance\"])            \n",
    "                    hf.create_dataset(\"distancePR\", data=ses.belt_dict[\"distancePR\"])            \n",
    "                    hf.create_dataset(\"reflect\", data=ses.belt_dict[\"reflect\"])            \n",
    "                    hf.create_dataset(\"licking\", data=ses.belt_dict[\"licking\"])            \n",
    "                    hf.create_dataset(\"stripes\", data=ses.belt_dict[\"stripes\"])   \n",
    "                    hf.create_dataset(\"stripesPR\", data=ses.belt_dict[\"stripesPR\"])            \n",
    "                    hf.create_dataset(\"time\", data=ses.belt_dict[\"time\"])            \n",
    "                    hf.create_dataset(\"timePR\", data=ses.belt_dict[\"timePR\"])            \n",
    "                    hf.create_dataset(\"tsscn\", data=ses.belt_dict[\"tsscn\"])  \n",
    "                    hf.create_dataset(\"running\", data=ses.belt_dict[\"running\"])            \n",
    "                    hf.create_dataset(\"runtime\", data=ses.belt_dict[\"runtime\"])  # Warning: empty dataset if the mouse did not run\n",
    "\n",
    "                    hf.create_dataset(\"running_scn\", data=ses.belt_scn_dict[\"running\"])\n",
    "                    hf.create_dataset(\"round_scn\", data=ses.belt_scn_dict[\"rounds\"])\n",
    "                    hf.create_dataset(\"speed_scn\", data=ses.belt_scn_dict[\"speed\"])\n",
    "                    hf.create_dataset(\"totdistscn\", data=ses.belt_scn_dict[\"totdist\"])\n",
    "                    hf.create_dataset(\"distance_scn\", data=ses.belt_scn_dict[\"distance\"])\n",
    "                \n",
    "        delete_file = False\n",
    "        print(f\"Saved file {export_h5fpath}.\")\n",
    "    finally:  # TODO: improve this handling of errors by looking up what kind of errors happen in try block\n",
    "        if delete_file and os.path.exists(export_h5fpath):\n",
    "            print(f\"Attempting to delete incomplete file {export_h5fpath}...\")\n",
    "            os.remove(export_h5fpath)\n",
    "            print(f\"Success.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iterrow in df_grouping.iterrows():  # tuple of (index, row)\n",
    "    i_row, row = iterrow\n",
    "    uuid = row[\"uuid\"]\n",
    "    export_h5fpath = os.path.join(export_results_folder, str(uuid) + \"_tps.h5\")\n",
    "    \n",
    "    if os.path.exists(export_h5fpath):\n",
    "        print(f\"Results file for {uuid} already exists; skipping session.\")\n",
    "        continue\n",
    "    if type(row[\"nd2\"]) is not float:  # NaN entries are of type float\n",
    "        nd2_fpath = os.path.join(row[\"folder\"], row[\"nd2\"])\n",
    "        assert os.path.exists(nd2_fpath)\n",
    "    else:\n",
    "        nd2_fpath = None\n",
    "    if type(row[\"labview\"]) is not float:  # NaN entries are of type float\n",
    "        labview_fpath = os.path.join(row[\"folder\"], row[\"labview\"])\n",
    "        labview_tstamps_fpath = os.path.join(row[\"folder\"], os.path.splitext(row[\"labview\"])[0] + \"time.txt\")  # infer labview timestamps file name\n",
    "        assert os.path.exists(labview_fpath)\n",
    "    else:\n",
    "        labview_fpath = None\n",
    "        labview_tstamps_fpath = None\n",
    "    if type(row[\"nikon_meta\"]) is not float:  # NaN entries are of type float\n",
    "        nikmeta_fpath = os.path.join(row[\"folder\"], row[\"nikon_meta\"])\n",
    "        assert os.path.exists(nikmeta_fpath)\n",
    "    else:\n",
    "        nikmeta_fpath = None\n",
    "    if type(row[\"lfp\"]) is not float:  # NaN entries are of type float\n",
    "        lfp_fpath = os.path.join(row[\"folder\"], row[\"lfp\"])\n",
    "        assert os.path.exists(lfp_fpath)\n",
    "    else:\n",
    "        lfp_fpath = None\n",
    "    \n",
    "    has_nd2 = \" \" if nd2_fpath is None else \"x\"\n",
    "    has_lv = \" \" if labview_fpath is None else \"x\"\n",
    "    has_nikmeta = \" \" if nikmeta_fpath is None else \"x\"\n",
    "    has_lfp = \" \" if lfp_fpath is None else \"x\"\n",
    "    print(f\"{uuid}\\nnd2: [{has_nd2}] lv: [{has_lv}] nik ts: [{has_nikmeta}] lfp: [{has_lfp}]\")\n",
    "    \n",
    "    experiment_type = row[\"experiment_type\"]\n",
    "    \n",
    "    \n",
    "    # process labview data (if present)\n",
    "    ses = tps.TwoPhotonSession.init_and_process(nd2_path=nd2_fpath, nd2_timestamps_path=nikmeta_fpath, labview_path=labview_fpath, labview_timestamps_path = labview_tstamps_fpath, lfp_path = lfp_fpath, matlab_2p_folder=matlab_2p_folder, uuid=uuid)\n",
    "    \n",
    "    delete_file = True\n",
    "    try:\n",
    "        ses.export_hdf5(fpath=export_h5fpath)\n",
    "        delete_file = False\n",
    "        print(f\"Saved file {export_h5fpath}.\")\n",
    "    finally:  # TODO: improve this handling of errors by looking up what kind of errors happen when saving to hdf5\n",
    "        if delete_file and os.path.exists(export_h5fpath):\n",
    "            print(f\"Attempting to delete incomplete file {export_h5fpath}...\")\n",
    "            os.remove(export_h5fpath)\n",
    "            print(f\"Success.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row = df_grouping.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbf8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_nd2_fpath = os.path.join(example_row[\"folder\"], example_row[\"nd2\"])\n",
    "ex_labview_fpath = os.path.join(example_row[\"folder\"], example_row[\"labview\"])\n",
    "ex_nikmeta_fpath = os.path.join(example_row[\"folder\"], example_row[\"nikon_meta\"])\n",
    "ex_labview_tstamps_fpath = os.path.join(example_row[\"folder\"], os.path.splitext(example_row[\"labview\"])[0] + \"time.txt\")\n",
    "if type(example_row[\"lfp\"]) is not float:\n",
    "    ex_lfp_fpath = os.path.join(example_row[\"folder\"], example_row[\"lfp\"])\n",
    "else:\n",
    "    ex_lfp_fpath = None\n",
    "ex_experiment_type = example_row[\"experiment_type\"]\n",
    "ex_uuid = example_row[\"uuid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cdf082",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses = tps.TwoPhotonSession.init_and_process(nd2_path=ex_nd2_fpath, nd2_timestamps_path=ex_nikmeta_fpath, labview_path=ex_labview_fpath, labview_timestamps_path = ex_labview_tstamps_fpath, lfp_path = ex_lfp_fpath, matlab_2p_folder=matlab_2p_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8726dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses.belt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20963d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses.belt_scn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses.belt_dict[\"runtime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8010cf43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

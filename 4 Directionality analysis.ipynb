{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6175bed9",
   "metadata": {},
   "source": [
    "# Directionality analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be2a2c",
   "metadata": {},
   "source": [
    "## Most important DataFrames and parameters\n",
    "DataFrames:\n",
    "* all_onsets_df: contains all neurons of all recordings, with onset and quantile values for each event (sz: quantile_sz, sd1: quantile1, sd2: quantile2)\n",
    "* quantiles_df: for each recording, contains all quantiles for each event type (quantile_type)\n",
    "* qdf: contains vectors (dx, dy) from first to last quantile centre for each event in all recordings\n",
    "* df_mean_vectors_per_mouse: contains Cartesian and polar coordinates of vectors for each event type, per mouse, averaged over each recording. Averaging: for one mouse, calculate center of first and last quantiles, create vector as difference; take the average of x and y coordinates of these vectors.\n",
    "* df_angles: contains seizure-sdx angles\n",
    "\n",
    "\n",
    "Columns:\n",
    "* quantile_type: sz, sd1 or sd2\n",
    "* onset_sz, onset1, onset2: the onset frame for each neuron/quantile for sz, sd1, sd2, respectively\n",
    "* dx, dy: The distance between the first and last quantile of <quantile_type> in pixels along the x or y axis, respectively.\n",
    "* uuid_extended: uuid if the recording contained one seizure; uuid + \"_1\"/\"_2\"/... for each event group (sz + sd waves) in that recording.\n",
    "* uuid_matched: manually correct uuid_extended to group seizure with sd waves that were split up by end of recording. This uuid should be unique among event groups (sz + sd waves), and the same for each group member.\n",
    "* theta_inj_top: the polar angle in a reference frame where the top side is the injection side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03957638",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True  # set to True to save the figures created\n",
    "save_as_eps = False\n",
    "if save_as_eps:\n",
    "    file_format = \".eps\"\n",
    "else:\n",
    "    file_format = \".jpg\"\n",
    "if save_figs:\n",
    "    print(f\"Going to save figures as {file_format} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d944e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d83ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from nd2_to_caiman import np_arr_from_nd2\n",
    "import labrotation.file_handling as fh\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib as mpl\n",
    "from math import floor, ceil, sqrt, atan2, acos, pi, sin, cos\n",
    "from datetime import datetime\n",
    "import json\n",
    "from labrotation import json_util\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.stats import circmean, circstd  # for statistical testing on directionality\n",
    "import datadoc_util\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import multiprocess as mp  # multiprocessing does not work with IPython. Use fork instead.\n",
    "import os\n",
    "import random  # for surrogate algorithm\n",
    "from collections.abc import Iterable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "color_palette = sns.color_palette(\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a123a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = datetime.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_shape = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72149579",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    data_docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    data_docu_folder = fh.open_dir(\"Open Data Documentation folder\")\n",
    "print(data_docu_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5e134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = datadoc_util.DataDocumentation(data_docu_folder)\n",
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = env_dict[\"DOWNLOADS_FOLDER\"]\n",
    "print(f\"Output files will be saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edacb9a",
   "metadata": {},
   "source": [
    "## Open files and get uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10288b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_uuid = ddoc.getIdUuid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_folder = fh.open_dir(\"Open directory with analysis (grid) data for all mice!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_files_list = []\n",
    "for root, dirs, files in os.walk(analysis_folder):\n",
    "    for fname in files:\n",
    "        if \"_grid.h5\" in fname:\n",
    "            grid_files_list.append(os.path.join(root,fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_dict = dict()\n",
    "for grid_fpath in grid_files_list:\n",
    "    # ..._grid.h5 -> ..._cnmf.hdf5\n",
    "    cnmf_fpath = os.path.join(os.path.split(grid_fpath)[0], os.path.split(grid_fpath)[-1][:-7] + \"cnmf.hdf5\")\n",
    "    with h5py.File(cnmf_fpath, 'r') as hf:\n",
    "        print(hf.attrs[\"uuid\"])\n",
    "        uuid_dict[grid_fpath] = hf.attrs[\"uuid\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f26fc6",
   "metadata": {},
   "source": [
    "## Combine all results into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_set = set()\n",
    "for fpath in grid_files_list:\n",
    "    df = pd.read_hdf(fpath)\n",
    "    for key in df.keys():\n",
    "        cols_set.add(key)\n",
    "cols_set.add(\"uuid\")\n",
    "cols_set.add(\"mouse_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32829f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining empty dataframe does not work, as all data types will be object (except x, y, which will be proper integers)\n",
    "all_onsets_df = pd.read_hdf(grid_files_list[0])\n",
    "all_onsets_df[\"uuid\"] = uuid_dict[grid_files_list[0]]\n",
    "all_onsets_df[\"mouse_id\"] = df_id_uuid[df_id_uuid[\"uuid\"] == uuid_dict[grid_files_list[0]]][\"mouse_id\"].values[0]\n",
    "\n",
    "assert all_onsets_df[\"uuid\"].isna().sum() == 0\n",
    "for fpath in grid_files_list[1:]:\n",
    "    df = pd.read_hdf(fpath)\n",
    "    df[\"uuid\"] = uuid_dict[fpath]\n",
    "    df[\"mouse_id\"] = df_id_uuid[df_id_uuid[\"uuid\"] == uuid_dict[fpath]][\"mouse_id\"].values[0]\n",
    "    assert df[\"uuid\"].isna().sum() == 0\n",
    "    all_onsets_df = pd.concat([all_onsets_df, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff7c804",
   "metadata": {},
   "source": [
    "### Make sure to have integer and float data types for the columns, and not object! (int16, int64, float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5243e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for old files containing onset data, n_seizures was not present, as one of the last recordings processed contained 2. \n",
    "# As a result, most of i_sz values are NaN; these contain 1 sz. Otherwise 0, 1... are the seizure indices.\n",
    "all_onsets_df[\"i_sz\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a262c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make seizures unique in uuid_extended\n",
    "def append_uuid(row):\n",
    "    if pd.isna(row['i_sz']):\n",
    "        return row['uuid']\n",
    "    elif row['i_sz'] >= 0:\n",
    "        return row['uuid'] + '_' + str(row[\"i_sz\"]+1)\n",
    "all_onsets_df['uuid_extended'] = all_onsets_df.apply(append_uuid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = all_onsets_df.groupby(\"mouse_id\")\n",
    "for group in g:\n",
    "    print(group[0])\n",
    "    g2 = group[1].groupby(\"uuid\")\n",
    "    for grp in g2:\n",
    "        print(\"\\t\" + grp[0])\n",
    "        print(\"\\t\" + str(len(grp[1])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d5842",
   "metadata": {},
   "source": [
    "`all_onsets_df` now contains each recording with seizure and/or SD each neuron. For each neuron, there is a value for onset of each SD and seizure wave (NaN for all neurons in a session if none occurred in the recording) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ecd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: check last missing recording for T333. Try matching neurons per recording?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b982d1",
   "metadata": {},
   "source": [
    "## Observe quartiles in one session, one event, per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUSE_ID=\"T352\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement easy way to pick a mouse and a specific sd/sz\n",
    "plot_quantiles = False\n",
    "if plot_quantiles:\n",
    "    uuids = all_onsets_df[\"uuid_extended\"].unique()\n",
    "    selected_uuid = uuids[3]\n",
    "    selected_df = all_onsets_df[all_onsets_df[\"uuid\"] == selected_uuid]\n",
    "    event_type = \"quantile_sz\"#\"quantile1\"\n",
    "\n",
    "    fig = plt.figure(figsize=(18,18), )\n",
    "    plt.suptitle(f\"Top={ddoc.getTopDirection(MOUSE_ID)}\", fontsize=24)\n",
    "    ax = plt.gca()\n",
    "    sns.scatterplot(x=\"x\", y=\"y\",\n",
    "                    hue=event_type, style=event_type, size=event_type,\n",
    "                    sizes=(100,400),\n",
    "                    data=selected_df, ax=ax,)\n",
    "\n",
    "    ax.set_xlim((0, 512))\n",
    "    ax.set_ylim((0,512))\n",
    "    ax.legend(fontsize=20)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d69bd59",
   "metadata": {},
   "source": [
    "## Get quantiles of recruitment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b845878",
   "metadata": {},
   "source": [
    "### Average coordinates per quartile per session (per mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_per_session = all_onsets_df.groupby([\"mouse_id\", \"uuid_extended\", \"quantile1\"], as_index=False)  # NaN quantile_sz values already dropped\n",
    "q_sd1_df = quantile_per_session.mean()\n",
    "q_sd1_df[\"quantile_type\"] = \"sd1\"\n",
    "q_sd1_df.rename({\"quantile1\": \"quantile\"}, axis=\"columns\", inplace=True)\n",
    "print(q_sd1_df.columns)\n",
    "\n",
    "quantile_per_session = all_onsets_df.groupby([\"mouse_id\", \"uuid_extended\", \"quantile2\"], as_index=False)  # NaN quantile_sz values already dropped\n",
    "q_sd2_df = quantile_per_session.mean()\n",
    "q_sd2_df[\"quantile_type\"] = \"sd2\"\n",
    "q_sd2_df.rename({\"quantile2\": \"quantile\"}, axis=\"columns\", inplace=True)\n",
    "\n",
    "\n",
    "quantile_per_session = all_onsets_df.groupby([\"mouse_id\", \"uuid_extended\", \"quantile_sz\"], as_index=False)\n",
    "q_sz_df = quantile_per_session.mean()\n",
    "q_sz_df[\"quantile_type\"] = \"sz\"\n",
    "q_sz_df.rename({\"quantile_sz\": \"quantile\"}, axis=\"columns\", inplace=True)\n",
    "\n",
    "\n",
    "quantiles_df = pd.concat([q_sd1_df, q_sd2_df, q_sz_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bcc1d8",
   "metadata": {},
   "source": [
    "### Inspect centre point of quantiles per mouse and per event type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092596af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.getMouseWinInjInfo(\"T352\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ebe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUSE_ID = \"T352\"\n",
    "EVENT_TYPE = \"sd2\"\n",
    "\n",
    "fig = plt.figure(figsize=(10,10), )\n",
    "plt.suptitle(f\"Top={ddoc.getTopDirection(MOUSE_ID)}\", fontsize=24)\n",
    "ax = plt.gca()\n",
    "sns.scatterplot(x=\"x\", y=\"y\",\n",
    "                hue=\"quantile\", style=\"quantile\", size=\"quantile\",\n",
    "                sizes=(100,400),\n",
    "                data=quantiles_df[(quantiles_df[\"mouse_id\"] == MOUSE_ID) & (quantiles_df[\"quantile_type\"] == EVENT_TYPE)], ax=ax,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.set_xlim((0, 512))\n",
    "ax.set_ylim((0,512))\n",
    "ax.legend(fontsize=20)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for each quantile, plot cells, k-means clustering? This way, can figure out if there might be more than two clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce80f42c",
   "metadata": {},
   "source": [
    "# Vectorize directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ca5fc",
   "metadata": {},
   "source": [
    "## Get vectorial difference of last minus first quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3720ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move from nd2/video-style coordinate system (top left = (0, 0)) to usual plotting coordinate style (bottom left = (0, 0))\n",
    "quantiles_df[\"y_mirrored\"]= quantiles_df.apply(lambda row: -1*row[\"y\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33beb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dx(df, colname=\"x\"):\n",
    "    max_quantile = df[\"quantile\"].max()\n",
    "    min_quantile = df[\"quantile\"].min()\n",
    "    x1 = df[df[\"quantile\"] == max_quantile][colname].values[0]\n",
    "    x0 = df[df[\"quantile\"] == min_quantile][colname].values[0]\n",
    "    return x1-x0\n",
    "\n",
    "# add dx and dy columns by finding for each session, each event (sd1, sd2, sz), the average x coordinate of each first and last quantiles, and producing the difference.\n",
    "qdf = quantiles_df.groupby([\"uuid_extended\", \"quantile_type\"], as_index=False).apply(lambda group_df: group_df.assign(dx=lambda gdf: get_dx(gdf, \"x\"), dy=lambda gdf: get_dx(gdf, \"y_mirrored\")))#[[\"mouse_id\", \"uuid\",\"dx\", \"dy\", \"quantile_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf[qdf[\"uuid_extended\"] == \"06ebcf354f5c41519669f187e16de364\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44984691",
   "metadata": {},
   "source": [
    "## Reshape dataframe\n",
    "Due to the way the vectors were calculated, each quantile per session has the same dx and dy values. Throw away duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf = qdf[qdf[\"quantile\"] == 0].drop(labels=[\"quantile\", \"x\", \"y\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be8461",
   "metadata": {},
   "source": [
    "## Add polar coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_change_dict = {\"bottom\": -1, \"top\": 1}  # for contralateral injections, injection is always on the medial side of the window\n",
    "qdf[\"r\"] = qdf.apply(lambda row: sqrt(pow(row[\"dx\"], 2) + pow(row[\"dy\"], 2)), axis=1)\n",
    "qdf[\"theta\"] = qdf.apply(lambda row: atan2(row[\"dy\"], row[\"dx\"]), axis=1)\n",
    "# correct angle s.t. top direction is always towards injection\n",
    "qdf[\"theta_inj_top\"] = qdf.apply(lambda row: sign_change_dict[ddoc.getInjectionDirection(row[\"mouse_id\"])]*row[\"theta\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adjust directions by getting mouse window size..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ceba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5) \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# Set up a grid of axes with a polar projection\n",
    "g = sns.FacetGrid(qdf, col=\"mouse_id\", hue=\"quantile_type\",\n",
    "                  subplot_kws=dict(projection='polar'), aspect=1, height=7,\n",
    "                  sharex=True, sharey=True, despine=False)\n",
    "\n",
    "# Draw a scatterplot onto each axes in the grid\n",
    "g.map(sns.scatterplot, \"theta\", \"r\", s=200, alpha=0.7)\n",
    "plt.gca().set_rlim(0, 350)\n",
    "\n",
    "g.add_legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb29a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5) \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# Set up a grid of axes with a polar projection\n",
    "g = sns.FacetGrid(qdf, col=\"mouse_id\", hue=\"quantile_type\",\n",
    "                  subplot_kws=dict(projection='polar'), aspect=1, height=7,\n",
    "                  sharex=True, sharey=True, despine=False)\n",
    "\n",
    "# Draw a scatterplot onto each axes in the grid\n",
    "g.map(sns.scatterplot, \"theta_inj_top\", \"r\", s=200, alpha=0.7)\n",
    "plt.gca().set_rlim(0, 350)\n",
    "\n",
    "g.add_legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfef3f",
   "metadata": {},
   "source": [
    "## Create sd-sz vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e74780",
   "metadata": {},
   "source": [
    "### Handle seizures that were split in two (sz onset in one session, sd waves in other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf[\"uuid_matched\"] = qdf[\"uuid_extended\"]\n",
    "# following two recordings contain 1 seizure-sd event\n",
    "qdf[\"uuid_matched\"] = qdf[\"uuid_matched\"].replace(\"65bff16a4cf04930a5cb14f489a8f99b\", \"30dc55d1a5dc4b0286d132e72f208ca6\")\n",
    "# following recordings do not have sz\n",
    "qdf = qdf[qdf[\"uuid_matched\"] != \"171693d0988c458a96c8198c7b8cfc28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7f16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_dict = {\"mouse_id\": [], \"uuid_matched\": [], \"quantile_type\": [], \"angle_with_sz\": [], \"cos_angle_with_sz\": []}\n",
    "angles_dict_v2 = {\"mouse_id\": [], \"uuid_matched\": [], \"angle_type\": [], \"angle\": [], \"cos_angle\": []} # keep backwards compatibility, but angle_with_sz is not flexible for example if want to look at sd1-sd2 angle\n",
    "\n",
    "session_groups = qdf.groupby(\"uuid_matched\")\n",
    "for uuid, group in session_groups:\n",
    "    sz_row = group[group[\"quantile_type\"] == \"sz\"]\n",
    "    sd1_row = group[group[\"quantile_type\"] == \"sd1\"]\n",
    "    sd2_row = group[group[\"quantile_type\"] == \"sd2\"]\n",
    "    \n",
    "    sz_len = sz_row[\"r\"].values[0] if len(sz_row[\"r\"].values) > 0 else np.nan\n",
    "    sd1_len = sd1_row[\"r\"].values[0] if len(sd1_row[\"r\"].values) > 0 else np.nan\n",
    "    sd2_len = sd2_row[\"r\"].values[0] if len(sd2_row[\"r\"].values) > 0 else np.nan\n",
    "    # u.v = |u|*|v|*cos(theta)\n",
    "    if len(sz_row[\"dx\"].values) > 0 and len(sd1_row[\"dx\"].values) > 0:\n",
    "        sz_dot_sd1 = sz_row[\"dx\"].values[0] * sd1_row[\"dx\"].values[0] + sz_row[\"dy\"].values[0] * sd1_row[\"dy\"].values[0]\n",
    "        costheta1 = sz_dot_sd1/(sz_len*sd1_len)\n",
    "    else:\n",
    "        sz_dot_sd1 = np.nan\n",
    "        costheta1 = np.nan\n",
    "    if len(sd2_row[\"dx\"].values) > 0 and len(sd1_row[\"dx\"].values) > 0: \n",
    "        sz_dot_sd2 = sz_row[\"dx\"].values[0] * sd2_row[\"dx\"].values[0] + sz_row[\"dy\"].values[0] * sd2_row[\"dy\"].values[0]\n",
    "        costheta2 = sz_dot_sd2/(sz_len*sd2_len)\n",
    "    else:\n",
    "        sz_dot_sd2 = np.nan\n",
    "        costheta2 = np.nan\n",
    "    \n",
    "    # add sd1-sd2 angle too\n",
    "    if len(sd1_row[\"dx\"].values) > 0 and len(sd2_row[\"dx\"].values) > 0:\n",
    "        sd1_dot_sd2 = sd1_row[\"dx\"].values[0] * sd2_row[\"dx\"].values[0] + sd1_row[\"dy\"].values[0] * sd2_row[\"dy\"].values[0]\n",
    "        costheta12 = sd1_dot_sd2/(sd1_len*sd2_len)\n",
    "    else:\n",
    "        sd1_dot_sd2 = np.nan\n",
    "        costheta12 = np.nan\n",
    "        \n",
    "    angles_dict[\"mouse_id\"].append(sz_row[\"mouse_id\"].values[0])\n",
    "    angles_dict[\"uuid_matched\"].append(uuid)\n",
    "    angles_dict[\"quantile_type\"].append(\"sd1\")\n",
    "    angles_dict[\"angle_with_sz\"].append(acos(costheta1))\n",
    "    angles_dict[\"cos_angle_with_sz\"].append(costheta1)\n",
    "    \n",
    "    angles_dict[\"mouse_id\"].append(sz_row[\"mouse_id\"].values[0])\n",
    "    angles_dict[\"uuid_matched\"].append(uuid)\n",
    "    angles_dict[\"quantile_type\"].append(\"sd2\")\n",
    "    angles_dict[\"angle_with_sz\"].append(acos(costheta2))\n",
    "    angles_dict[\"cos_angle_with_sz\"].append(costheta2)\n",
    "    \n",
    "    # sz-sd1\n",
    "    angles_dict_v2[\"mouse_id\"].append(sz_row[\"mouse_id\"].values[0])\n",
    "    angles_dict_v2[\"uuid_matched\"].append(uuid)\n",
    "    angles_dict_v2[\"angle_type\"].append(\"sz-sd1\")\n",
    "    angles_dict_v2[\"angle\"].append(acos(costheta1))\n",
    "    angles_dict_v2[\"cos_angle\"].append(costheta1)\n",
    "    # sz-sd2\n",
    "    angles_dict_v2[\"mouse_id\"].append(sz_row[\"mouse_id\"].values[0])\n",
    "    angles_dict_v2[\"uuid_matched\"].append(uuid)\n",
    "    angles_dict_v2[\"angle_type\"].append(\"sz-sd2\")\n",
    "    angles_dict_v2[\"angle\"].append(acos(costheta2))\n",
    "    angles_dict_v2[\"cos_angle\"].append(costheta2)    \n",
    "    # sd1-sd2\n",
    "    angles_dict_v2[\"mouse_id\"].append(sz_row[\"mouse_id\"].values[0])\n",
    "    angles_dict_v2[\"uuid_matched\"].append(uuid)\n",
    "    angles_dict_v2[\"angle_type\"].append(\"sd1-sd2\")\n",
    "    angles_dict_v2[\"angle\"].append(acos(costheta12))\n",
    "    angles_dict_v2[\"cos_angle\"].append(costheta12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb833f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles = pd.DataFrame(angles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_map = {\"sd1\": 2, \"sd2\": 1}  # decreasing radius order\n",
    "df_angles[\"r_dummy\"] = df_angles.apply(lambda row: r_map[row[\"quantile_type\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ab402",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf[\"theta_deg\"] = qdf[\"theta\"]*180./pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf[(qdf[\"mouse_id\"] == \"T333\") & (qdf[\"quantile_type\"] != \"sz\")][[\"quantile_type\",\"theta_deg\", \"uuid_matched\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bbe979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles.pivot_table(index=\"mouse_id\",columns='r_dummy', values=\"angle_with_sz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c1e01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5) \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# Set up a grid of axes with a polar projection\n",
    "g = sns.FacetGrid(df_angles, col=\"mouse_id\", hue=\"quantile_type\",\n",
    "                  subplot_kws=dict(projection='polar'), aspect=1, height=7,\n",
    "                  sharex=True, sharey=True, despine=False)\n",
    "\n",
    "# Draw a scatterplot onto each axes in the grid\n",
    "g.map(sns.scatterplot, \"angle_with_sz\", \"r_dummy\", s=400, alpha=0.5)\n",
    "plt.gca().set_rlim(0, 2.25)\n",
    "\n",
    "\n",
    "g.add_legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a57110",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5) \n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "# Set up a grid of axes with a polar projection\n",
    "g = sns.FacetGrid(qdf, col=\"mouse_id\", hue=\"quantile_type\",\n",
    "                  subplot_kws=dict(projection='polar'), aspect=1, height=7,\n",
    "                  sharex=True, sharey=True, despine=False)\n",
    "\n",
    "# Draw a scatterplot onto each axes in the grid\n",
    "g.map(sns.scatterplot, \"theta\", \"r\", s=200, alpha=0.7)\n",
    "plt.gca().set_rlim(0, 350)\n",
    "\n",
    "g.add_legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65839e8d",
   "metadata": {},
   "source": [
    "## Set plotting details\n",
    "Color scheme, arrow widths, order of event types (sz, sd1, sd2)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create colors with hues\n",
    "rgbs = []\n",
    "for color in mcolors.TABLEAU_COLORS.values():\n",
    "    rgbs.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this color scheme does not work properly. Need to adjust v values...\n",
    "\n",
    "# create 2d array: [color][lightness_variant]\n",
    "def getColorScheme(n_shades=4):\n",
    "    color_scheme = []\n",
    "    for color in mcolors.TABLEAU_COLORS.values():\n",
    "        h, s, v = mcolors.rgb_to_hsv(mcolors.to_rgb(color))\n",
    "        vs = np.linspace(v, 1, n_shades+1)  # first color in linspace is #000000, which will not be used\n",
    "        color_row = [mcolors.to_hex(mcolors.hsv_to_rgb((h, s, v_i))) for v_i in vs[1:]]\n",
    "        color_scheme.append(color_row)\n",
    "    return color_scheme\n",
    "#color_scheme = getColorScheme(4)\n",
    "#mcolors.TABLEAU_COLORS with tints, [hue][dark to light]\n",
    "color_scheme = [\n",
    "    ['#1f77b4', \"#258fd8\", \"#49a2e0\", \"#6db5e6\", \"#92c7ec\", \"#b6daf2\"],\n",
    "    [\"#ff7f0e\", \"#ff9130\", \"#ffa453\", \"#ffb675\", \"#ffc898\", \"#ffdaba\"],\n",
    "    [\"#2ca02c\", \"#35c235\", \"#54d054\", \"#76d976\", \"#98e398\", \"#baecba\"],\n",
    "    [\"#d62728\", \"#dd4546\", \"#e36464\", \"#e88383\", \"#eea2a2\", \"#f4c1c1\"],\n",
    "    [\"#9467bd\", \"#a37dc6\", \"#b392d0\", \"#c2a8d9\", \"#d1bee3\", \"#e0d4ec\"],\n",
    "    [\"#8c564b\", \"#a7675a\", \"#b58176\", \"#c49a91\", \"#d3b3ad\", \"#e2ccc8\"],\n",
    "    [\"#e377c2\", \"#e78acb\", \"#eb9ed3\", \"#efb1dc\", \"#f3c5e5\", \"#f7d8ee\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c187552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign an index to each mouse. 0.0, 1.0, 2.0, ...\n",
    "qdf[\"mouse_index\"] = qdf[\"mouse_id\"].rank(method='dense') - 1\n",
    "qdf[\"mouse_index\"] = qdf[\"mouse_index\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97fce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert enough colors are available\n",
    "assert len(color_scheme) > qdf[\"mouse_index\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#event_types = list(qdf.quantile_type.unique())\n",
    "event_types = [\"sd2\", \"sd1\", \"sz\"]  # order for vector length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2139b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARROW_WIDTHS = {\"sd2\": 12, \"sd1\": 6, \"sz\": 2}\n",
    "ARROW_HEAD = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339633e",
   "metadata": {},
   "source": [
    "## Create arrow plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection='polar')\n",
    "\n",
    "# plot arrows\n",
    "for i, row in qdf.iterrows():\n",
    "    r = event_types.index(row[\"quantile_type\"])+1# row['r']\n",
    "    theta = row['theta_inj_top']\n",
    "    ax.annotate('', xy=(theta, r), xytext=(0, 0),\n",
    "                arrowprops=dict(facecolor=color_scheme[int(row[\"mouse_index\"])][len(event_types) - event_types.index(row[\"quantile_type\"])], edgecolor='none', width=ARROW_WIDTHS[row[\"quantile_type\"]], headwidth=ARROW_HEAD, alpha=0.9))\n",
    "\n",
    "# set the radial limits\n",
    "max_r = len(qdf[\"quantile_type\"].unique())-1#qdf['r'].max()\n",
    "ax.set_ylim(0, max_r + 1)\n",
    "ax.set_rgrids(np.linspace(0, max_r+1, num=len(event_types)+1))\n",
    "ax.set_yticklabels([\"\"] + event_types)\n",
    "ax.set_xticklabels(['', '', 'medial/injection', '', '', '', 'lateral', ''], fontsize=20)\n",
    "\n",
    "#ax.set_xticklabels(event_types) \n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cacee39",
   "metadata": {},
   "source": [
    "### Extract all seizure angles per mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ac4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_seizures_dict = dict()\n",
    "seizure_angles_groups = qdf[qdf[\"quantile_type\"] == \"sz\"].groupby(\"mouse_id\")\n",
    "for mouse_id, mouse_group in seizure_angles_groups:\n",
    "    mouse_seizures_dict[mouse_id] = mouse_group[\"theta_inj_top\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9779fd0f",
   "metadata": {},
   "source": [
    "### Plot for each mouse separately\n",
    "Directionality: do 1 for 1 mouse, all sz, one thick mean arrow, color code sessions, angles + mean angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a766bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mice = len(qdf.mouse_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d10f89",
   "metadata": {},
   "source": [
    "### Define mean vectors\n",
    "Two methods possible:\n",
    "* Average x and y coordinates (i.e. average vectors)\n",
    "* Average theta only (i.e. discard vector magnitude, equal weight for each angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa495c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf[\"costheta_inj_top\"] = qdf.apply(lambda row: cos(row[\"theta_inj_top\"]), axis=1)\n",
    "qdf[\"sintheta_inj_top\"] = qdf.apply(lambda row: sin(row[\"theta_inj_top\"]), axis=1)\n",
    "\n",
    "qdf[\"costheta\"] = qdf.apply(lambda row: cos(row[\"theta\"]), axis=1)\n",
    "qdf[\"sintheta\"] = qdf.apply(lambda row: sin(row[\"theta\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qdf = quantiles_df.groupby([\"uuid_extended\", \"quantile_type\"], as_index=False).apply(lambda group_df: group_df.assign(dx=lambda gdf: get_dx(gdf, \"x\"), dy=lambda gdf: get_dx(gdf, \"y_mirrored\")))\n",
    "df_mean_vectors_per_mouse = qdf.groupby(['mouse_id', 'quantile_type'], as_index=False).mean().drop(columns=[\"y_mirrored\", \"r\"])\n",
    "\n",
    "\n",
    "df_sum_components = qdf[[\"mouse_id\", \"quantile_type\", \"dx\", \"dy\"]].groupby([\"mouse_id\", \"quantile_type\"], as_index=False).sum()\n",
    "df_sum_components[\"r\"] = df_sum_components.apply(lambda row: sqrt(pow(row[\"dx\"], 2) + pow(row[\"dy\"], 2) ), axis=1)\n",
    "# direction vector theta: the mean of all theta angles, i.e. unweighted average\n",
    "df_mean_vectors_per_mouse[\"mean_dir_theta\"] = df_mean_vectors_per_mouse.apply(lambda row: atan2(row[\"sintheta\"], row[\"costheta\"]), axis=1)\n",
    "df_mean_vectors_per_mouse[\"mean_dir_theta_inj_top\"] = df_mean_vectors_per_mouse.apply(lambda row: atan2(row[\"sintheta_inj_top\"], row[\"costheta_inj_top\"]), axis=1)\n",
    "\n",
    "sign_change_dict = {\"bottom\": -1, \"top\": 1}  # for contralateral injections, injection is always on the medial side of the window\n",
    "df_mean_vectors_per_mouse[\"r\"] = df_mean_vectors_per_mouse.apply(lambda row: sqrt(pow(row[\"dx\"], 2) + pow(row[\"dy\"], 2)), axis=1)\n",
    "df_mean_vectors_per_mouse[\"theta\"] = df_mean_vectors_per_mouse.apply(lambda row: atan2(row[\"dy\"], row[\"dx\"]), axis=1)\n",
    "df_mean_vectors_per_mouse[\"theta_inj_top\"] = df_mean_vectors_per_mouse.apply(lambda row: sign_change_dict[ddoc.getInjectionDirection(row[\"mouse_id\"])]*row[\"theta\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_vectors_per_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_angles_pivot = df_mean_vectors_per_mouse.pivot_table(index=\"mouse_id\", columns='quantile_type', values='theta_inj_top')\n",
    "quantile_angles_pivot[\"sz-sd1\"] = (quantile_angles_pivot[\"sz\"] - quantile_angles_pivot[\"sd1\"] + pi) % (2 * pi) - pi # convert to (-pi, pi)\n",
    "quantile_angles_pivot[\"sz-sd2\"] = (quantile_angles_pivot[\"sz\"] - quantile_angles_pivot[\"sd2\"] + pi) % (2 * pi) - pi # convert to (-pi, pi)\n",
    "# create a pivot table for the direction angles as well\n",
    "quantile_dir_angles_pivot =  df_mean_vectors_per_mouse.pivot_table(index=\"mouse_id\", columns='quantile_type', values='mean_dir_theta_inj_top')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09460c",
   "metadata": {},
   "source": [
    "Helper functions to create sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radianTo02PiRange(angle_rad):\n",
    "    return (angle_rad)%(2*pi)\n",
    "\n",
    "\n",
    "def getSectorsForMouse(mouse_id, mouse_index, use_dir_angles=False):\n",
    "    if use_dir_angles:  # use direction angles, i.e. mean theta angles\n",
    "        theta_sz = radianTo02PiRange(quantile_dir_angles_pivot.loc[mouse_id][\"sz\"])\n",
    "        theta_sd1 = radianTo02PiRange(quantile_dir_angles_pivot.loc[mouse_id][\"sd1\"])\n",
    "        theta_sd2 = radianTo02PiRange(quantile_dir_angles_pivot.loc[mouse_id][\"sd2\"])\n",
    "        if mouse_id == \"T352\":\n",
    "            print(\"Sectors:\")\n",
    "            print(theta_sd2*180.0/pi)\n",
    "            print(theta_sz*180.0/pi)\n",
    "            print()\n",
    "    else:\n",
    "        theta_sz = radianTo02PiRange(quantile_angles_pivot.loc[mouse_id][\"sz\"])\n",
    "        theta_sd1 = radianTo02PiRange(quantile_angles_pivot.loc[mouse_id][\"sd1\"])\n",
    "        theta_sd2 = radianTo02PiRange(quantile_angles_pivot.loc[mouse_id][\"sd2\"])\n",
    "\n",
    "    # width angle: total angular region covered.\n",
    "    # 1. find smaller angle between them\n",
    "    theta1_min = min(theta_sz, theta_sd1)\n",
    "    theta1_max = max(theta_sz, theta_sd1)\n",
    "    theta2_min = min(theta_sz, theta_sd2)\n",
    "    theta2_max = max(theta_sz, theta_sd2)\n",
    "\n",
    "    dtheta_1 = theta1_max - theta1_min\n",
    "    theta1_width = min(dtheta_1, 2*pi - dtheta_1)\n",
    "    dtheta_2 = theta2_max - theta2_min\n",
    "    theta2_width = min(dtheta_2, 2*pi - dtheta_2)\n",
    "\n",
    "    # mid angle: between the two arrows.\n",
    "    # 1. find larger angle - smaller angle difference; if > pi, should take counter-clockwise difference.\n",
    "    if dtheta_1 <= pi:  # can take angle as-is\n",
    "        theta1_mid = (theta_sz + theta_sd1)/2 #np.deg2rad((theta1 + theta2)/2)\n",
    "    else:\n",
    "        # the middle angle clockwise needs to be mirrored around the origin. Done by subtracting pi.\n",
    "        theta1_mid = (theta_sz + theta_sd1)/2 - pi\n",
    "    if dtheta_2 <= pi:\n",
    "        theta2_mid = (theta_sz + theta_sd2)/2\n",
    "    else:\n",
    "        theta2_mid = (theta_sz + theta_sd2)/2 - pi\n",
    "    #ax.bar(x=theta1_mid, height = 20, width=theta1_width, bottom=r0, color=color_scheme[int(row[\"mouse_index\"])][len(event_types) - event_types.index(row[\"quantile_type\"])])\n",
    "    #r0 += 20\n",
    "    #\n",
    "    #r0 += 20\n",
    "\n",
    "    # TODO: make sure sd1 and sd2 exist\n",
    "\n",
    "    # get vector lengths for radii of sectors\n",
    "    r0 = 10  # the inner perimeter of each segment will be at 10.\n",
    "    r1 = df_mean_vectors_per_mouse[(df_mean_vectors_per_mouse[\"mouse_id\"] == mouse_id) & (df_mean_vectors_per_mouse[\"quantile_type\"] == \"sd1\")][\"r\"].values[0]\n",
    "    r2 = df_mean_vectors_per_mouse[(df_mean_vectors_per_mouse[\"mouse_id\"] == mouse_id) & (df_mean_vectors_per_mouse[\"quantile_type\"] == \"sd2\")][\"r\"].values[0]\n",
    "    rsz = df_mean_vectors_per_mouse[(df_mean_vectors_per_mouse[\"mouse_id\"] == mouse_id) & (df_mean_vectors_per_mouse[\"quantile_type\"] == \"sz\")][\"r\"].values[0]\n",
    "\n",
    "    r_padding = 6  # to make arrows visible, leave this much space between arrow point and sector perimeter\n",
    "    rmax_sd1 = min(r1-r_padding, rsz-r_padding)\n",
    "    rmax_sd2 = min(r2-r_padding, rsz-r_padding)\n",
    "    assert rmax_sd1 > r0\n",
    "    assert rmax_sd2 > r0\n",
    "\n",
    "\n",
    "    # avoid same-size sectors for same mouse\n",
    "    if rmax_sd1 == rmax_sd2:\n",
    "        rmax_sd2 -= 20\n",
    "\n",
    "    # calculate inner perimeter (bottom) and height for both sectors\n",
    "    height1 = rmax_sd1 - r0 - r_padding\n",
    "    height2 = rmax_sd2 - r0 - r_padding\n",
    "    bottom1 = r0\n",
    "    bottom2 = r0\n",
    "\n",
    "\n",
    "    # get colors\n",
    "    color1 = color_scheme[int(mouse_index)][len(event_types) - event_types.index(\"sd1\")]\n",
    "    color2 = color_scheme[int(mouse_index)][len(event_types) - event_types.index(\"sd2\")]\n",
    "    return [[theta1_mid, height1, theta1_width, bottom1, color1], [theta2_mid, height2, theta2_width, bottom2, color2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf05a9",
   "metadata": {},
   "source": [
    "## All events, color-coded by sessions, for each mouse independently (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4aadfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n_mice <= 4  # if >4, need to reformat the figure, say, to 3x3\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "mice_list = []\n",
    "arcs_list = []\n",
    "for i_mouse in range(n_mice):\n",
    "    qdf_single_mouse = qdf[qdf[\"mouse_index\"] == i_mouse]\n",
    "    theta_mean_sz = df_mean_vectors_per_mouse[(df_mean_vectors_per_mouse[\"mouse_index\"] == i_mouse) & (df_mean_vectors_per_mouse[\"quantile_type\"] == \"sz\")].mean_dir_theta_inj_top.values[0]\n",
    "    #theta_mean_sz = qdf[(qdf[\"mouse_index\"] == i_mouse) & (qdf[\"quantile_type\"] == \"sz\")].theta_inj_top.mean()\n",
    "    mouse_id = qdf[qdf[\"mouse_index\"] == i_mouse][\"mouse_id\"].unique()[0]\n",
    "    \n",
    "    ax = fig.add_subplot(2,2,i_mouse+1, projection='polar')\n",
    "    ax.set_title(mouse_id)\n",
    "    r0 = 0.1\n",
    "    r_out_sd1 = event_types.index(\"sd1\") + 0.8  # 0-indexing + 1 - 0.2 to make arrow points still visible\n",
    "    r_out_sd2 = event_types.index(\"sd2\") + 0.8\n",
    "\n",
    "    # contains all arc properties gathered for later plotting:\n",
    "    # mice_list = [<mouse_id1>, <mouse_id1>, <mouse_id2>, <mouse_id2>, ...]\n",
    "    # for each mouse_id entry, there is one array in arcs_list:\n",
    "    # [theta1_mid, height1, theta1_width, bottom1, color1], [theta2_mid, height2, theta2_width, bottom2, color2]\n",
    "    # it is a list to be able to sort the plotting\n",
    "    # TODO: create this dictionary, then loop through keys, loop through keys inside, and if exists, plot the corresponding arc.\n",
    "    # TODO: change arc colors to shades of sd1 and sd2\n",
    "    # TODO: change arcs to\n",
    " \n",
    "\n",
    "\n",
    "    # to also plot the relative amplitudes of each vector, keep track of [theta, r] pairs. Later, plot normalized r (normalized to 3)\n",
    "    length_markers_list = [[],[],[]]\n",
    "    r_max = df_mean_vectors_per_mouse['r'].max()  # use r_max to normalize to 3. Longest vector will reach 3...\n",
    "\n",
    "    sessions = qdf_single_mouse[\"uuid_matched\"].unique().tolist()\n",
    "\n",
    "    outline_color = \"lightgrey\"  # \"grey\" or \"lightgrey\" or \"none\"\n",
    "    \n",
    "    # plot arrows\n",
    "    for i, row in qdf_single_mouse.iterrows():\n",
    "        r = event_types.index(row[\"quantile_type\"])+1 # length depends on type (sz, sd1, sd2)\n",
    "        theta = row['theta_inj_top']\n",
    "        r_original = row['r']\n",
    "        # add theta and length to points list\n",
    "        length_markers_list[0].append(theta)\n",
    "        length_markers_list[1].append((r_original/r_max)*len(event_types))\n",
    "        length_markers_list[2].append(color_scheme[int(row[\"mouse_index\"])][0])\n",
    "        ax.annotate('', xy=(theta, r), xytext=(0, 0),\n",
    "                    arrowprops=dict(facecolor=color_scheme[sessions.index(row[\"uuid_matched\"])][len(event_types) - event_types.index(row[\"quantile_type\"])], edgecolor=outline_color, width=ARROW_WIDTHS[row[\"quantile_type\"]], headwidth=ARROW_HEAD, alpha=0.9))\n",
    "        if row[\"quantile_type\"] == \"sd2\" and row[\"mouse_id\"] == \"T352\":\n",
    "            print(theta*180.0/pi)\n",
    "\n",
    "        if row[\"mouse_id\"] not in mice_list:\n",
    "            # get angles as sectors. sectors[0] is sd1, sectors[1] is sd2\n",
    "            sectors = getSectorsForMouse(row[\"mouse_id\"], row[\"mouse_index\"], use_dir_angles=True)\n",
    "            mice_list.append(row[\"mouse_id\"])\n",
    "            # mean sd1 angle\n",
    "            sector = sectors[0]\n",
    "            ax.bar(x=sector[0], height=event_types.index(\"sd1\")+1-r0, width=sector[2], bottom=r0, color=\"grey\", edgecolor=\"grey\")\n",
    "            # mean sd2 angle (if present)\n",
    "            if len(sectors) > 1:\n",
    "                sector = sectors[1]\n",
    "                if row[\"mouse_id\"] == \"T352\":\n",
    "                    print(sector)\n",
    "                ax.bar(x=sector[0], height=event_types.index(\"sd2\")+1 - r0, width=sector[2], bottom=r0, color=\"lightgrey\", edgecolor=\"grey\")\n",
    "    # plot mean seizure direction arrow as last of arrows\n",
    "    ax.annotate('', xy=(theta_mean_sz, 3), xytext=(0, 0),\n",
    "            arrowprops=dict(facecolor=\"black\", edgecolor=outline_color, width=ARROW_WIDTHS[\"sz\"]+4, headwidth=ARROW_HEAD, alpha=0.9))\n",
    "\n",
    "    #r = Rectangle((0., 0.), 100., 100, color=\"red\")\n",
    "    #p = PatchCollection([Rectangle((np.deg2rad(20), 100), 45, 50, color='blue')])\n",
    "    #ax.add_collection(p)\n",
    "\n",
    "    # set the radial limits\n",
    "    max_r = len(qdf[\"quantile_type\"].unique())-1#\n",
    "    plot_length = False\n",
    "    if plot_length:  # add scatter points for relative lengths\n",
    "        for i_length_marker in range(len(length_markers_list[0])):\n",
    "            theta = length_markers_list[0][i_length_marker]\n",
    "            r = length_markers_list[1][i_length_marker]\n",
    "            color = length_markers_list[2][i_length_marker]\n",
    "            ax.scatter(theta, r, color=color, s=40)# color=\"black\", s=20)\n",
    "\n",
    "    ax.set_ylim(0, max_r + 1)\n",
    "    ax.set_rgrids(np.linspace(0, max_r+1, num=len(event_types)+1), fontsize=20)\n",
    "    ax.set_yticklabels([\"\"] + event_types)\n",
    "    ax.set_xticklabels(['', '', 'medial/injection', '', '', '', 'lateral', ''], fontsize=20)  # top direction should be \"medial/injection\"\n",
    "\n",
    "    \n",
    "# display the plot\n",
    "#plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf0d6e",
   "metadata": {},
   "source": [
    "### Do it for one mouse only, representatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf923c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_id = \"T301\"\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "mice_list = []\n",
    "arcs_list = []\n",
    "\n",
    "qdf_single_mouse = qdf[qdf[\"mouse_id\"] == mouse_id]\n",
    "theta_mean_sz = df_mean_vectors_per_mouse[(df_mean_vectors_per_mouse[\"mouse_id\"] == mouse_id) & (df_mean_vectors_per_mouse[\"quantile_type\"] == \"sz\")].mean_dir_theta_inj_top.values[0]\n",
    "\n",
    "ax = fig.add_subplot(1,1,1, projection='polar')\n",
    "ax.set_title(mouse_id)\n",
    "r0 = 0.1\n",
    "r_out_sd1 = event_types.index(\"sd1\") + 0.8  # 0-indexing + 1 - 0.2 to make arrow points still visible\n",
    "r_out_sd2 = event_types.index(\"sd2\") + 0.8\n",
    "\n",
    "# contains all arc properties gathered for later plotting:\n",
    "# mice_list = [<mouse_id1>, <mouse_id1>, <mouse_id2>, <mouse_id2>, ...]\n",
    "# for each mouse_id entry, there is one array in arcs_list:\n",
    "# [theta1_mid, height1, theta1_width, bottom1, color1], [theta2_mid, height2, theta2_width, bottom2, color2]\n",
    "# it is a list to be able to sort the plotting\n",
    "# TODO: create this dictionary, then loop through keys, loop through keys inside, and if exists, plot the corresponding arc.\n",
    "# TODO: change arc colors to shades of sd1 and sd2\n",
    "# TODO: change arcs to\n",
    "\n",
    "\n",
    "\n",
    "# to also plot the relative amplitudes of each vector, keep track of [theta, r] pairs. Later, plot normalized r (normalized to 3)\n",
    "length_markers_list = [[],[],[]]\n",
    "r_max = df_mean_vectors_per_mouse['r'].max()  # use r_max to normalize to 3. Longest vector will reach 3...\n",
    "\n",
    "sessions = qdf_single_mouse[\"uuid_matched\"].unique().tolist()\n",
    "\n",
    "outline_color = \"lightgrey\"  # \"grey\" or \"lightgrey\" or \"none\"\n",
    "\n",
    "# plot arrows\n",
    "for i, row in qdf_single_mouse.iterrows():\n",
    "    r = event_types.index(row[\"quantile_type\"])+1 # length depends on type (sz, sd1, sd2)\n",
    "    theta = row['theta_inj_top']\n",
    "    r_original = row['r']\n",
    "    # add theta and length to points list\n",
    "    length_markers_list[0].append(theta)\n",
    "    length_markers_list[1].append((r_original/r_max)*len(event_types))\n",
    "    length_markers_list[2].append(color_scheme[int(row[\"mouse_index\"])][0])\n",
    "    ax.annotate('', xy=(theta, r), xytext=(0, 0),\n",
    "                arrowprops=dict(facecolor=color_scheme[sessions.index(row[\"uuid_matched\"])][len(event_types) - event_types.index(row[\"quantile_type\"])], edgecolor=outline_color, width=ARROW_WIDTHS[row[\"quantile_type\"]], headwidth=ARROW_HEAD, alpha=0.9))\n",
    "    if row[\"quantile_type\"] == \"sd2\" and row[\"mouse_id\"] == \"T352\":\n",
    "        print(theta*180.0/pi)\n",
    "\n",
    "    if row[\"mouse_id\"] not in mice_list:\n",
    "        # get angles as sectors. sectors[0] is sd1, sectors[1] is sd2\n",
    "        sectors = getSectorsForMouse(row[\"mouse_id\"], row[\"mouse_index\"], use_dir_angles=True)\n",
    "        mice_list.append(row[\"mouse_id\"])\n",
    "        # mean sd1 angle\n",
    "        sector = sectors[0]\n",
    "        ax.bar(x=sector[0], height=event_types.index(\"sd1\")+1-r0, width=sector[2], bottom=r0, color=\"grey\", edgecolor=\"grey\")\n",
    "        # mean sd2 angle (if present)\n",
    "        if len(sectors) > 1:\n",
    "            sector = sectors[1]\n",
    "            if row[\"mouse_id\"] == \"T352\":\n",
    "                print(sector)\n",
    "            ax.bar(x=sector[0], height=event_types.index(\"sd2\")+1 - r0, width=sector[2], bottom=r0, color=\"lightgrey\", edgecolor=\"grey\")\n",
    "# plot mean seizure direction arrow as last of arrows\n",
    "ax.annotate('', xy=(theta_mean_sz, 3), xytext=(0, 0),\n",
    "        arrowprops=dict(facecolor=\"black\", edgecolor=outline_color, width=ARROW_WIDTHS[\"sz\"]+4, headwidth=ARROW_HEAD, alpha=0.9))\n",
    "\n",
    "#r = Rectangle((0., 0.), 100., 100, color=\"red\")\n",
    "#p = PatchCollection([Rectangle((np.deg2rad(20), 100), 45, 50, color='blue')])\n",
    "#ax.add_collection(p)\n",
    "\n",
    "# set the radial limits\n",
    "max_r = len(qdf[\"quantile_type\"].unique())-1#\n",
    "plot_length = False\n",
    "if plot_length:  # add scatter points for relative lengths\n",
    "    for i_length_marker in range(len(length_markers_list[0])):\n",
    "        theta = length_markers_list[0][i_length_marker]\n",
    "        r = length_markers_list[1][i_length_marker]\n",
    "        color = length_markers_list[2][i_length_marker]\n",
    "        ax.scatter(theta, r, color=color, s=40)# color=\"black\", s=20)\n",
    "\n",
    "ax.set_ylim(0, max_r + 1)\n",
    "ax.set_rgrids(np.linspace(0, max_r+1, num=len(event_types)+1), fontsize=20)\n",
    "ax.set_yticklabels([\"\"] + event_types)\n",
    "ax.set_xticklabels(['', '', 'medial/injection', '', '', '', 'lateral', ''], fontsize=20)  # top direction should be \"medial/injection\"\n",
    "\n",
    "\n",
    "# display the plot\n",
    "#plt.show()\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    fig_fpath = os.path.join(output_folder, f'single_mouse_directionality_{get_datetime_for_fname()}.eps')\n",
    "    plt.savefig(fig_fpath, format='eps')\n",
    "    print(f\"Saved to {fig_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580cb420",
   "metadata": {},
   "source": [
    "## Plot vectors with length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8348c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf[qdf[\"mouse_index\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33938b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n_mice <= 4  # if >4, need to reformat the figure, say, to 3x3\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "mice_list = []\n",
    "arcs_list = []\n",
    "for i_mouse in range(n_mice):\n",
    "    qdf_single_mouse = qdf[qdf[\"mouse_index\"] == i_mouse]\n",
    "    theta_mean_sz = df_mean_vectors_per_mouse[(df_mean_vectors_per_mouse[\"mouse_index\"] == i_mouse) & (df_mean_vectors_per_mouse[\"quantile_type\"] == \"sz\")].theta_inj_top.values[0]\n",
    "    r_mean_sz = df_mean_vectors_per_mouse[(df_mean_vectors_per_mouse[\"mouse_index\"] == i_mouse) & (df_mean_vectors_per_mouse[\"quantile_type\"] == \"sz\")].r.values[0]\n",
    "    \n",
    "    #theta_mean_sz = qdf[(qdf[\"mouse_index\"] == i_mouse) & (qdf[\"quantile_type\"] == \"sz\")].theta_inj_top.mean()\n",
    "    mouse_id = qdf[qdf[\"mouse_index\"] == i_mouse][\"mouse_id\"].unique()[0]\n",
    "    \n",
    "    ax = fig.add_subplot(2,2,i_mouse+1, projection='polar')\n",
    "    ax.set_title(mouse_id)\n",
    "    r0 = 0.1\n",
    "    r_out_sd1 = event_types.index(\"sd1\") + 0.8  # 0-indexing + 1 - 0.2 to make arrow points still visible\n",
    "    r_out_sd2 = event_types.index(\"sd2\") + 0.8\n",
    "\n",
    "    # contains all arc properties gathered for later plotting:\n",
    "    # mice_list = [<mouse_id1>, <mouse_id1>, <mouse_id2>, <mouse_id2>, ...]\n",
    "    # for each mouse_id entry, there is one array in arcs_list:\n",
    "    # [theta1_mid, height1, theta1_width, bottom1, color1], [theta2_mid, height2, theta2_width, bottom2, color2]\n",
    "    # it is a list to be able to sort the plotting\n",
    "    # TODO: create this dictionary, then loop through keys, loop through keys inside, and if exists, plot the corresponding arc.\n",
    "    # TODO: change arc colors to shades of sd1 and sd2\n",
    "    # TODO: change arcs to\n",
    " \n",
    "\n",
    "\n",
    "    # to also plot the relative amplitudes of each vector, keep track of [theta, r] pairs. Later, plot normalized r (normalized to 3)\n",
    "    length_markers_list = [[],[],[]]\n",
    "    r_max = df_mean_vectors_per_mouse['r'].max()  # use r_max to normalize to 3. Longest vector will reach 3...\n",
    "\n",
    "    sessions = qdf_single_mouse[\"uuid_matched\"].unique().tolist()\n",
    "\n",
    "    outline_color = \"lightgrey\"  # \"grey\" or \"lightgrey\" or \"none\"\n",
    "    \n",
    "    # plot arrows\n",
    "    for i, row in qdf_single_mouse.iterrows():\n",
    "        r = row[\"r\"]#event_types.index(row[\"quantile_type\"])+1 # length depends on type (sz, sd1, sd2)\n",
    "        theta = row['theta_inj_top']\n",
    "\n",
    "        ax.annotate('', xy=(theta, r), xytext=(0, 0),\n",
    "                    arrowprops=dict(facecolor=color_scheme[sessions.index(row[\"uuid_matched\"])][len(event_types) - event_types.index(row[\"quantile_type\"])], edgecolor=outline_color, width=ARROW_WIDTHS[row[\"quantile_type\"]], headwidth=ARROW_HEAD, alpha=0.9))\n",
    "\n",
    "\n",
    "        if row[\"mouse_id\"] not in mice_list:\n",
    "            # get angles as sectors. sectors[0] is sd1, sectors[1] is sd2\n",
    "            sectors = getSectorsForMouse(row[\"mouse_id\"], row[\"mouse_index\"], use_dir_angles=False)\n",
    "            mice_list.append(row[\"mouse_id\"])\n",
    "            # mean sd1 angle\n",
    "            sector = sectors[0]\n",
    "            ax.bar(x=sector[0], height=r_mean_sz-r0-ARROW_HEAD, width=sector[2], bottom=r0, color=\"grey\", edgecolor=\"grey\")\n",
    "            # mean sd2 angle (if present)\n",
    "            if len(sectors) > 1:\n",
    "                sector = sectors[1]\n",
    "                ax.bar(x=sector[0], height=0.8*r_mean_sz-r0-ARROW_HEAD, width=sector[2], bottom=r0, color=\"lightgrey\", edgecolor=\"grey\")\n",
    "    # plot mean seizure direction arrow as last of arrows\n",
    "    ax.annotate('', xy=(theta_mean_sz, r_mean_sz), xytext=(0, 0),\n",
    "            arrowprops=dict(facecolor=\"black\", edgecolor=outline_color, width=ARROW_WIDTHS[\"sz\"]+4, headwidth=ARROW_HEAD, alpha=0.9))\n",
    "\n",
    "    #r = Rectangle((0., 0.), 100., 100, color=\"red\")\n",
    "    #p = PatchCollection([Rectangle((np.deg2rad(20), 100), 45, 50, color='blue')])\n",
    "    #ax.add_collection(p)\n",
    "\n",
    "    # set the radial limits\n",
    "    max_r = qdf_single_mouse[\"r\"].max()#\n",
    "    plot_length = False\n",
    "    if plot_length:  # add scatter points for relative lengths\n",
    "        for i_length_marker in range(len(length_markers_list[0])):\n",
    "            theta = length_markers_list[0][i_length_marker]\n",
    "            r = length_markers_list[1][i_length_marker]\n",
    "            color = length_markers_list[2][i_length_marker]\n",
    "            ax.scatter(theta, r, color=color, s=40)# color=\"black\", s=20)\n",
    "\n",
    "    ax.set_ylim(0, max_r + 1)\n",
    "    ax.set_rgrids(np.linspace(0, max_r+1, num=len(event_types)+1))\n",
    "    #ax.set_yticklabels([\"\"] + event_types)\n",
    "    ax.set_xticklabels(['', '', 'medial/injection', '', '', '', 'lateral', ''], fontsize=20)  # top direction should be \"medial/injection\"\n",
    "\n",
    "    \n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1de70",
   "metadata": {},
   "source": [
    "### Test cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed556033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# group by mouse and by event type\n",
    "vectors_df = qdf[[\"mouse_index\", \"mouse_id\", \"uuid_matched\", \"quantile_type\", \"dx\", \"dy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5944daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by \"id\" and calculate similarity matrix for each group\n",
    "cos_similarity_matrices = {mouse_id: {} for mouse_id in vectors_df.mouse_id.unique()}\n",
    "for group_id_event_type, group_df in vectors_df.groupby(['mouse_id', \"quantile_type\"]):\n",
    "    x = group_df['dx'].values\n",
    "    y = group_df['dy'].values\n",
    "    \n",
    "    mouse_id, event_type = group_id_event_type\n",
    "    \n",
    "    # calculate similarity matrix using cosine similarity\n",
    "    vectors = np.stack((x, y), axis=1)\n",
    "    similarity_matrix = cosine_similarity(vectors)\n",
    "    \n",
    "    cos_similarity_matrices[mouse_id][event_type] = similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d87b9",
   "metadata": {},
   "source": [
    "### Get span of seizure theta angles for all mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f1d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection='polar')\n",
    "# contains all arc properties gathered for later plotting:\n",
    "# mice_list = [<mouse_id1>, <mouse_id1>, <mouse_id2>, <mouse_id2>, ...]\n",
    "# for each mouse_id entry, there is one array in arcs_list:\n",
    "# [theta1_mid, height1, theta1_width, bottom1, color1], [theta2_mid, height2, theta2_width, bottom2, color2]\n",
    "# it is a list to be able to sort the plotting\n",
    "# TODO: create this dictionary, then loop through keys, loop through keys inside, and if exists, plot the corresponding arc.\n",
    "# TODO: change arc colors to shades of sd1 and sd2\n",
    "# TODO: change arcs to\n",
    "mice_list = []\n",
    "arcs_list = [] \n",
    "\n",
    "\n",
    "\n",
    "# plot arrows\n",
    "for i, row in df_mean_vectors_per_mouse.iterrows():\n",
    "    r = row['r']#event_types.index(row[\"quantile_type\"])+1# \n",
    "    theta = row['theta_inj_top']\n",
    "    ax.annotate('', xy=(theta, r), xytext=(0, 0),\n",
    "                arrowprops=dict(facecolor=color_scheme[int(row[\"mouse_index\"])][len(event_types) - event_types.index(row[\"quantile_type\"])], edgecolor='grey', width=ARROW_WIDTHS[row[\"quantile_type\"]], headwidth=ARROW_HEAD, alpha=0.9))\n",
    "    if row[\"mouse_id\"] not in mice_list:  # avoid adding sectors for the same mouse again\n",
    "        sectors = getSectorsForMouse(row[\"mouse_id\"], row[\"mouse_index\"])\n",
    "        \n",
    "        # add data to list\n",
    "        mice_list.append(row[\"mouse_id\"])\n",
    "        arcs_list.append(sectors[0]) #[row[\"mouse_id\"]] = arc_data\n",
    "        mice_list.append(row[\"mouse_id\"])\n",
    "        arcs_list.append(sectors[1])\n",
    "\n",
    "    \n",
    "        \n",
    "# plot light clored sectors that span all seizures per mouse\n",
    "r_max = df_mean_vectors_per_mouse[ (df_mean_vectors_per_mouse[\"quantile_type\"] == \"sz\")][\"r\"].max()\n",
    "for i_mouse in range(0, len(mice_list), 2):\n",
    "    mouse_id = mice_list[i_mouse]\n",
    "    mouse_index = i_mouse//2\n",
    "    theta_min = mouse_seizures_dict[mouse_id].min()\n",
    "    theta_max = mouse_seizures_dict[mouse_id].max()\n",
    "    width=radianTo02PiRange(theta_max - theta_min)\n",
    "    r_min = 20\n",
    "    color = color_scheme[mouse_index][-1]\n",
    "    ax.bar(x=(theta_max+theta_min)/2.0, height=r_max - r_min - (i_mouse+1)*10, width=width, bottom=r_min, color=color, edgecolor=\"lightgrey\" )\n",
    "        \n",
    "\n",
    "# sort by descending outer perimeter so all of them visible by plotting smaller on top of larger sectors\n",
    "for sector in sorted(arcs_list, key=lambda row: row[1], reverse=True):\n",
    "    ax.bar(x=sector[0], height=sector[1], width=sector[2], bottom=sector[3], color=sector[4], edgecolor=\"grey\")\n",
    "\n",
    "        \n",
    "#r = Rectangle((0., 0.), 100., 100, color=\"red\")\n",
    "#p = PatchCollection([Rectangle((np.deg2rad(20), 100), 45, 50, color='blue')])\n",
    "#ax.add_collection(p)\n",
    "\n",
    "# set the radial limits\n",
    "max_r = df_mean_vectors_per_mouse['r'].max() #len(qdf[\"quantile_type\"].unique())-1#\n",
    "ax.set_ylim(0, max_r + 1)\n",
    "#ax.set_rgrids(np.linspace(0, max_r+1, num=len(event_types)+1))\n",
    "#ax.set_yticklabels([\"\"] + event_types)\n",
    "ax.set_xticklabels(['', '', 'medial/injection', '', '', '', 'lateral', ''], fontsize=20)  # top direction should be \"medial/injection\"\n",
    "\n",
    "#ax.set_xticklabels(event_types) \n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce0aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: length of vectors should still somehow correspond to average... If length is small, the direction might be insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use circular heatmap or roseplot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: mark the angles between average vectors (sz-sd1, sz-sd2) for each mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_means = True  # use mean direction? (mean theta vs x, y mean components i.e. mean vector)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection='polar')\n",
    "r0 = 0.1\n",
    "r_out_sd1 = event_types.index(\"sd1\") + 0.8  # 0-indexing + 1 - 0.2 to make arrow points still visible\n",
    "r_out_sd2 = event_types.index(\"sd2\") + 0.8\n",
    "\n",
    "# contains all arc properties gathered for later plotting:\n",
    "# mice_list = [<mouse_id1>, <mouse_id1>, <mouse_id2>, <mouse_id2>, ...]\n",
    "# for each mouse_id entry, there is one array in arcs_list:\n",
    "# [theta1_mid, height1, theta1_width, bottom1, color1], [theta2_mid, height2, theta2_width, bottom2, color2]\n",
    "# it is a list to be able to sort the plotting\n",
    "# TODO: create this dictionary, then loop through keys, loop through keys inside, and if exists, plot the corresponding arc.\n",
    "# TODO: change arc colors to shades of sd1 and sd2\n",
    "# TODO: change arcs to\n",
    "mice_list = []\n",
    "arcs_list = [] \n",
    "\n",
    "\n",
    "# to also plot the relative amplitudes of each vector, keep track of [theta, r] pairs. Later, plot normalized r (normalized to 3)\n",
    "length_markers_list = [[],[],[]]\n",
    "r_max = df_mean_vectors_per_mouse['r'].max()  # use r_max to normalize to 3. Longest vector will reach 3...\n",
    "\n",
    "\n",
    "def radianTo02PiRange(angle_rad):\n",
    "    return (angle_rad)%(2*pi)\n",
    "\n",
    "outline_color = \"lightgrey\"  # \"grey\" or \"lightgrey\" or \"none\"\n",
    "\n",
    "# plot arrows\n",
    "for i, row in df_mean_vectors_per_mouse.iterrows():\n",
    "    r = event_types.index(row[\"quantile_type\"])+1 # length depends on type (sz, sd1, sd2)\n",
    "    if dir_means:\n",
    "        theta = row[\"mean_dir_theta_inj_top\"]\n",
    "    else:\n",
    "        theta = row['theta_inj_top']\n",
    "    r_original = row['r']\n",
    "    # add theta and length to points list\n",
    "    length_markers_list[0].append(theta)\n",
    "    length_markers_list[1].append((r_original/r_max)*len(event_types))\n",
    "    length_markers_list[2].append(color_scheme[int(row[\"mouse_index\"])][0])\n",
    "    \n",
    "    ax.annotate('', xy=(theta, r), xytext=(0, 0),\n",
    "                arrowprops=dict(facecolor=color_scheme[int(row[\"mouse_index\"])][len(event_types) - event_types.index(row[\"quantile_type\"])], edgecolor=outline_color, width=ARROW_WIDTHS[row[\"quantile_type\"]], headwidth=ARROW_HEAD, alpha=0.9))\n",
    "    \n",
    "    \n",
    "    if row[\"mouse_id\"] not in mice_list:\n",
    "        if dir_means:\n",
    "            theta_sz = radianTo02PiRange(quantile_dir_angles_pivot.loc[row[\"mouse_id\"]][\"sz\"])\n",
    "            theta_sd1 = radianTo02PiRange(quantile_dir_angles_pivot.loc[row[\"mouse_id\"]][\"sd1\"])\n",
    "            theta_sd2 = radianTo02PiRange(quantile_dir_angles_pivot.loc[row[\"mouse_id\"]][\"sd2\"])           \n",
    "        else:\n",
    "            theta_sz = radianTo02PiRange(quantile_angles_pivot.loc[row[\"mouse_id\"]][\"sz\"])\n",
    "            theta_sd1 = radianTo02PiRange(quantile_angles_pivot.loc[row[\"mouse_id\"]][\"sd1\"])\n",
    "            theta_sd2 = radianTo02PiRange(quantile_angles_pivot.loc[row[\"mouse_id\"]][\"sd2\"])\n",
    "        \n",
    "        # width angle: total angular region covered.\n",
    "        # 1. find smaller angle between them\n",
    "        theta1_min = min(theta_sz, theta_sd1)\n",
    "        theta1_max = max(theta_sz, theta_sd1)\n",
    "        theta2_min = min(theta_sz, theta_sd2)\n",
    "        theta2_max = max(theta_sz, theta_sd2)\n",
    "        \n",
    "        dtheta_1 = theta1_max - theta1_min\n",
    "        theta1_width = min(dtheta_1, 2*pi - dtheta_1)\n",
    "        dtheta_2 = theta2_max - theta2_min\n",
    "        theta2_width = min(dtheta_2, 2*pi - dtheta_2)\n",
    "        \n",
    "        # mid angle: between the two arrows.\n",
    "        # 1. find larger angle - smaller angle difference; if > pi, should take counter-clockwise difference.\n",
    "        if theta1_max - theta1_min <= pi:  # can take angle as-is\n",
    "            theta1_mid = (theta_sz + theta_sd1)/2 #np.deg2rad((theta1 + theta2)/2)\n",
    "        else:\n",
    "            # the middle angle clockwise needs to be mirrored around the origin. Done by subtracting pi.\n",
    "            theta1_mid = (theta_sz + theta_sd1)/2 - pi\n",
    "        if theta2_max - theta2_min <= pi:\n",
    "            theta2_mid = (theta_sz + theta_sd2)/2\n",
    "        else:\n",
    "            theta2_mid = (theta_sz + theta_sd2)/2 - pi\n",
    "        \n",
    "        # calculate inner perimeter (bottom) and height for both sectors\n",
    "        height1 = r_out_sd1 - r0\n",
    "        height2 = r_out_sd2 - r0\n",
    "        bottom1 = r0\n",
    "        bottom2 = r0\n",
    "        \n",
    "        \n",
    "        # get colors\n",
    "        color1 = color_scheme[int(row[\"mouse_index\"])][len(event_types) - event_types.index(\"sd1\")]\n",
    "        color2 = color_scheme[int(row[\"mouse_index\"])][len(event_types) - event_types.index(\"sd2\")]\n",
    "        \n",
    "        # add data to list\n",
    "        mice_list.append(row[\"mouse_id\"])\n",
    "        arcs_list.append([theta1_mid, height1, theta1_width, bottom1, color1]) #[row[\"mouse_id\"]] = arc_data\n",
    "        mice_list.append(row[\"mouse_id\"])\n",
    "        arcs_list.append([theta2_mid, height2, theta2_width, bottom2, color2])\n",
    "        \n",
    "        r_out_sd1 -= 0.1\n",
    "        r_out_sd2 -= 0.1\n",
    "        \n",
    "    # plot light clored sectors that span all seizures per mouse\n",
    "    r_max = event_types.index(\"sz\")+1\n",
    "    for i_mouse in range(0, len(mice_list), 2):\n",
    "        mouse_id = mice_list[i_mouse]\n",
    "        mouse_index = i_mouse//2\n",
    "        theta_min = mouse_seizures_dict[mouse_id].min()\n",
    "        theta_max = mouse_seizures_dict[mouse_id].max()\n",
    "        width=radianTo02PiRange(theta_max - theta_min)\n",
    "        r_min = 0.2\n",
    "        color = color_scheme[mouse_index][-1]\n",
    "        ax.bar(x=(theta_max+theta_min)/2.0, height=r_max - r_min - (i_mouse+1)*0.05, width=width, bottom=r_min, color=color, edgecolor=\"lightgrey\" )\n",
    "\n",
    "        \n",
    "\n",
    "# sort by descending outer perimeter so all of them visible by plotting smaller on top of larger sectors\n",
    "for sector in sorted(arcs_list, key=lambda row: row[1], reverse=True):\n",
    "    ax.bar(x=sector[0], height=sector[1], width=sector[2], bottom=sector[3], color=sector[4], edgecolor=outline_color)\n",
    "\n",
    "\n",
    "#r = Rectangle((0., 0.), 100., 100, color=\"red\")\n",
    "#p = PatchCollection([Rectangle((np.deg2rad(20), 100), 45, 50, color='blue')])\n",
    "#ax.add_collection(p)\n",
    "\n",
    "# set the radial limits\n",
    "max_r = len(qdf[\"quantile_type\"].unique())-1#\n",
    "plot_length = False\n",
    "if plot_length:  # add scatter points for relative lengths\n",
    "    for i_length_marker in range(len(length_markers_list[0])):\n",
    "        theta = length_markers_list[0][i_length_marker]\n",
    "        r = length_markers_list[1][i_length_marker]\n",
    "        color = length_markers_list[2][i_length_marker]\n",
    "        ax.scatter(theta, r, color=color, s=40)# color=\"black\", s=20)\n",
    "    \n",
    "ax.set_ylim(0, max_r + 1)\n",
    "ax.set_rgrids(np.linspace(0, max_r+1, num=len(event_types)+1))\n",
    "ax.set_yticklabels([\"\"] + event_types)\n",
    "ax.set_xticklabels(['', '', 'medial/injection', '', '', '', 'lateral', ''], fontsize=20)  # top direction should be \"medial/injection\"\n",
    "\n",
    "    \n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0ef0d",
   "metadata": {},
   "source": [
    "### Get sectors for all recordings individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = qdf.pivot_table(index=[\"uuid_matched\", \"mouse_id\", \"mouse_index\"], columns=[\"quantile_type\"], values=[\"theta_inj_top\", \"r\"]).sort_values(by=[\"mouse_id\"])\n",
    "pt.loc[\"06ebcf354f5c41519669f187e16de364\"].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSectorAnglesForVectors(theta1, theta2, force_direction=False, direction=\"ccw\"):\n",
    "    # direction: cw for clockwise, ccw for counter-clockwise\n",
    "    dtheta = abs(theta1 - theta2)\n",
    "    if force_direction:\n",
    "        if direction == \"ccw\":\n",
    "            # to make only counter-clockwise sectors (from theta1 to theta2):\n",
    "            #  0. the width does not change, no matter in what interval the two angles are defined\n",
    "            theta_width = (theta2 - theta1)%(2*pi)\n",
    "            #  1. bring them to a form where theta2 > theta1\n",
    "            theta2_adjusted = (theta2)%(2*pi)\n",
    "            theta1_adjusted = (theta1)%(2*pi)\n",
    "            if theta2_adjusted < theta1_adjusted:  # need to swap to (-pi, pi) range\n",
    "                theta2_adjusted = (theta2_adjusted - pi)%(2*pi)\n",
    "                theta1_adjusted = (theta1_adjusted - pi)%(2*pi)\n",
    "            theta_mid= ((theta1 + theta2)/2)%(2*pi)\n",
    "        elif direction == \"cw\":\n",
    "            # clockwise sectors from theta1 to theta2. This means the signs are reversed\n",
    "            # bring the angles to a range where theta2 < theta1. Try (0, 2pi) and (-pi, pi)\n",
    "            theta2_adjusted = (theta2)%(2*pi)\n",
    "            theta1_adjusted = (theta1)%(2*pi)\n",
    "            if theta2_adjusted > theta1_adjusted:  # need to swap to (-pi, pi) range\n",
    "                theta2_adjusted = (theta2_adjusted - pi)%(2*pi)\n",
    "                theta1_adjusted = (theta1_adjusted - pi)%(2*pi)\n",
    "            theta_width = (theta1_adjusted - theta2_adjusted)%(2*pi)\n",
    "            theta_mid= ((theta1_adjusted + theta2_adjusted)/2)%(2*pi)\n",
    "    else:  # find smaller angle for sectors\n",
    "        theta_width = min(dtheta, 2*pi - dtheta)\n",
    "        if dtheta <= pi:  # can take angle as-is\n",
    "            theta_mid= (theta1 + theta2)/2 #np.deg2rad((theta1 + theta2)/2)\n",
    "        else:\n",
    "            # the middle angle clockwise needs to be mirrored around the origin. Done by subtracting pi.\n",
    "            theta_mid = (theta1 + theta2)/2 - pi\n",
    "    return (theta_mid, theta_width)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = []  # list of [theta_mid, height, theta_width, bottom, color]\n",
    "seizure_indicators = []  # list of (theta, r_max = height + r_0, color)\n",
    "r_0 = 0.2\n",
    "r_top = 0.4\n",
    "for indices, row in pt.iterrows(): # (uuid_matched, mouse_id, mouse_index), df[theta_inj_top/r][sz/sd1/sd2]\n",
    "    # get one or two sectors \n",
    "    # get sd1\n",
    "    theta_mid, theta_width = getSectorAnglesForVectors(row[\"theta_inj_top\"][\"sz\"], row[\"theta_inj_top\"][\"sd1\"], False, \"ccw\")\n",
    "    color = color_scheme[indices[2]][len(event_types) - event_types.index(\"sd1\")]\n",
    "    height = r_top - r_0\n",
    "    sectors.append([theta_mid, height, theta_width, r_0, color])\n",
    "    r_top += 0.2    \n",
    "    # get sd2 (if exists)\n",
    "    if not np.isnan(row[\"theta_inj_top\"][\"sd2\"]):\n",
    "        theta_mid, theta_width = getSectorAnglesForVectors(row[\"theta_inj_top\"][\"sz\"], row[\"theta_inj_top\"][\"sd2\"], False, \"ccw\")\n",
    "        color = color_scheme[indices[2]][len(event_types) - event_types.index(\"sd2\")]\n",
    "        height = r_top - r_0\n",
    "        sectors.append([theta_mid, height, theta_width, r_0, color])\n",
    "    # get seizure direction for showing as line\n",
    "    color = color_scheme[indices[2]][len(event_types) - event_types.index(\"sz\")]\n",
    "    seizure_indicators.append((row[\"theta_inj_top\"][\"sz\"], r_top, color))\n",
    "    r_top += 0.4\n",
    "    \n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, projection='polar')\n",
    "\n",
    "# sort by descending outer perimeter so all of them visible by plotting smaller on top of larger sectors\n",
    "i_sector = len(sectors) -1\n",
    "while i_sector > 0:\n",
    "    sector = sectors[i_sector]\n",
    "    ax.bar(x=sector[0], height=sector[1], width=sector[2], bottom=sector[3], color=sector[4], edgecolor=\"grey\")\n",
    "    i_sector -= 1\n",
    "# seizure direction\n",
    "for sz_ind in seizure_indicators:\n",
    "    ax.annotate('', xy=(sz_ind[0], sz_ind[1]), xytext=(0, 0),\n",
    "            arrowprops=dict(facecolor=\"black\", edgecolor='none', width=1, headwidth=4, alpha=0.9))\n",
    "# set the radial limits\n",
    "max_r = sectors[-1][1] + sectors[-1][3]\n",
    "\n",
    "ax.set_ylim(0, max_r)\n",
    "#ax.set_rgrids(np.linspace(0, max_r+1, num=len(event_types)+1))\n",
    "#ax.set_yticklabels([\"\"] + event_types)\n",
    "ax.set_xticklabels(['', '', 'medial/injection', '', '', '', 'lateral', ''], fontsize=20)  # top direction should be \"medial/injection\"\n",
    "\n",
    "    \n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26b2a6",
   "metadata": {},
   "source": [
    "# Change seaborn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a1ac5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cce5406",
   "metadata": {},
   "source": [
    "## Bar plot angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles_v2 = pd.DataFrame(angles_dict_v2)  # this dict contains sd1-sd2 angles too\n",
    "df_angles_v2[\"angle_deg\"] = df_angles_v2[\"angle\"].apply(lambda rad: 360.*rad/(2*pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f162eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "sns.barplot(data=df_angles_v2, x=\"mouse_id\", y=\"angle_deg\", hue=\"angle_type\", errorbar=\"sd\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857ef738",
   "metadata": {},
   "source": [
    "### Try semi-circular plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f39ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_colors = {\"sz-sd1\" : \"blue\", \"sz-sd2\" : \"lightgreen\", \"sd1-sd2\": \"yellow\"}\n",
    "#mouse_colors = {\"T301\" : \"blue\", \"T333\" : \"green\", \"T329\" : \"red\", \"T352\" : \"orange\"}\n",
    "mouse_colors = {\"T301\": color_palette[0], \"T333\": color_palette[1], \"T329\": color_palette[2], \"T352\": color_palette[3]}\n",
    "bar_height=20\n",
    "r0 = 100\n",
    "\n",
    "fig = plt.figure(figsize=(18,12))\n",
    "ax_szsd1 = fig.add_subplot(131, projection='polar')\n",
    "ax_szsd2 = fig.add_subplot(132, projection='polar')\n",
    "ax_sd1sd2 = fig.add_subplot(133, projection='polar')\n",
    "ax_szsd1.set_title(\"Sz-SD1\", fontsize=24)\n",
    "ax_szsd2.set_title(\"Sz-SD2\", fontsize=24)\n",
    "ax_sd1sd2.set_title(\"SD1-SD2\", fontsize=24)\n",
    "\n",
    "ax_dict = {\"sz-sd1\" : ax_szsd1, \"sz-sd2\" : ax_szsd2, \"sd1-sd2\" : ax_sd1sd2}\n",
    "r_dict = {\"sz-sd1\" : 400, \"sz-sd2\" : 400, \"sd1-sd2\"  : 400}\n",
    "\n",
    "for i_row, row in df_angles_v2.sort_values(by=\"mouse_id\").dropna().iterrows():\n",
    "    angle = row[\"angle\"]\n",
    "    mid_angle = angle/2.\n",
    "    ax_choice = ax_dict[row[\"angle_type\"]]\n",
    "    ax_choice.bar(x=mid_angle, height=bar_height, width=angle, bottom=r_dict[row[\"angle_type\"]]-bar_height, color=mouse_colors[row[\"mouse_id\"]], edgecolor=\"grey\")\n",
    "    r_dict[row[\"angle_type\"]] -=bar_height\n",
    "\n",
    "ax_szsd1.axis(xmin=0.,xmax=math.pi)\n",
    "ax_szsd2.axis(xmin=0.,xmax=math.pi)\n",
    "ax_sd1sd2.axis(xmin=0.,xmax=math.pi)    \n",
    "ax_szsd1.axes.get_yaxis().set_visible(False)\n",
    "ax_szsd2.axes.get_yaxis().set_visible(False)\n",
    "ax_sd1sd2.axes.get_yaxis().set_visible(False)  \n",
    "    \n",
    "if save_figs:\n",
    "    fig_fpath = os.path.join(output_folder, f'relative_angles_all_mice_{get_datetime_for_fname()}{file_format}')\n",
    "    plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "    print(f\"Saved to {fig_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75438d7e",
   "metadata": {},
   "source": [
    "### Plot per mouse, per angle type the mean + SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc359fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.catplot(\n",
    "#    data=df_angles_v2.groupby([\"mouse_id\", \"angle_type\"]).mean().reset_index(), kind=\"bar\",\n",
    "#    x=\"angle_type\", y=\"angle_deg\", hue=\"mouse_id\",\n",
    "#    errorbar=\"se\", palette=\"dark\", alpha=.6, height=6\n",
    "#)\n",
    "#fig = plt.figure(figsize=(18,18))\n",
    "# need to sort by mouse ID to match color coding with other plots (circular bar plot, for example)\n",
    "sns.catplot(data=df_angles_v2.replace({\"sz-sd1\":\"Sz-SD1\", \"sz-sd2\":\"Sz-SD2\", \"sd1-sd2\":\"SD1-SD2\"}).rename(columns={\"mouse_id\":\"mouse ID\"}).sort_values(by=\"mouse ID\"), kind=\"bar\", x=\"angle_type\", y=\"angle_deg\", hue=\"mouse ID\", palette=color_palette, errorbar=\"sd\",height=6)\n",
    "plt.xlabel('Angle type')\n",
    "plt.ylabel('Angle')\n",
    "if save_figs:\n",
    "    out_fpath = os.path.join(env_dict[\"DOWNLOADS_FOLDER\"], f\"relative_angles_barplot_{get_datetime_for_fname()}{file_format}\")\n",
    "    plt.savefig(out_fpath,bbox_inches='tight', dpi=300)\n",
    "    print(f\"Saved as {out_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee76f5e",
   "metadata": {},
   "source": [
    "### Plot angles grouped by angle type only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79027af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,8))\n",
    "sns.barplot(data=df_angles_v2.replace({\"sz-sd1\":\"Sz-SD1\", \"sz-sd2\":\"Sz-SD2\", \"sd1-sd2\":\"SD1-SD2\"}).rename(columns={\"mouse_id\":\"mouse ID\"}).sort_values(by=\"mouse ID\"), x=\"angle_type\", y=\"angle_deg\", errorbar=\"se\", color=\"lightgrey\")\n",
    "plt.xlabel('Angle type')\n",
    "plt.ylabel('Angle')\n",
    "\n",
    "if save_figs:\n",
    "    fig_fpath = os.path.join(output_folder, f'barplot_meanSEM_per_angle_type{get_datetime_for_fname()}{file_format}')\n",
    "    plt.savefig(fig_fpath)\n",
    "    print(f\"Saved to {fig_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c059c567",
   "metadata": {},
   "source": [
    "## Combine semicircle barplot with barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7c5f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_colors = {\"sz-sd1\" : \"blue\", \"sz-sd2\" : \"lightgreen\", \"sd1-sd2\": \"yellow\"}\n",
    "mouse_colors = {\"T301\": color_palette[0], \"T333\": color_palette[1], \"T329\": color_palette[2], \"T352\": color_palette[3]}\n",
    "bar_height=20\n",
    "r0 = 100\n",
    "\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "ax_szsd1 = fig.add_subplot(221, projection='polar')\n",
    "ax_szsd2 = fig.add_subplot(222, projection='polar')\n",
    "ax_sd1sd2 = fig.add_subplot(223, projection='polar')\n",
    "ax_barplot = fig.add_subplot(224)\n",
    "ax_szsd1.set_title(\"Sz-SD1\", fontsize=24)\n",
    "ax_szsd2.set_title(\"Sz-SD2\", fontsize=24)\n",
    "ax_sd1sd2.set_title(\"SD1-SD2\", fontsize=24)\n",
    "\n",
    "\n",
    "ax_dict = {\"sz-sd1\" : ax_szsd1, \"sz-sd2\" : ax_szsd2, \"sd1-sd2\" : ax_sd1sd2}\n",
    "r_dict = {\"sz-sd1\" : 400, \"sz-sd2\" : 400, \"sd1-sd2\"  : 400}\n",
    "\n",
    "for i_row, row in df_angles_v2.sort_values(by=\"mouse_id\").dropna().iterrows():\n",
    "    angle = row[\"angle\"]\n",
    "    mid_angle = angle/2.\n",
    "    ax_choice = ax_dict[row[\"angle_type\"]]\n",
    "    ax_choice.bar(x=mid_angle, height=bar_height, width=angle, bottom=r_dict[row[\"angle_type\"]]-bar_height, color=mouse_colors[row[\"mouse_id\"]], edgecolor=\"grey\")\n",
    "    r_dict[row[\"angle_type\"]] -=bar_height\n",
    "\n",
    "sns.barplot(data=df_angles_v2.replace({\"sz-sd1\":\"Sz-SD1\", \"sz-sd2\":\"Sz-SD2\", \"sd1-sd2\":\"SD1-SD2\"}).rename(columns={\"mouse_id\":\"mouse ID\"}).sort_values(by=\"mouse ID\"), x=\"angle_type\", y=\"angle_deg\", color=\"lightgrey\", errorbar=\"se\", ax=ax_barplot)\n",
    "plt.xlabel('Angle type')\n",
    "plt.ylabel('Angle')\n",
    "\n",
    "ax_szsd1.axes.get_yaxis().set_visible(False)\n",
    "ax_szsd2.axes.get_yaxis().set_visible(False)\n",
    "ax_sd1sd2.axes.get_yaxis().set_visible(False)\n",
    "ax_szsd1.axis(xmin=0.,xmax=math.pi)\n",
    "ax_szsd2.axis(xmin=0.,xmax=math.pi)\n",
    "ax_sd1sd2.axis(xmin=0.,xmax=math.pi)\n",
    "    \n",
    "if save_figs:\n",
    "    fig_fpath = os.path.join(output_folder, f'relative_angles_plus_barplot_{get_datetime_for_fname()}{file_format}')\n",
    "    plt.savefig(fig_fpath)\n",
    "    print(f\"Saved to {fig_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409360ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: dataset assumed to be unimodal (one clump distribution for seizure, for sd1, for sd2...). \n",
    "# q-q plot for comparison between groups?\n",
    "# TODO: Fisher circular statistics p. 47-: mean direction, mean resultant length!!! Circular standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316ac5e",
   "metadata": {},
   "source": [
    "# Speed analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8895bef",
   "metadata": {},
   "source": [
    "## SD speed based on grid approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDSpeedsTileAlgorithm(i_wave):  \n",
    "    # i_wave should be 1 or 2\n",
    "    # returns a tuple:\n",
    "    # uuids: a list of the uuids, and a 2d list of velocities: an array of all calculated velocities per session (uuid_extended)\n",
    "    uuids = []\n",
    "    vs_2d = []\n",
    "    \n",
    "    \n",
    "    for i_group, session_group in all_onsets_df[all_onsets_df[f\"onset{i_wave}\"].notna()].groupby(\"uuid_extended\"):\n",
    "        print(session_group.describe())\n",
    "        tiles_group = session_group.groupby(\"tile\").median()  # TODO: the center values should be mean, not median!\n",
    "        x_y_onset = np.array([tiles_group[\"x\"], tiles_group[\"y\"], tiles_group[\"onset\" + str(i_wave)]])\n",
    "        x_y_onset = x_y_onset.T  # x_y_onset1[i] = [x_i, y_i, onset1_i]\n",
    "        n_tiles = len(x_y_onset)\n",
    "        \n",
    "        # 1. find all tiles with later onset\n",
    "        #      boolean array of arrays: in a row i, value at index j is True if onset j is greater than onset i. \n",
    "        larger_values = x_y_onset[:, 2][:, np.newaxis] < x_y_onset[:, 2]\n",
    "        #      convert True/False into index. Use fact that within a row, i-th element corresponds to index i. Put np.inf if not larger\n",
    "        larger_indices = np.where(larger_values, np.arange(n_tiles), np.inf)\n",
    "        # 2. find all tile distances\n",
    "        dist_matrix = distance_matrix(x_y_onset[:,:2],x_y_onset[:,:2])\n",
    "        #      dist_matrix: each row contains distance to all the other tiles. inf if same tile! (diagonal)\n",
    "        assert (dist_matrix == dist_matrix.T).all()  # symmetric\n",
    "        np.fill_diagonal(dist_matrix, np.inf)  # exclude tile itself from being nearest neighbor\n",
    "        later_tiles_distances = np.where(np.isfinite(larger_indices), dist_matrix, np.inf)\n",
    "        nearest_indices_later_onset = np.argmin(later_tiles_distances, axis=1)\n",
    "        vs = np.zeros(n_tiles)\n",
    "        for i_tile, tile_nearest_indices in enumerate(nearest_indices_later_onset):\n",
    "            if np.isinf(later_tiles_distances[i_tile]).all():  #  a later onset neuron is actually found\n",
    "                continue\n",
    "            else:\n",
    "                i_nearest_later = tile_nearest_indices\n",
    "                ds = dist_matrix[i_tile][i_nearest_later] * 1.579  # objective conversion factor  -> [pixel] * [m] / [pixel]\n",
    "                dt = (x_y_onset[i_nearest_later][2] - x_y_onset[i_tile][2]) / 15.0  # [frames] / ([frames]/[second]) \n",
    "                vs[i_tile] = ds/dt\n",
    "        vs_2d.append(vs)\n",
    "        uuids.append(i_group)\n",
    "    vs_flat = [item for vs_row in vs_2d for item in vs_row]\n",
    "    v_median = np.median(vs_flat)\n",
    "    print(f\"{v_median} m/s = {v_median*6./100.} mm/min\") \n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    plt.hist(vs_flat, bins=150)\n",
    "    plt.show()\n",
    "    return (uuids, vs_2d)  # in m/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids_grid1, vs_grid1 = SDSpeedsTileAlgorithm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb467ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids_grid2, vs_grid2 = SDSpeedsTileAlgorithm(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe077415",
   "metadata": {},
   "source": [
    "## SD speed based on cell approach\n",
    "Algorithm stays same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f225f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "later_neurons_distances = [[1., 2.5, np.inf, 2.4], [np.inf, 1.5, np.inf, np.inf], [np.inf, np.inf, np.inf, np.inf], [1.6, 1.8, 2.5, 1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76422eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_indices_later_onset = np.argsort(later_neurons_distances, axis=1)[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb98ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_indices_later_onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3fa6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDSpeedsCellAlgorithm(i_wave, n_neighbors=1, plot_res = False, vectorize = False):  \n",
    "    # i_wave should be 1 or 2\n",
    "    # n_neighbors: average the closest n_neighbors cells (with a later onset)\n",
    "    # plot_res: whether to plot the results (histogram with all velocities)\n",
    "    # vectorize: whether to return not only the velocity, but in addition, the 2d vector velocity, as well as the centre of the neuron.\n",
    "    # returns a tuple:\n",
    "    # uuids: a list of the uuids, and a 2d list of velocities: an array of all calculated velocities per session (uuid_extended)\n",
    "    uuids = []\n",
    "    vs_2d = []\n",
    "    neuron_ids = np.array([], dtype=np.int16)\n",
    "    \n",
    "    if vectorize:\n",
    "        dx_2d = []\n",
    "        dy_2d = []\n",
    "        centres_x = np.array([])  # the centre coordinate of each neuron. Same as \"x\" column in all_onsets_df.\n",
    "        centres_y = np.array([])\n",
    "    for i_group, session_group in all_onsets_df.groupby(\"uuid_extended\"):\n",
    "        # TODO: the center values should be mean, not median!\n",
    "        x_y_onset = np.array([session_group[\"x\"], session_group[\"y\"], session_group[\"onset\" + str(i_wave)]])\n",
    "        x_y_onset = x_y_onset.T  # x_y_onset1[i] = [x_i, y_i, onset1_i]\n",
    "        n_neurons = len(x_y_onset)\n",
    "        neuron_ids_curr_session = np.array(session_group[\"neuron_id\"], dtype=np.int16)\n",
    "        neuron_ids = np.concatenate([neuron_ids, neuron_ids_curr_session])\n",
    "        # contains (mean) x/y distance to nearest neighbor for each neuron\n",
    "        dx_session = np.zeros(n_neurons, dtype=np.float64)\n",
    "        dy_session = np.zeros(n_neurons, dtype=np.float64)\n",
    "        \n",
    "        # 1. find all neurons with later onset\n",
    "        #      boolean array of arrays: in a row i, value at index j is True if onset j is greater than onset i. \n",
    "        larger_values = x_y_onset[:, 2][:, np.newaxis] < x_y_onset[:, 2]\n",
    "        #      convert True/False into index. Use fact that within a row, i-th element corresponds to index i. Put np.inf if not larger\n",
    "        larger_indices = np.where(larger_values, np.arange(n_neurons), np.inf)\n",
    "        # 2. find all neuron distances\n",
    "        dist_matrix = distance_matrix(x_y_onset[:,:2],x_y_onset[:,:2])\n",
    "        #      dist_matrix: each row contains distance to all the other tiles. inf if same tile! (diagonal)\n",
    "        assert (dist_matrix == dist_matrix.T).all()  # symmetric\n",
    "        np.fill_diagonal(dist_matrix, np.inf)  # exclude tile itself from being nearest neighbor\n",
    "        # find distances neurons with later onset\n",
    "        later_neurons_distances = np.where(np.isfinite(larger_indices), dist_matrix, np.inf)\n",
    "        # find closest neurons with later onset\n",
    "        nearest_indices_later_onset = np.argsort(later_neurons_distances, axis=1)[:,:n_neighbors]\n",
    "        # calculate velocity with all neighbors above\n",
    "        vs = np.zeros(n_neurons)\n",
    "        if vectorize:\n",
    "            dxs = np.zeros(n_neurons)\n",
    "            dys = np.zeros(n_neurons)\n",
    "        for i_neuron, neuron_nearest_indices in enumerate(nearest_indices_later_onset):\n",
    "            if np.isinf(later_neurons_distances[i_neuron]).all():  #  a later onset neuron is actually found\n",
    "                continue\n",
    "            else:       \n",
    "                if isinstance(neuron_nearest_indices, Iterable):\n",
    "                    v_neighbors_list = np.zeros(len(neuron_nearest_indices))  \n",
    "                    if vectorize:\n",
    "                        dx_neighbors_list = np.zeros(len(neuron_nearest_indices))  \n",
    "                        dy_neighbors_list = np.zeros(len(neuron_nearest_indices))  \n",
    "                    \n",
    "                    for i_neighbor, index_neighbor in enumerate(neuron_nearest_indices):\n",
    "                        ds = dist_matrix[i_neuron][index_neighbor] * 1.579  # objective conversion factor  -> [pixel] * [m] / [pixel]\n",
    "                        dt = (x_y_onset[index_neighbor][2] - x_y_onset[i_neuron][2]) / 15.0  # [frames] / ([frames]/[second]) \n",
    "                        v_neighbor = ds/dt\n",
    "                        v_neighbors_list[i_neighbor] = v_neighbor\n",
    "                        if vectorize:  # \n",
    "                            # get x, y of current neighbor\n",
    "                            x_nearest = x_y_onset[index_neighbor][0]\n",
    "                            y_nearest = x_y_onset[index_neighbor][1]\n",
    "                            # get x, y of current neuron\n",
    "                            x_curr = x_y_onset[i_neuron][0]\n",
    "                            y_curr = x_y_onset[i_neuron][1]\n",
    "                            # get dx, dy\n",
    "                            dx = x_nearest - x_curr\n",
    "                            dy = y_nearest - y_curr\n",
    "                            dx_neighbors_list[i_neighbor] = dx\n",
    "                            dy_neighbors_list[i_neighbor] = dy\n",
    "                        \n",
    "                        \n",
    "                    vs[i_neuron] = np.median(v_neighbors_list) \n",
    "                    if vectorize:\n",
    "                        dxs[i_neuron] = np.mean(dx_neighbors_list)\n",
    "                        dys[i_neuron] = np.mean(dy_neighbors_list)\n",
    "                        \n",
    "                else:\n",
    "                    ds = dist_matrix[i_neuron][neuron_nearest_indices[0]] * 1.579  # objective conversion factor  -> [pixel] * [m] / [pixel]\n",
    "                    dt = (x_y_onset[neuron_nearest_indices[0]][2] - x_y_onset[i_neuron][2]) / 15.0  # [frames] / ([frames]/[second]) \n",
    "                    vs[i_neuron] = ds/dt\n",
    "        vs_2d.append(vs)\n",
    "        uuids.append(i_group)\n",
    "        if vectorize:\n",
    "            centres_x = np.concatenate([centres_x, session_group[\"x\"]])\n",
    "            centres_y = np.concatenate([centres_y, session_group[\"y\"]])\n",
    "            dx_2d.append(dxs)\n",
    "            dy_2d.append(dys)\n",
    "            \n",
    "    vs_flat = [item for vs_row in vs_2d for item in vs_row]\n",
    "    v_median = np.median(vs_flat)\n",
    "    print(f\"{v_median} m/s = {v_median*6./100.} mm/min\") \n",
    "    if plot_res:\n",
    "        fig = plt.figure(figsize=(16,8))\n",
    "        plt.hist(vs_flat, bins=150)\n",
    "        plt.show()\n",
    "    if vectorize:\n",
    "        return (uuids, neuron_ids, vs_2d, dx_2d, dy_2d, centres_x, centres_y)\n",
    "    else:\n",
    "        return (uuids, neuron_ids, vs_2d)  # in m/s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07afbbd9",
   "metadata": {},
   "source": [
    "### Set number of neighbors to find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbeb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids_neuron1, ids_neuron1, vs_neuron1 = SDSpeedsCellAlgorithm(1,N_NEIGHBORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f79237",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids_neuron2, ids_neuron2, vs_neuron2 = SDSpeedsCellAlgorithm(2,N_NEIGHBORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031b729",
   "metadata": {},
   "source": [
    "## Create dataframe from results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfc68e3",
   "metadata": {},
   "source": [
    "### SD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten all arrays\n",
    "vs_neuron1_flat = [element for sublist in vs_neuron1 for element in sublist]\n",
    "uuids_neuron1_flat = [uuids_neuron1[i] for i, neurons in enumerate(vs_neuron1) for j in range(len(neurons))]\n",
    "assert len(vs_neuron1_flat) == len(uuids_neuron1_flat)\n",
    "# create mean velocity for all sessions\n",
    "vs_neuron1_mean = [np.median(element) for element in vs_neuron1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee284f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid algorithm\n",
    "# flatten all arrays\n",
    "vs_grid1_flat = [element for sublist in vs_grid1 for element in sublist]\n",
    "uuids_grid1_flat = [uuids_grid1[i] for i, tiles in enumerate(vs_grid1) for j in range(len(tiles))]\n",
    "assert len(vs_grid1_flat) == len(uuids_grid1_flat)\n",
    "# create mean velocity for all sessions\n",
    "vs_grid1_mean = [np.median(element) for element in vs_grid1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47347ef0",
   "metadata": {},
   "source": [
    "### SD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_neuron2_flat = [element for sublist in vs_neuron2 for element in sublist]\n",
    "uuids_neuron2_flat = [uuids_neuron1[i] for i, neurons in enumerate(vs_neuron2) for j in range(len(neurons))]\n",
    "assert len(vs_neuron2_flat) == len(uuids_neuron2_flat)\n",
    "# create mean velocity for all sessions\n",
    "vs_neuron2_mean = [np.mean(element) for element in vs_neuron2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc2f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_grid2_flat = [element for sublist in vs_grid2 for element in sublist]\n",
    "uuids_grid2_flat = [uuids_grid1[i] for i, tiles in enumerate(vs_grid2) for j in range(len(tiles))]\n",
    "assert len(vs_grid2_flat) == len(uuids_grid2_flat)\n",
    "# create mean velocity for all sessions\n",
    "vs_grid2_mean = [np.mean(element) for element in vs_grid2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b508eac",
   "metadata": {},
   "source": [
    "## Create data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid-based algorithm\n",
    "vs_grid_df1 = pd.DataFrame({\"uuid\": uuids_grid1_flat, \"v_umps\": vs_grid1_flat, \"i_wave\": 1})  # all velocities calculated\n",
    "vs_grid_df1_means = pd.DataFrame({\"uuid\": uuids_grid1, \"v_umps\": vs_grid1_mean, \"i_wave\": 1})\n",
    "vs_grid_df2 = pd.DataFrame({\"uuid\": uuids_grid2_flat, \"v_umps\": vs_grid2_flat, \"i_wave\": 2})\n",
    "vs_grid_df2_means = pd.DataFrame({\"uuid\": uuids_grid2, \"v_umps\": vs_grid2_mean, \"i_wave\": 2})\n",
    "\n",
    "# reset index, but keep old index just in case\n",
    "vs_grid_df = pd.concat([vs_grid_df1, vs_grid_df2], axis=0).reset_index()\n",
    "vs_grid_df_means = pd.concat([vs_grid_df1_means, vs_grid_df2_means], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron-based algorithm\n",
    "vs_df1 = pd.DataFrame({\"uuid\": uuids_neuron1_flat, \"v_umps\": vs_neuron1_flat, \"i_wave\": 1})  # all velocities calculated\n",
    "vs_df1_means = pd.DataFrame({\"uuid\": uuids_neuron1, \"v_umps\": vs_neuron1_mean, \"i_wave\": 1})\n",
    "vs_df2 = pd.DataFrame({\"uuid\": uuids_neuron2_flat, \"v_umps\": vs_neuron2_flat, \"i_wave\": 2})  # all velocities calculated\n",
    "vs_df2_means = pd.DataFrame({\"uuid\": uuids_neuron2, \"v_umps\": vs_neuron2_mean, \"i_wave\": 2})\n",
    "\n",
    "# reset index, but keep old index just in case\n",
    "vs_df = pd.concat([vs_df1, vs_df2], axis=0).reset_index()\n",
    "vs_df_means = pd.concat([vs_df1_means, vs_df2_means], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59467ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of 0 values\n",
    "vs_df = vs_df[vs_df[\"v_umps\"] > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9eb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: check this warning. Maybe it is due to the split() and it is not a problem?\n",
    "vs_df[\"mouse_id\"] = vs_df.apply(lambda row: ddoc.getMouseIdForUuid(row[\"uuid\"].split(\"_\")[0]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309757e5",
   "metadata": {},
   "source": [
    "### Add mm/min\n",
    "1 m/s = 60 m/min = 0.06 mm/min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c6e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONVERSION_FACTOR = 0.06\n",
    "\n",
    "vs_grid_df[\"v_mmpmin\"] = vs_grid_df[\"v_umps\"] * CONVERSION_FACTOR\n",
    "vs_grid_df_means[\"v_mmpmin\"] = vs_grid_df_means[\"v_umps\"] * CONVERSION_FACTOR\n",
    "vs_df[\"v_mmpmin\"] = vs_df[\"v_umps\"] * CONVERSION_FACTOR\n",
    "vs_df_means[\"v_mmpmin\"] = vs_df_means[\"v_umps\"] * CONVERSION_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efe0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.hist(vs_df[(vs_df[\"v_mmpmin\"] < 100) & (vs_df[\"i_wave\"] == 2)][\"v_mmpmin\"], bins=100)\n",
    "plt.xlim((0,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b29aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: group by uuid and i_wave (pivot_table) and make boxplot with sem\n",
    "means_per_session = vs_df.groupby([\"mouse_id\", \"uuid\", \"i_wave\"]).median().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "sns.barplot(means_per_session, x=\"i_wave\", y=\"v_mmpmin\", hue=\"mouse_id\", errorbar=\"se\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42492e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.hist(vs_df[(vs_df[\"v_mmpmin\"] < 100)][\"v_mmpmin\"], bins=100)\n",
    "plt.xlim((0,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45063a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2323e54",
   "metadata": {},
   "source": [
    "### Plot velocity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histVelocities(vs_df):\n",
    "    f, ax = plt.subplots(figsize=(12, 10))\n",
    "    sns.despine(f)\n",
    "    sns.histplot(vs_df, x=\"v_mmpmin\", hue=\"uuid\", multiple=\"stack\")\n",
    "    ax.set_ylim((0,600))\n",
    "    ax.set_xlim((0,1500))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421950ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histVelocities(vs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histVelocities(vs_grid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8740e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxPlotMeanSDVelocity(vs_df_means):\n",
    "    fig = plt.figure(figsize=(6,10))\n",
    "    sns.barplot(\n",
    "        vs_df_means, x=\"i_wave\", y=\"v_mmpmin\", errorbar=\"se\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15cc3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxPlotMeanSDVelocity(vs_df_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d664ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxPlotMeanSDVelocity(vs_grid_df_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6fa2b",
   "metadata": {},
   "source": [
    "## Do the same for several n_neighbors settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2])\n",
    "b = np.array([3,4])\n",
    "np.concatenate([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9cefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_neighbors = 10\n",
    "neuron_means_multi_dict = {\"uuid\": [], \"i_wave\": [], \"n_neighbors\" : [], \"v_umps\":[]}\n",
    "\n",
    "v_umps = np.array([])\n",
    "\n",
    "for i_wave in range(2):\n",
    "    for i_neighbors in range(1,n_max_neighbors+1):\n",
    "        uuids, neuron_ids, vs = SDSpeedsCellAlgorithm(i_wave+1,i_neighbors)  # i_wave is 0-indexing, function takes 1-indexing\n",
    "        vs_mean = np.array([np.median(element[element > 0.0]) for element in vs])\n",
    "        neuron_means_multi_dict[\"uuid\"] += uuids\n",
    "        neuron_means_multi_dict[f\"i_wave\"] += [i_wave+1 for i in range(len(uuids))]\n",
    "        neuron_means_multi_dict[\"n_neighbors\"] += [i_neighbors for i in range(len(uuids))]\n",
    "        v_umps = np.concatenate([v_umps, vs_mean])\n",
    "        \n",
    "neuron_means_multi_dict[f\"v_umps\"] = v_umps\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb433eff",
   "metadata": {},
   "source": [
    "### Create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_means_multi_df = pd.DataFrame(neuron_means_multi_dict)\n",
    "neuron_means_multi_df[\"v_mmpmin\"] =  neuron_means_multi_df[\"v_umps\"] * CONVERSION_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec52952",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "sns.barplot(neuron_means_multi_df, x=\"i_wave\", y=\"v_mmpmin\", hue=\"n_neighbors\", errorbar=\"se\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neuron_means_multi_dict[\"v_umps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b2be0",
   "metadata": {},
   "source": [
    "# Check quality of estimation visually\n",
    "perform the nearest later neighbor extraction with vectorize=True, plot as arrows with center of each neuron the nearest neighbors, or the velocity (multiply [dx, dy] by v/sqrt(dx^2 + dy^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f240a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizedVDF(i_wave=1, n_neighbors=1):  # i_wave: 1 or 2, n_neighbors: 1, 2, ...\n",
    "    # results are a list of numpy arrays, one array per recording \n",
    "    uuids_neuron1, ids_neuron1, vs_neuron1, dx_neuron1, dy_neuron1, centres_x_neuron1, centres_y_neuron1 = SDSpeedsCellAlgorithm(i_wave,n_neighbors,False,True)\n",
    "\n",
    "    # flatten all arrays\n",
    "    vs_flat = [element for sublist in vs_neuron1 for element in sublist]\n",
    "    uuids_flat = [uuids_neuron1[i] for i, neurons in enumerate(vs_neuron1) for j in range(len(neurons))]\n",
    "    dx_flat = [element for sublist in dx_neuron1 for element in sublist]\n",
    "    dy_flat = [element for sublist in dy_neuron1 for element in sublist]\n",
    "\n",
    "    #ids_neuron1, centres_x_neuron1, centres_y_neuron1 are already flat\n",
    "    assert len(vs_neuron1_flat) == len(uuids_neuron1_flat)\n",
    "    # create mean velocity for all sessions\n",
    "    vs_neuron1_mean = [np.median(element) for element in vs_neuron1]\n",
    "    vector_vs_df = pd.DataFrame({\"uuid\": uuids_flat, \"neuron_id\": ids_neuron1, \"v\": vs_flat, \"dx\": dx_flat, \"dy\": dy_flat, \"x0\": centres_x_neuron1, \"y0\": centres_y_neuron1, \"i_wave\": [i_wave for i in range(len(centres_y_neuron1))]})\n",
    "    return vector_vs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec222307",
   "metadata": {},
   "source": [
    "### Get vector nearest neighbor velocity data for all waves and sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS_VEC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming there are 2 waves at most\n",
    "vector_vs_df = vectorizedVDF(1, N_NEIGHBORS_VEC)\n",
    "vector_vs_df = pd.concat([vector_vs_df, vectorizedVDF(2, N_NEIGHBORS_VEC)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d0634",
   "metadata": {},
   "source": [
    "## Plot velocities calculated for first look of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_uuid = 9\n",
    "print(vector_vs_df[\"uuid\"].unique()[i_uuid])\n",
    "vector_vs_df_single2 = vector_vs_df[(vector_vs_df[\"uuid\"] == vector_vs_df[\"uuid\"].unique()[i_uuid]) & (vector_vs_df[\"i_wave\"] == 2)]\n",
    "vector_vs_df_single1 = vector_vs_df[(vector_vs_df[\"uuid\"] == vector_vs_df[\"uuid\"].unique()[i_uuid]) & (vector_vs_df[\"i_wave\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# throw away outliers\n",
    "v_90_percent2 = vector_vs_df_single2[\"v\"].quantile(0.9)\n",
    "vector_vs_df_single2_outliers = vector_vs_df_single2[vector_vs_df_single2[\"v\"] > v_90_percent2]\n",
    "vector_vs_df_single2_rest = vector_vs_df_single2[vector_vs_df_single2[\"v\"] <= v_90_percent2]\n",
    "\n",
    "v_90_percent1 = vector_vs_df_single1[\"v\"].quantile(0.9)\n",
    "vector_vs_df_single1_outliers = vector_vs_df_single1[vector_vs_df_single1[\"v\"] > v_90_percent1]\n",
    "vector_vs_df_single1_rest = vector_vs_df_single1[vector_vs_df_single1[\"v\"] <= v_90_percent1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,18))\n",
    "ax.quiver(vector_vs_df_single1_rest['x0'], vector_vs_df_single1_rest['y0'], vector_vs_df_single1_rest['dx'], vector_vs_df_single1_rest['dy'], color='blue', angles='xy', scale_units='xy', scale=1)\n",
    "ax.quiver(vector_vs_df_single1_outliers['x0'], vector_vs_df_single1_outliers['y0'], vector_vs_df_single1_outliers['dx'], vector_vs_df_single1_outliers['dy'], color='r', angles='xy', scale_units='xy', scale=1)\n",
    "plt.axis(\"off\")\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,18))\n",
    "ax.quiver(vector_vs_df_single2_rest['x0'], vector_vs_df_single2_rest['y0'], vector_vs_df_single2_rest['dx'], vector_vs_df_single2_rest['dy'], color='blue', angles='xy', scale_units='xy', scale=1)\n",
    "ax.quiver(vector_vs_df_single2_outliers['x0'], vector_vs_df_single2_outliers['y0'], vector_vs_df_single2_outliers['dx'], vector_vs_df_single2_outliers['dy'], color='r', angles='xy', scale_units='xy', scale=1)\n",
    "plt.axis(\"off\")\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e34fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,18))\n",
    "ax.scatter(vector_vs_df_single2_rest['x0'], vector_vs_df_single2_rest['y0'])\n",
    "ax.scatter(vector_vs_df_single2_outliers['x0'], vector_vs_df_single2_outliers['y0'],)\n",
    "plt.axis(\"off\")\n",
    "ax.invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14068ffd",
   "metadata": {},
   "source": [
    "# Compare within-mouse directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406e676",
   "metadata": {},
   "source": [
    "Two dfs that can be used: `df_angles_per_event`, defined below, contains all events (sz, sd1, sd2) with their angles aligned in a top injection frame. `df_angles_v2` contains for each seizure event (sz, sd1, sd2) the pairwise angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868ee4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_angles_v2\n",
    "df_angles_per_event = qdf.drop(columns=[\"row\", \"col\", \"neuron_id\", \"onset1\", \"onset2\", \"onset_sz\", \"quantile1\", \"quantile2\", \"quantile_sz\", \"i_sz\", \"costheta_inj_top\", \"sintheta_inj_top\", \"costheta\", \"sintheta\", \"y_mirrored\", \"dx\", \"dy\", \"tile\", \"uuid_extended\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d52965",
   "metadata": {},
   "source": [
    "## Calculate standard deviation of same-event directions\n",
    "i.e. sz-sdx, sd1-sd2 angles are variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab654e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_sz_sd1 = df_angles_v2[df_angles_v2[\"angle_type\"] == \"sz-sd1\"].angle_deg.std()\n",
    "std_sz_sd1 = df_angles_v2[df_angles_v2[\"angle_type\"] == \"sz-sd1\"].angle_deg.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles_per_event[df_angles_per_event[\"uuid_matched\"] == \"2aa75aa234a749668eb896e7e00aa87a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de79b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ratio of recordings with 1 sd only\n",
    "p_two_sd_waves = df_angles_v2[df_angles_v2[\"angle_type\"] == \"sz-sd2\"].angle.notna().sum() / len(df_angles_v2[df_angles_v2[\"angle_type\"] == \"sz-sd2\"].angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d30e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_std(x):\n",
    "    # circstd  # two alternatives: np.std, circstd\n",
    "    return np.std(x, ddof=1)\n",
    "    # return circstd(x)\n",
    "std_func = partial_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e5587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles_std_per_mouse = df_angles_v2.dropna().groupby([\"mouse_id\", \"angle_type\"])[\"angle\"].apply(lambda x: std_func(x)) # df_angles_v2.groupby([\"mouse_id\", \"angle_type\"]).std().angle_deg\n",
    "df_angles_v2[\"dummy\"] = 1  # for summing entries\n",
    "df_n_exps_per_mouse = df_angles_v2[df_angles_v2[\"angle_type\"] == \"sz-sd1\"].groupby(\"mouse_id\").sum().dummy\n",
    "df_angles_v2 = df_angles_v2.drop(columns=\"dummy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ddfa2",
   "metadata": {},
   "source": [
    "## Create surrogate sampling\n",
    "Use circular statistics (mean direction, circular standard deviation):\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.circmean.html#scipy.stats.circmean\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.circstd.html\n",
    "Fisher - Statistical Analysis of Circular Data (48/293, p. 32). Log = ln (log_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318081a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rng = random.SystemRandom() \n",
    "rng = np.random.default_rng(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b72db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomDirectionsAngle(rng, n_angles: int = 2, as_deg = False):\n",
    "    if as_deg:\n",
    "        max_angle = 360.0\n",
    "    else:\n",
    "        max_angle = 2*pi\n",
    "    thetas = [max_angle*rng.random() for i_angle in range(n_angles)]\n",
    "    dthetas = [min(abs(thetas[i]-thetas[0]), max_angle - abs(thetas[i]-thetas[0])) for i in range(1, n_angles)]  # one less angles than in thetas_deg\n",
    "    return (thetas, dthetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogateSample(p_two_sd_waves, rng, n_simulated_mice: int = 1000):\n",
    "    \"\"\"\n",
    "    p_two_sd_waves: observed probability (0-1) of having two SD waves.\n",
    "    n_simulated_mice: the number of times the experiment should be simulated\n",
    "    \"\"\"\n",
    "    all_angles = []\n",
    "    all_diff_angles = []\n",
    "    stds_measured = {\"sz-sd1\": [], \"sz-sd2\": [], \"sd1-sd2\" : []}  # sz-sd1 and sz-sd2 angles\n",
    "    for i_mouse in range(n_simulated_mice):\n",
    "        angles_measured = {\"sz-sd1\": [], \"sz-sd2\": [], \"sd1-sd2\" : []}\n",
    "        # decide number of experiments to run with simulated mouse\n",
    "        n_experiments = df_n_exps_per_mouse.iloc[rng.randint(0, len(df_n_exps_per_mouse) - 1)]  # randint(a, b) for [a, b]\n",
    "        for i_experiment in range(n_experiments):\n",
    "            # decide on number of waves\n",
    "            if rng.random() > p_two_sd_waves:\n",
    "                n_angles = 2  # only sz and sd1\n",
    "            else:\n",
    "                n_angles = 3\n",
    "                \n",
    "            raw_angles, angles_for_exp = randomDirectionsAngle(rng, n_angles)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Add all generated angles to appropriate lists\n",
    "            # to check uniform distribution of generated angles and angles between these simulated vectors\n",
    "            #  FIXME: these two assignments slow down the algorithm by a lot\n",
    "            all_angles = all_angles + raw_angles  \n",
    "            all_diff_angles = all_diff_angles + angles_for_exp\n",
    "            \n",
    "            # record angles measured\n",
    "            angles_measured[\"sz-sd1\"].append(angles_for_exp[0])\n",
    "            if len(angles_for_exp) > 1:\n",
    "                angles_measured[\"sz-sd2\"].append(angles_for_exp[1])\n",
    "            if n_angles == 3:  # also record sd1-sd2 angle if applicable\n",
    "                angle_sd1sd2 = min(abs(raw_angles[2] - raw_angles[1]), 2*pi - abs(raw_angles[2]-raw_angles[1]))\n",
    "                angles_measured[\"sd1-sd2\"].append(angle_sd1sd2)\n",
    "        # calculate std for mouse\n",
    "        stds_measured[\"sz-sd1\"].append(std_func(angles_measured[\"sz-sd1\"]))  # note: angles are in rad, 0 to pi... maybe need to adjust high and low!\n",
    "        if len(angles_measured[\"sz-sd2\"]) > 1:\n",
    "            stds_measured[\"sz-sd2\"].append(std_func(angles_measured[\"sz-sd2\"]))\n",
    "            stds_measured[\"sd1-sd2\"].append(std_func(angles_measured[\"sd1-sd2\"]))\n",
    "    return stds_measured, all_angles, all_diff_angles\n",
    "# old method\n",
    "# surrogate_stds, surrogate_all_angles, surrogate_all_diff_angles = surrogateSample(p_two_sd_waves, rng, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each mouse, go through each angle type. Get the number of angles of that type for the mouse, simulate 1000 times.\n",
    "def simulateMouseAngles(rng, n_experiments = 3, n_simulations = 1000):\n",
    "    std_vals = np.zeros(n_simulations)\n",
    "    for i_simrun in range(n_simulations):\n",
    "        angles = np.zeros(n_experiments)\n",
    "        for i_experiment in range(n_experiments):  # same number of recordings as the mouse had\n",
    "            raw_angles, generated_angle = randomDirectionsAngle(rng, n_angles=2, as_deg=True) \n",
    "            angles[i_experiment] = generated_angle[0] # randomDirectionsAngle returns list\n",
    "        std_vals[i_simrun] = np.std(angles)\n",
    "    return std_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each mouse, each angle type, I need the number of data points available, so I can simulate it. \n",
    "# I should also take the std of these\n",
    "rng = np.random.default_rng(2023)\n",
    "# {mouse_id1: {angle_type1 :  (n_measurements_per_std1, measured_std, np.array([simulated_std1, ...]) ), angle_type2 : (...), ...}, mouse_id2: [...], ...} \n",
    "surrogates_res_dict = {mouse_id: dict() for mouse_id in df_angles_v2.mouse_id.unique()}\n",
    "\n",
    "for (mouse_id, angle_type), grp in df_angles_v2.drop(columns=[\"uuid_matched\", \"angle\", \"cos_angle\"]).dropna().groupby([\"mouse_id\", \"angle_type\"]):\n",
    "    std_deg = np.std(grp.angle_deg)\n",
    "    n_experiments = len(grp.angle_deg)\n",
    "    print(f\"{mouse_id} {angle_type}: {std_deg}, {n_experiments} values per std\")\n",
    "    simulated_stds_deg = simulateMouseAngles(rng, n_experiments=n_experiments, n_simulations=10000)\n",
    "    surrogates_res_dict[mouse_id][angle_type] = (n_experiments, std_deg, simulated_stds_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b030ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSTDs(mouse_id, angle_type):\n",
    "    sim_data = np.sort(surrogates_res_dict[mouse_id][angle_type][2])  # need sorting later for threshold anyway\n",
    "    measured_std = surrogates_res_dict[mouse_id][angle_type][1]\n",
    "    n_measurements_per_std = surrogates_res_dict[mouse_id][angle_type][0]\n",
    "    fig, ax = plt.subplots(figsize=(14,10))\n",
    "    ax.set_title(f\"{mouse_id} {angle_type} ({n_measurements_per_std} values per std)\")\n",
    "    ax.hist(sim_data, bins=30)\n",
    "    ax.vlines(x=measured_std, ymin=0, ymax=100, color=mouse_colors[mouse_id], linewidth=2)\n",
    "    #plot 95% threshold\n",
    "    i_thr = ceil(0.05*len(sim_data))\n",
    "    x_thr = sim_data[i_thr]  # sim_data is sorted\n",
    "    ax.vlines(x=x_thr, ymin=0, ymax=120, color=\"black\", linewidth=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_angle_types = len(df_angles_v2.angle_type.unique())\n",
    "mouse_ids = df_angles_v2.mouse_id.unique()\n",
    "angle_types = df_angles_v2.angle_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740f0d6",
   "metadata": {},
   "source": [
    "### Plot sample std distributions for n=2, 3, ... measurements forming one std value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6657b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f957e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_simulations = 1000\n",
    "n_plots = 8\n",
    "fig, axs = plt.subplots(nrows=n_plots, ncols=1, figsize=(12,18), sharex=True)\n",
    "#xs = np.arange(0,120,0.1)\n",
    "for i_row in range(n_plots):\n",
    "    n_samples = i_row+2\n",
    "    axs[i_row].set_title(f\"n={n_samples}\")\n",
    "    sim_data = np.zeros(n_simulations)\n",
    "    for i in range(n_simulations):\n",
    "        samples = []\n",
    "        for i_sim in range(n_samples):\n",
    "            angle1 = 360.*rng.random()\n",
    "            angle2 = 360.*rng.random()\n",
    "            d_angle = min(abs(angle1-angle2), 360.0 - abs(angle1-angle2))\n",
    "            samples.append(d_angle)\n",
    "        sim_data[i] = std_func(samples)\n",
    "    axs[i_row].hist(sim_data, bins=100)\n",
    "    #axs[i_row].plot(xs, 20*chi2.pdf(xs, df=i_row+2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6c8794",
   "metadata": {},
   "source": [
    "### Plot surrogate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=n_mice, ncols=n_angle_types, figsize=(18,18))\n",
    "for i_mouse in range(n_mice):\n",
    "    for i_angle_type in range(n_angle_types):\n",
    "        mouse_id = mouse_ids[i_mouse]\n",
    "        angle_type = angle_types[i_angle_type]\n",
    "        sim_data = np.sort(surrogates_res_dict[mouse_id][angle_type][2])  # need sorting later for threshold anyway\n",
    "        measured_std = surrogates_res_dict[mouse_id][angle_type][1]\n",
    "        n_measurements_per_std = surrogates_res_dict[mouse_id][angle_type][0]\n",
    "        axs[i_mouse][i_angle_type].set_title(f\"{mouse_id} {angle_type}, {n_measurements_per_std} vals/std\")\n",
    "        h = axs[i_mouse][i_angle_type].hist(sim_data, bins=30)\n",
    "        ymax = max(h[0])  # hist returns n, bins, patches. n is the list of histogram values, take max of it for vline\n",
    "        axs[i_mouse][i_angle_type].vlines(x=measured_std, ymin=0, ymax=0.8*ymax, color=mouse_colors[mouse_id], linewidth=4)\n",
    "        #plot 95% threshold\n",
    "        i_thr = ceil(0.05*len(sim_data))\n",
    "        x_thr = sim_data[i_thr]  # sim_data is sorted\n",
    "        axs[i_mouse][i_angle_type].vlines(x=x_thr, ymin=0, ymax=ymax, color=\"black\", linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc631b",
   "metadata": {},
   "source": [
    "## Plot histogram of simulated SDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make sure there are no periodicity-related artifacts in sd-s! Need to change random angles generator, for example: 0+360...\n",
    "# Use again unity vectors addition method. Also check for df_angles_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eec8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdOfUniformAngles(rng, n_angles=3, deg=False):\n",
    "    if deg:\n",
    "        full_angle=360.\n",
    "    else:\n",
    "        full_angle=2*pi\n",
    "    angles = np.zeros(n_angles)\n",
    "    for i_angle in range(n_angles):\n",
    "        angles[i_angle] = rng.random()*full_angle\n",
    "    return np.std(angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643b6f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_direction_cstds = df_angles_per_event[[\"mouse_id\", \"quantile_type\", \"theta\"]].groupby([\"mouse_id\", \"quantile_type\"]).apply(lambda col: circstd(col[\"theta\"])).reset_index(name=\"circstd\")\n",
    "# add n_events per mouse, event type (sz, sd1, sd2)\n",
    "df_angles_per_event[\"n_events\"] = 1\n",
    "df_direction_cstds[\"n_events\"] = df_angles_per_event[[\"mouse_id\", \"quantile_type\", \"n_events\"]].groupby([\"mouse_id\", \"quantile_type\"], as_index=False).sum().n_events\n",
    "df_angles_per_event = df_angles_per_event.drop(columns=[\"n_events\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a269ad",
   "metadata": {},
   "source": [
    "## StD of SD1, SD2, Sz angles compared to StD of same number of random angles (radians) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02042671",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "segment_types_dict = {\"sd1\": \"SD1\", \"sd2\": \"SD2\", \"sz\": \"Sz\"}\n",
    "\n",
    "rows_map = {df_direction_cstds.mouse_id.unique()[i] : i for i in range(len(df_direction_cstds.mouse_id.unique()))}\n",
    "cols_map = {df_direction_cstds.quantile_type.unique()[i] : i for i in range(len(df_direction_cstds.quantile_type.unique()))}\n",
    "rng = np.random.default_rng(2023)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(df_direction_cstds.mouse_id.unique()), ncols=len(df_direction_cstds.quantile_type.unique()), figsize=(18,18))\n",
    "for i_row, row in df_direction_cstds.iterrows():\n",
    "    axs[rows_map[row[\"mouse_id\"]]][cols_map[row[\"quantile_type\"]]].set_title(f'{row[\"mouse_id\"]} {segment_types_dict[row[\"quantile_type\"]]}')\n",
    "    sample = sorted([stdOfUniformAngles(rng, row[\"n_events\"]) for i in range(1000)])\n",
    "    h = axs[rows_map[row[\"mouse_id\"]]][cols_map[row[\"quantile_type\"]]].hist(sample)\n",
    "    ymax = max(h[0])\n",
    "    axs[rows_map[row[\"mouse_id\"]]][cols_map[row[\"quantile_type\"]]].vlines(x=row[\"circstd\"], ymin=0, ymax=0.8*ymax, color=mouse_colors[row[\"mouse_id\"]], linewidth=3)\n",
    "    axs[rows_map[row[\"mouse_id\"]]][cols_map[row[\"quantile_type\"]]].vlines(x=sample[floor(0.05*len(sample))], ymin=0, ymax = ymax, color=\"black\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6209f52f",
   "metadata": {},
   "source": [
    "## Same with degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e97d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles_per_event_deg = df_angles_per_event.copy()\n",
    "df_direction_cstds_deg = df_angles_per_event_deg[[\"mouse_id\", \"quantile_type\", \"theta_deg\"]].groupby([\"mouse_id\", \"quantile_type\"]).apply(lambda col: std_func(col[\"theta_deg\"])).reset_index(name=\"std\")\n",
    "# add n_events per mouse, event type (sz, sd1, sd2)\n",
    "df_angles_per_event_deg[\"n_events\"] = 1\n",
    "df_direction_cstds_deg[\"n_events\"] = df_angles_per_event_deg[[\"mouse_id\", \"quantile_type\", \"n_events\"]].groupby([\"mouse_id\", \"quantile_type\"], as_index=False).sum().n_events\n",
    "df_angles_per_event_deg = df_angles_per_event_deg.drop(columns=[\"n_events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_direction_cstds_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids_lis = []\n",
    "angle_types_lis = []\n",
    "samples_lis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b0dbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stds_dict_flat = {\"mouse_id\": [], \"angle_type\": [], \"measured_std\": [], \"n_measurements\": [], \"simulated_std_threshold_onetailed\": [], \"p\": [], \"alpha\": [], \"n_simulations\": []}\n",
    "segment_types_dict = {\"sd1\": \"SD1\", \"sd2\": \"SD2\", \"sz\": \"Sz\"}\n",
    "rows_map = {df_direction_cstds_deg.mouse_id.unique()[i] : i for i in range(len(df_direction_cstds_deg.mouse_id.unique()))}\n",
    "cols_map = {df_direction_cstds_deg.quantile_type.unique()[i] : i for i in range(len(df_direction_cstds_deg.quantile_type.unique()))}\n",
    "alpha = 0.05\n",
    "n_simulations = 1000\n",
    "rng = np.random.default_rng(2023)\n",
    "fig, axs = plt.subplots(nrows=len(df_direction_cstds_deg.mouse_id.unique()), ncols=len(df_direction_cstds_deg.quantile_type.unique()), figsize=(18,18))\n",
    "for i_row, row in df_direction_cstds_deg.iterrows():\n",
    "    axs[rows_map[row[\"mouse_id\"]]][cols_map[row[\"quantile_type\"]]].set_title(f'{row[\"mouse_id\"]} {segment_types_dict[row[\"quantile_type\"]]}')\n",
    "    sample = sorted([stdOfUniformAngles(rng, row[\"n_events\"], deg=True) for i in range(n_simulations)])  # len(sample) = n_simulations\n",
    "    h = axs[rows_map[row[\"mouse_id\"]]][cols_map[row[\"quantile_type\"]]].hist(sample)\n",
    "    ymax = max(h[0])\n",
    "    # add measured std value\n",
    "    axs[rows_map[row[\"mouse_id\"]]][cols_map[row[\"quantile_type\"]]].vlines(x=row[\"std\"], ymin=0, ymax=0.8*ymax, color=mouse_colors[row[\"mouse_id\"]], linewidth=3)\n",
    "    # add simulated (surrogate) std value\n",
    "    axs[rows_map[row[\"mouse_id\"]]][cols_map[row[\"quantile_type\"]]].vlines(x=sample[floor(alpha*len(sample))], ymin=0, ymax = ymax, color=\"black\", linewidth=2)\n",
    "    print(f'{row[\"mouse_id\"]} {row[\"quantile_type\"]}:\\tmeasured: {row[\"std\"]},\\tsimulated: {sample[floor(alpha*len(sample))]},\\tp={np.searchsorted( sample, row[\"std\"])/len(sample)}')\n",
    "    \n",
    "    stds_dict_flat[\"mouse_id\"].append(row[\"mouse_id\"])\n",
    "    stds_dict_flat[\"angle_type\"].append(segment_types_dict[row[\"quantile_type\"]])\n",
    "    stds_dict_flat[\"measured_std\"].append(row[\"std\"])\n",
    "    stds_dict_flat[\"n_measurements\"].append(row[\"n_events\"])\n",
    "    stds_dict_flat[\"simulated_std_threshold_onetailed\"].append(sample[floor(alpha*len(sample))])\n",
    "    stds_dict_flat[\"p\"].append(np.searchsorted( sample, row[\"std\"])/len(sample))\n",
    "    stds_dict_flat[\"alpha\"].append(alpha)\n",
    "    stds_dict_flat[\"n_simulations\"].append(n_simulations)\n",
    "    \n",
    "    mouse_ids_lis += [row[\"mouse_id\"] for i in range(len(sample))]\n",
    "    angle_types_lis += [row[\"quantile_type\"] for i in range(len(sample))]\n",
    "    samples_lis += sample\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f25c1e",
   "metadata": {},
   "source": [
    "## Plot surrogates over another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_measurements = pd.DataFrame(data=stds_dict_flat, columns=[\"mouse_id\",\"angle_type\", \"measured_std\", \"simulated_std_threshold_onetailed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdd946",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_data = {\"mouse_id\": mouse_ids_lis, \"angle_type\": angle_types_lis, \"sample\": samples_lis}\n",
    "df_samples = pd.DataFrame(data=samples_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e86111",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = sns.color_palette() # sns.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False)  # \n",
    "pal_light = sns.color_palette(\"pastel\")\n",
    "pal_dict = dict()\n",
    "pal_light_dict = dict()\n",
    "for i, mouse_id in enumerate(df_samples.mouse_id.unique()):\n",
    "    pal_dict[mouse_id] = pal[i]\n",
    "    pal_light_dict[mouse_id] = pal_light[i]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505ecb68",
   "metadata": {},
   "source": [
    "### Seizure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f470c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_sz = df_samples[df_samples[\"angle_type\"] == \"sz\"]\n",
    "df_measurements_sz = df_measurements[df_measurements[\"angle_type\"] == \"Sz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax = 0.0030\n",
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "plt.suptitle(\"Sz\", fontsize=26)\n",
    "sns.kdeplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    log_scale=False,\n",
    "    palette=pal_light_dict,\n",
    "    fill=True,\n",
    "    alpha=0.75,\n",
    "    linewidth=4,\n",
    "    ax=ax\n",
    ")\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sz)\n",
    "for i_meas, measurement in df_measurements_sz.iterrows():\n",
    "    ax.vlines(x=measurement.simulated_std_threshold_onetailed, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linestyles=\"dashed\", linewidth=4)\n",
    "    ax.vlines(x=measurement.measured_std, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linewidth=2)\n",
    "    ymin += y_step\n",
    "    \n",
    "if save_figs:\n",
    "    fig_fpath = os.path.join(output_folder, f'angles_std_sz_kde_{get_datetime_for_fname()}{file_format}')\n",
    "    plt.savefig(fig_fpath)\n",
    "    print(f\"Saved to {fig_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b27e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "plt.suptitle(\"Sz\", fontsize=26)\n",
    "ymax = 170\n",
    "sns.histplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    multiple=\"layer\",\n",
    "    palette=pal_light_dict,\n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    kde=True,\n",
    "    log_scale=False,\n",
    "    alpha=0.7,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sz)\n",
    "for i_meas, measurement in df_measurements_sz.iterrows():\n",
    "    ax.vlines(x=measurement.simulated_std_threshold_onetailed, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linestyles=\"dashed\", linewidth=4)\n",
    "    ax.vlines(x=measurement.measured_std, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linewidth=4)\n",
    "    ymin += y_step\n",
    "\n",
    "if save_figs:\n",
    "    fig_fpath = os.path.join(output_folder, f'angles_std_sz_hist_{get_datetime_for_fname()}{file_format}')\n",
    "    plt.savefig(fig_fpath)\n",
    "    print(f\"Saved to {fig_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "plt.suptitle(\"Sz\", fontsize=26)\n",
    "ymax = 170\n",
    "sns.histplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    multiple=\"layer\",\n",
    "    palette=pal_dict,\n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    kde=False,\n",
    "    log_scale=False,\n",
    "    alpha=0.7,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sz)\n",
    "for i_meas, measurement in df_measurements_sz.iterrows():\n",
    "    ax.vlines(x=measurement.measured_std, ymin=0,ymax=ymax, colors=pal_dict[measurement.mouse_id], linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f40107",
   "metadata": {},
   "source": [
    "### SD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_sd1 = df_samples[df_samples[\"angle_type\"] == \"sd1\"]\n",
    "df_measurements_sd1 = df_measurements[df_measurements[\"angle_type\"] == \"SD1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8df6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax = 0.0030\n",
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "plt.suptitle(\"SD1\", fontsize=26)\n",
    "sns.kdeplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    log_scale=False,\n",
    "    palette=pal_light_dict,\n",
    "    fill=True,\n",
    "    alpha=0.75,\n",
    "    linewidth=4,\n",
    "    ax=ax\n",
    ")\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sd1)\n",
    "for i_meas, measurement in df_measurements_sd1.iterrows():\n",
    "    ax.vlines(x=measurement.simulated_std_threshold_onetailed, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linestyles=\"dashed\", linewidth=4)\n",
    "    ax.vlines(x=measurement.measured_std, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linewidth=2)\n",
    "    ymin += y_step\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef38aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "ymax = 170\n",
    "plt.suptitle(\"SD1\", fontsize=26)\n",
    "sns.histplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    multiple=\"layer\",\n",
    "    palette=pal_light_dict,\n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    kde=False,\n",
    "    log_scale=False,\n",
    "    alpha=0.7,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sd1)\n",
    "for i_meas, measurement in df_measurements_sd1.iterrows():\n",
    "    ax.vlines(x=measurement.simulated_std_threshold_onetailed, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linestyles=\"dashed\", linewidth=4)\n",
    "    ax.vlines(x=measurement.measured_std, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linewidth=4)\n",
    "    ymin += y_step\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "ymax = 170\n",
    "plt.suptitle(\"SD1\", fontsize=26)\n",
    "sns.histplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    multiple=\"layer\",\n",
    "    palette=pal_dict,\n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    kde=False,\n",
    "    log_scale=False,\n",
    "    alpha=0.7,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sd1)\n",
    "for i_meas, measurement in df_measurements_sd1.iterrows():\n",
    "    ax.vlines(x=measurement.measured_std, ymin=0,ymax=ymax, colors=pal_dict[measurement.mouse_id], linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb279036",
   "metadata": {},
   "source": [
    "### SD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31016d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples_sd2 = df_samples[df_samples[\"angle_type\"] == \"sd2\"]\n",
    "df_measurements_sd2 = df_measurements[df_measurements[\"angle_type\"] == \"SD2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax = 0.0030\n",
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "plt.suptitle(\"SD2\", fontsize=26)\n",
    "sns.kdeplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    log_scale=False,\n",
    "    palette=pal_light_dict,\n",
    "    fill=True,\n",
    "    alpha=0.75,\n",
    "    linewidth=4,\n",
    "    ax=ax\n",
    ")\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sd2)\n",
    "for i_meas, measurement in df_measurements_sd2.iterrows():\n",
    "    ax.vlines(x=measurement.simulated_std_threshold_onetailed, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linestyles=\"dashed\", linewidth=4)\n",
    "    ax.vlines(x=measurement.measured_std, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linewidth=2)\n",
    "    ymin += y_step\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "ymax = 170\n",
    "plt.suptitle(\"SD2\", fontsize=26)\n",
    "sns.histplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    multiple=\"layer\",\n",
    "    palette=pal_light_dict,\n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    kde=False,\n",
    "    log_scale=False,\n",
    "    alpha=0.7,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sd2)\n",
    "for i_meas, measurement in df_measurements_sd2.iterrows():\n",
    "    ax.vlines(x=measurement.simulated_std_threshold_onetailed, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linestyles=\"dashed\", linewidth=4)\n",
    "    ax.vlines(x=measurement.measured_std, ymin=ymin,ymax=ymin+y_step, colors=pal_dict[measurement.mouse_id], linewidth=4)\n",
    "    ymin += y_step\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0191d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,12))\n",
    "ymax = 170\n",
    "plt.suptitle(\"SD2\", fontsize=26)\n",
    "sns.histplot(\n",
    "    df_samples,\n",
    "    x=\"sample\", hue=\"mouse_id\",\n",
    "    multiple=\"layer\",\n",
    "    palette=pal_dict,\n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    kde=False,\n",
    "    log_scale=False,\n",
    "    alpha=0.7,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ymin = 0\n",
    "y_step = (ymax-ymin)/len(df_measurements_sd2)\n",
    "for i_meas, measurement in df_measurements_sd2.iterrows():\n",
    "    ax.vlines(x=measurement.measured_std, ymin=0,ymax=ymax, colors=pal_dict[measurement.mouse_id], linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd8b59",
   "metadata": {},
   "source": [
    "## Create illustratory plot for one mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_id = \"T301\"\n",
    "df_direction_stds_deg_single = df_direction_cstds_deg[df_direction_cstds_deg[\"mouse_id\"] == example_id]\n",
    "rows_map = {df_direction_stds_deg_single.mouse_id.unique()[i] : i for i in range(len(df_direction_stds_deg_single.mouse_id.unique()))}\n",
    "cols_map = {df_direction_stds_deg_single.quantile_type.unique()[i] : i for i in range(len(df_direction_stds_deg_single.quantile_type.unique()))}\n",
    "rng = np.random.default_rng(2023)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(df_direction_stds_deg_single.mouse_id.unique()), ncols=len(df_direction_stds_deg_single.quantile_type.unique()), figsize=(20,6))\n",
    "segment_types_dict = {\"sd1\": \"SD1\", \"sd2\": \"SD2\", \"sz\": \"Sz\"}\n",
    "for i_row, row in df_direction_stds_deg_single.iterrows():\n",
    "    # only 1 mouse, so axs is 1D\n",
    "    \n",
    "    axs[cols_map[row[\"quantile_type\"]]].set_title(f'{segment_types_dict[row[\"quantile_type\"]]}', fontsize=20)\n",
    "    sample = sorted([stdOfUniformAngles(rng, row[\"n_events\"], deg=True) for i in range(1000)])\n",
    "    h = axs[cols_map[row[\"quantile_type\"]]].hist(sample)\n",
    "    ymax = max(h[0])\n",
    "    # add measured std value\n",
    "    axs[cols_map[row[\"quantile_type\"]]].vlines(x=row[\"std\"], ymin=0, ymax=ymax, color=mpl.colormaps[\"tab10\"](1), linewidth=2)\n",
    "    # add simulated (surrogate) std value\n",
    "    axs[cols_map[row[\"quantile_type\"]]].vlines(x=sample[floor(0.05*len(sample))], ymin=0, ymax = ymax, cmap=mpl.colormaps[\"tab10\"], linewidth=2)\n",
    "    print(f'{row[\"mouse_id\"]} {row[\"quantile_type\"]}:\\tmeasured: {row[\"std\"]},\\tsimulated: {sample[floor(0.05*len(sample))]},\\tp={np.searchsorted( sample, row[\"std\"])/len(sample)}')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlim((0, 180))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.set_xlabel(\"SD (deg)\", fontsize=18)\n",
    "    ax.set_ylabel(\"Count\", fontsize=18)\n",
    "    \n",
    "if save_figs:\n",
    "    fig_fpath = os.path.join(output_folder, f'angles_std_illustrative_surrogate_{get_datetime_for_fname()}{file_format}')\n",
    "    plt.savefig(fig_fpath)\n",
    "    print(f\"Saved to {fig_fpath}\")    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check again why different 3b sz grid is to 3a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles_per_event[\"theta_deg_inj_top\"] = df_angles_per_event[\"theta_inj_top\"]*180./pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_angles_per_event.to_excel(\"D:\\\\Downloads\\\\angles_per_event.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999caf64",
   "metadata": {},
   "source": [
    "# Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c46bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = fh.open_dir(\"Choose export folder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a012e",
   "metadata": {},
   "source": [
    "### Export StD surrogate statistical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b447266",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = f\"angles_std_and_surrogate_{get_datetime_for_fname()}.json\"\n",
    "export_fpath = os.path.join(export_dir, export_fname)\n",
    "print(f\"Saving SD1, 2, Sz angle StD vs surrogates data to {export_fpath}\")\n",
    "with open(export_fpath, 'w') as json_file:\n",
    "    json.dump(stds_dict_flat, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles_v2_export = df_angles_v2.sort_values(by=[\"mouse_id\", \"uuid_matched\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53034d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles_v2_export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230882e",
   "metadata": {},
   "source": [
    "### Convert uuid to integer event index for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3412f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_angles_v2_export[\"event_index\"] = df_angles_v2_export.groupby('uuid_matched', sort=False).ngroup() + 1  # convert to 1-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2b1b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dict = dict()\n",
    "export_dict[\"mouse_id\"] = df_angles_v2_export.mouse_id\n",
    "export_dict[\"angle_type\"] = df_angles_v2_export.angle_type\n",
    "export_dict[\"angle_deg\"] = df_angles_v2_export.angle_deg\n",
    "export_dict[\"angle_rad\"] = df_angles_v2_export.angle\n",
    "export_dict[\"event_index\"] = df_angles_v2_export.event_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = f\"angles_per_event_dataset_{get_datetime_for_fname()}.h5\"\n",
    "export_fpath = os.path.join(export_dir, export_fname)\n",
    "with h5py.File(export_fpath, \"w\") as hf:\n",
    "    for key in export_dict.keys():\n",
    "        if type(export_dict[key][0]) == str:\n",
    "            print(f\"{key} converted to dtype=\\'S\\'\")\n",
    "            hf.create_dataset(key, data=np.array(export_dict[key], dtype='S'))\n",
    "        else:\n",
    "            hf.create_dataset(key, data=export_dict[key])\n",
    "print(f\"Saved dataset to {export_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460952de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

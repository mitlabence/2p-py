{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf76531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import labrotation.file_handling as fh\n",
    "import datadoc_util as ddoc\n",
    "import os\n",
    "import pims_nd2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = dt.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DOWNLOADS_FOLDER\" in env_dict.keys():\n",
    "    output_folder =  env_dict[\"DOWNLOADS_FOLDER\"]\n",
    "    print(f\"Output: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545463d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovery_traces_fpath = fh.open_file(\"Select excel file containing recovery trace list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ca32ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovery_traces = pd.read_excel(recovery_traces_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5164cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    dd = ddoc.DataDocumentation(env_dict[\"DATA_DOCU_FOLDER\"])\n",
    "    dd.loadDataDoc()\n",
    "    if \"SERVER_SYMBOL\" in env_dict.keys():\n",
    "        dd.setDataDriveSymbol(env_dict[\"SERVER_SYMBOL\"])\n",
    "    print(\"data documentation loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16763db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovery_traces = df_recovery_traces[df_recovery_traces[\"event_uuid\"] ==\"74473c5d22e04525acf53f5a5cb799f4\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_uuids = df_recovery_traces.recording_uuid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fd2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_list_nd2 = dd.getNikonFilePathForUuid(rec_uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b41b5b",
   "metadata": {},
   "source": [
    "### Test that all nd2 files are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8adf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fpath_nd2 in fpath_list_nd2:\n",
    "    if not (os.path.exists(fpath_nd2)):\n",
    "        print(fpath_nd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5071ed",
   "metadata": {},
   "source": [
    "# Load nd2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af0ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nd2_data_dict = { uuid: (t_start_utc, nd2_tstamps, mean_fluo)}\n",
    "nd2_data_dict = dict()\n",
    "for i_fpath_nd2 in range(len(fpath_list_nd2)):\n",
    "    fpath_nd2 = fpath_list_nd2[i_fpath_nd2]\n",
    "    rec_uuid = rec_uuids[i_fpath_nd2]\n",
    "    print(rec_uuid)\n",
    "    nd2r = pims_nd2.ND2_Reader(fpath_nd2)\n",
    "    t_start_jdn = nd2r.metadata[\"time_start_jdn\"]\n",
    "    t_start_utc = nd2r.metadata[\"time_start_utc\"]\n",
    "    mean_fluo = np.mean(nd2r, axis=(1,2))\n",
    "    \n",
    "    nd2_tstamps = np.array([nd2r[i].metadata[\"t_ms\"] for i in range(len(nd2r))]) \n",
    "    \n",
    "    nd2_data_dict[rec_uuid] = (t_start_utc, nd2_tstamps, mean_fluo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uuid-nd2 consistency\n",
    "for i_nd2 in range(len(fpath_list_nd2)):\n",
    "    uuid = rec_uuids[i_nd2]\n",
    "    nd2_fname = os.path.split(fpath_list_nd2[i_nd2])[-1]\n",
    "    rec_len = dd.getSegmentsForUUID(uuid).frame_end.max()\n",
    "    len_to_check = len(nd2_data_dict[uuid][2])\n",
    "    if len_to_check != rec_len:\n",
    "        print(f\"Length mismatch {uuid} ({nd2_fname}):\\n\\tshould: {rec_len} but is {len_to_check}\")\n",
    "        print(uuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4665e26b",
   "metadata": {},
   "source": [
    "# Assemble the traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break_points: break points of segments AND recordings. \n",
    "# recording_break_points: break points of nd2 files\n",
    "# segment_type_break_points: break points of segments. 0, n_bl_frames, n_bl_frames + n_sz_frames\n",
    "# session_uuids: uuids of recording sessions\n",
    "# window_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeceffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_mapping = {\"cx\": \"Cx\", \"ca1\": \"CA1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae03f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_begin_end_frames = dict()\n",
    "traces_dict = dict()\n",
    "tstamps_dict = dict()\n",
    "trace_attributes_dict = dict()\n",
    "for event_uuid, g in df_recovery_traces.groupby(\"event_uuid\"):\n",
    "    trace = np.array([])\n",
    "    tstamps = np.array([])\n",
    "    mouse_id = dd.getMouseIdForUuid(g.recording_uuid.unique()[0])\n",
    "    session_uuids = []\n",
    "    recording_break_points = []  # 0-indices in the trace of first frames of each nd2 contributing to trace\n",
    "    segment_type_break_points = [0]  # bl, sz, am first (0-indexing) frames in the trace\n",
    "    win_type = window_mapping[dd.getMouseWinInjInfo(mouse_id).window_type.iloc[0]]  # CA1 or Cx\n",
    "    i_current_frame = 0\n",
    "    # When starting to construct a trace, the very first segment starts at 0.\n",
    "    # Each consecutive segment is matched by taking the time stamps (ms since beginning of current recording),\n",
    "    # and subtract first segment time (first recording start time stamp + ms between start and first frame used for trace)\n",
    "    first_recording_begin_datetime = None\n",
    "    first_frame_dt_ms_since_rec_begin = None  # dt between first frame used in trace and start timestamp of first recording\n",
    "    for i_row, row in g.iterrows():\n",
    "\n",
    "        rec_uuid = row[\"recording_uuid\"]\n",
    "\n",
    "        if rec_uuid not in session_uuids:  # first time the recording appears in this trace\n",
    "            recording_break_points.append(i_current_frame)\n",
    "            session_uuids.append(rec_uuid)\n",
    "\n",
    "        begin_frame = row[\"begin_frame\"]\n",
    "        end_frame = row[\"end_frame\"]\n",
    "\n",
    "        if first_recording_begin_datetime is None:  # this is the first segment\n",
    "            first_recording_begin_datetime = nd2_data_dict[rec_uuid][0]\n",
    "            first_frame_ms_since_rec_begin =  nd2_data_dict[rec_uuid][1][begin_frame-1]\n",
    "        current_recording_begin_datetime = nd2_data_dict[rec_uuid][0]\n",
    "\n",
    "        assert (current_recording_begin_datetime - first_recording_begin_datetime).total_seconds() >= 0.\n",
    "\n",
    "        segment_timestamps = nd2_data_dict[rec_uuid][1]  # ms since start of current recording\n",
    "        segment_timestamps = segment_timestamps[begin_frame-1:end_frame]  # cut to segment used from this recording\n",
    "\n",
    "        # get the number in ms needed to match to timeframe where first frame of this trace is 0\n",
    "        dt_ms_first_frame_current_start_frame = (current_recording_begin_datetime - first_recording_begin_datetime).total_seconds()*1000. - first_frame_ms_since_rec_begin\n",
    "\n",
    "        segment_timestamps = segment_timestamps + dt_ms_first_frame_current_start_frame  # convert time stamps to set t=0 to the first frame in the trace\n",
    "\n",
    "        segment = nd2_data_dict[rec_uuid][2][begin_frame-1:end_frame]  # both inclusive, 1-indexing -> convert to 0-indexing\n",
    "        segment_type = row[\"segment_type\"]\n",
    "\n",
    "        # TODO: check how segment type break points are added. Should not add duplicates!!!\n",
    "        if segment_type == \"sz\":  # add sz begin and end frames\n",
    "            if event_uuid not in sz_begin_end_frames.keys():  # first, and maybe last, sz segment\n",
    "                sz_begin_end_frames[event_uuid] = [i_current_frame, i_current_frame + len(segment)-1]  # both indices 0-indexing, inclusive\n",
    "                segment_type_break_points.append(i_current_frame)  # add first 0-index of sz segment\n",
    "            else:  # not the first \"sz\" segment\n",
    "                sz_begin_end_frames[event_uuid][1] = i_current_frame + len(segment)-1  # expand sz segment in trace\n",
    "        elif segment_type == \"am\":\n",
    "            if event_uuid in [\"f0442bebcd1a4291a8d0559eb47df08e\"]:  # manually add sz begin end frames to recordings where they are missing\n",
    "                if event_uuid not in sz_begin_end_frames.keys():\n",
    "                    sz_begin_end_frames[event_uuid] = [i_current_frame, i_current_frame]\n",
    "                    segment_type_break_points.append(i_current_frame-1)  # set begin of sz segment\n",
    "                    segment_type_break_points.append(i_current_frame)  # set begin of am segment \n",
    "            else:\n",
    "                if len(segment_type_break_points) < 3:  # only add am begin frame if not yet in list\n",
    "                    segment_type_break_points.append(i_current_frame)  # set begin of am segment\n",
    "\n",
    "        trace = np.concatenate([trace, segment])\n",
    "        tstamps = np.concatenate([tstamps, segment_timestamps])\n",
    "        i_current_frame = len(trace)  # set the next frame index\n",
    "    trace_attributes_dict[event_uuid] = dict()\n",
    "    trace_attributes_dict[event_uuid][\"mouse_id\"] = mouse_id\n",
    "    trace_attributes_dict[event_uuid][\"window_type\"] = win_type\n",
    "    trace_attributes_dict[event_uuid][\"session_uuids\"] = session_uuids\n",
    "    trace_attributes_dict[event_uuid][\"recording_break_points\"] = recording_break_points\n",
    "    trace_attributes_dict[event_uuid][\"segment_type_break_points\"] = segment_type_break_points\n",
    "    # assemble total break points\n",
    "    i_recbreak = 0\n",
    "    i_segbreak = 0\n",
    "    break_points = []\n",
    "    while (i_recbreak < len(recording_break_points)) and (i_segbreak < len(segment_type_break_points)):\n",
    "        if recording_break_points[i_recbreak] < segment_type_break_points[i_segbreak]:\n",
    "            if recording_break_points[i_recbreak] not in break_points:\n",
    "                break_points.append(recording_break_points[i_recbreak])\n",
    "            i_recbreak += 1\n",
    "        else:\n",
    "            if segment_type_break_points[i_segbreak] not in break_points:\n",
    "                break_points.append(segment_type_break_points[i_segbreak])\n",
    "            i_segbreak += 1\n",
    "    # one of the break points list is completely in break_points; add the rest of the other\n",
    "    if i_recbreak == len(recording_break_points):\n",
    "        while i_segbreak < len(segment_type_break_points):\n",
    "            if segment_type_break_points[i_segbreak] not in break_points:\n",
    "                break_points.append(segment_type_break_points[i_segbreak])\n",
    "            i_segbreak += 1\n",
    "    elif i_segbreak == len(segment_type_break_points):\n",
    "        while i_recbreak < len(recording_break_points):\n",
    "            if recording_break_points[i_recbreak] not in break_points:\n",
    "                break_points.append(recording_break_points[i_recbreak])\n",
    "            i_recbreak += 1\n",
    "    trace_attributes_dict[event_uuid][\"break_points\"] = break_points\n",
    "\n",
    "    traces_dict[event_uuid] = trace\n",
    "    tstamps_dict[event_uuid] = tstamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = f\"traces_for_recovery_{get_datetime_for_fname()}.h5\"\n",
    "output_fpath = os.path.join(output_folder, output_fname)\n",
    "with h5py.File(output_fpath, \"w\") as hf:\n",
    "    for event_uuid in traces_dict.keys():\n",
    "        uuid_grp = hf.create_group(event_uuid)\n",
    "        uuid_grp.attrs[\"sz_begin_frame\"] = sz_begin_end_frames[event_uuid][0]\n",
    "        uuid_grp.attrs[\"sz_end_frame\"] = sz_begin_end_frames[event_uuid][1]\n",
    "        for k in trace_attributes_dict[event_uuid].keys():\n",
    "            uuid_grp.attrs[k] = trace_attributes_dict[event_uuid][k]\n",
    "        trace = uuid_grp.create_dataset(data=traces_dict[event_uuid], name=\"mean_fluo\")\n",
    "        tstamps = uuid_grp.create_dataset(data=tstamps_dict[event_uuid], name=\"tstamps\")\n",
    "        n_frames = len(trace)\n",
    "        segment_type_break_points = trace_attributes_dict[event_uuid][\"segment_type_break_points\"]\n",
    "        if len(segment_type_break_points) != 3:  # bl_begin, sz_begin, am_begin are the points\n",
    "            print(event_uuid)\n",
    "            print(segment_type_break_points)\n",
    "            raise Exception()\n",
    "        n_bl_frames = segment_type_break_points[1]-segment_type_break_points[0]\n",
    "        n_sz_frames = segment_type_break_points[2]-segment_type_break_points[1]\n",
    "        n_am_frames = n_frames - n_sz_frames - n_bl_frames\n",
    "        uuid_grp.attrs[\"n_bl_frames\"] = n_bl_frames\n",
    "        uuid_grp.attrs[\"n_sz_frames\"] = n_sz_frames\n",
    "        uuid_grp.attrs[\"n_am_frames\"] = n_am_frames\n",
    "print(f\"Saved to {output_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb8b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

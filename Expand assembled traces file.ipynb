{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3984d6",
   "metadata": {},
   "source": [
    "Intended use case: given a file with assembled traces, open it, copy data, open new data, append, and write the extended dataset into a new file. Specific use: to add LFP+LabView-only dataset to assembled_traces CHR2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1bb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b371ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import labrotation.file_handling as fh\n",
    "import datadoc_util as ddutil\n",
    "from labrotation import two_photon_session as tps\n",
    "import h5py\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import pyabf\n",
    "import matlab.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = dt.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d486cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(t):\n",
    "    t1 = t[1:]\n",
    "    t0 = t[:-1]\n",
    "    dt = np.zeros(len(t))\n",
    "    dt[1:] = t1 - t0\n",
    "    dt[0] = dt[1]  # assume same step size to avoid 0\n",
    "    return dt\n",
    "def create_totdist_abs(speed, dt):\n",
    "    totdist_abs = np.zeros(len(speed))\n",
    "    totdist_abs[0] = speed[0]*dt[0]\n",
    "    for i in range(1, len(totdist_abs)):\n",
    "        totdist_abs[i] = totdist_abs[i-1] + abs(speed[i]*dt[i])\n",
    "    return totdist_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"SERVER_SYMBOL\" in env_dict.keys():\n",
    "    SERVER_SYMBOL = env_dict[\"SERVER_SYMBOL\"]\n",
    "else:\n",
    "    SERVER_SYMBOL = \"R\"\n",
    "    print(f\"Server symbol not found in .env file. Setting it to {SERVER_SYMBOL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ea8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6691b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = fh.open_dir(\"Choose export directory for results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168dea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = ddutil.DataDocumentation(env_dict[\"DATA_DOCU_FOLDER\"])\n",
    "ddoc.loadDataDoc()\n",
    "ddoc.setDataDriveSymbol(SERVER_SYMBOL)\n",
    "ddoc.checkFileConsistency()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5fffd",
   "metadata": {},
   "source": [
    "## List recordings to be added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_recordings = ddoc.getRecordingsWithExperimentType([\"jrgeco_bilat_ctl_bilat_lfpr\", \"jrgeco_bilat_sd_bilat_lfpr\", \"jrgeco_bilat_ctl_monor_lfpr\", \"jrgeco_bilat_sd_bilat_lfpl\", \"jrgeco_bilat_ctl_right_lfpr\", ])\n",
    "# do the filtering by mouse\n",
    "dset_dict = {\"no_nikon\": [\"WEZ-8946\",]}\n",
    "\n",
    "df_new_recordings = df_new_recordings[df_new_recordings[\"mouse_id\"].isin(dset_dict[\"no_nikon\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_new_recordings.iterrows():\n",
    "    print(f\"{row.uuid}: {row.lfp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33079ff4",
   "metadata": {},
   "source": [
    "## Manually save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid = \"202c1dde3e5d4c07b9033d8c6f82b7ef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39190b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ddoc.getSessionFilesForUuid(uuid).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = files.folder\n",
    "lfp_fpath = os.path.join(fold, files[\"lfp\"])\n",
    "lv_fpath = os.path.join(fold, files[\"labview\"])\n",
    "lv_times_fpath = os.path.join(fold, os.path.splitext(files[\"labview\"])[0]+\"time.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e43fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lv_t = []  # col 0 of ...time.txt files\n",
    "\n",
    "with open(lv_times_fpath, \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        lv_t.append(float(line.split(\"\\t\")[0]))\n",
    "lv_t = np.array(lv_t)\n",
    "#lv_t = lv_t - lv_t[0]  # set to 0 starting time\n",
    "#lv_t = lv_t/1000.  # convert to s\n",
    "\n",
    "lv_rounds = []  # col 0\n",
    "lv_speed = []  # col 1\n",
    "lv_totdist = []  # col 2\n",
    "lv_distancepr = []  # col 3\n",
    "lv_stripes = []  # col 6\n",
    "lv_stripespr = []  # col 7\n",
    "with open(lv_fpath, \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        if len(line.strip().split(\"\\t\")) == 20:\n",
    "            lv_rounds.append(int(line.strip().split(\"\\t\")[0]))\n",
    "            lv_speed.append(float(line.strip().split(\"\\t\")[1]))\n",
    "            lv_totdist.append(float(line.strip().split(\"\\t\")[2]))\n",
    "            lv_distancepr.append(float(line.strip().split(\"\\t\")[3]))\n",
    "            lv_stripes.append(float(line.strip().split(\"\\t\")[6]))\n",
    "            lv_stripespr.append(float(line.strip().split(\"\\t\")[7]))\n",
    "            \n",
    "        else:\n",
    "            print(len(line.strip().split(\"\\t\")))\n",
    "lv_speed = np.array(lv_speed)\n",
    "lv_rounds = np.array(lv_rounds)\n",
    "lv_totdist = np.array(lv_totdist)\n",
    "lv_distancepr = np.array(lv_distancepr)\n",
    "lv_stripes = np.array(lv_stripes)\n",
    "lv_stripespr = np.array(lv_stripespr)\n",
    "\n",
    "lv_t = lv_t[:len(lv_speed)]  # cut out last, incomplete entry\n",
    "\n",
    "# cut if lv_t shorter\n",
    "lv_speed = lv_speed[:len(lv_t)]\n",
    "lv_rounds = lv_rounds[:len(lv_t)]\n",
    "lv_totdist = lv_totdist[:len(lv_t)]\n",
    "lv_distancepr = lv_distancepr[:len(lv_t)]\n",
    "lv_stripes = lv_stripes[:len(lv_t)]\n",
    "lv_stripespr = lv_stripespr[:len(lv_t)]\n",
    "\n",
    "assert len(lv_t) == len(lv_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22cd6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run part of matlab pipeline\n",
    "belt_struct = {\"speed\":lv_speed, \"distance\": lv_totdist, \"round\":lv_rounds, \"distancePR\": lv_distancepr, \"stripes\": lv_stripes, \"stripesPR\": lv_stripespr, \"time\": lv_t}\n",
    "eng = matlab.engine.start_matlab()\n",
    "m2p_path = eng.genpath(matlab_2p_folder)\n",
    "eng.addpath(m2p_path, nargout=0)\n",
    "belt_struct_proc = eng.beltCorrectWithoutNikon(belt_struct, nargout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy \n",
    "belt_dict = dict()\n",
    "for key in belt_struct_proc:   \n",
    "    belt_dict[key] = np.squeeze(np.array(belt_struct_proc[key]))\n",
    "belt_dict[\"time_s\"] = belt_dict[\"time\"]/1000.\n",
    "belt_dict[\"time_s\"] = belt_dict[\"time_s\"] - belt_dict[\"time_s\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f721a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_file = pyabf.ABF(lfp_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f62634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_file.setSweep(sweepNumber=0, channel=0)\n",
    "lfp_t = lfp_file.sweepX\n",
    "lfp_y = lfp_file.sweepY\n",
    "\n",
    "lfp_file.setSweep(sweepNumber=0, channel=1)\n",
    "lfp_loco = lfp_file.sweepY\n",
    "lfp_t = lfp_t*1.0038\n",
    "lfp_t = lfp_t - lfp_t[0]  # shift to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(belt_dict[\"time_s\"][-1]-lfp_t[-1])/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a09ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_length = 300  # 5 min\n",
    "stim_length = 4  # 4 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742b9f1",
   "metadata": {},
   "source": [
    "### Replicate some steps from the matlab processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec991b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_type = ddoc.getExperimentTypeForUuid(uuid)\n",
    "mouse_id = ddoc.getMouseIdForUuid(uuid)\n",
    "win_type = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b94d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b66073",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "plt.plot(belt_dict[\"time_s\"]-offset, belt_dict[\"speed\"])\n",
    "plt.plot(lfp_t, lfp_loco-2.5)\n",
    "plt.xlim((0, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "plt.plot(belt_dict[\"time_s\"]-offset, belt_dict[\"speed\"])\n",
    "plt.plot(lfp_t, lfp_loco-2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "plt.plot(belt_dict[\"time_s\"]-offset, belt_dict[\"speed\"])\n",
    "plt.plot(lfp_t, lfp_y)\n",
    "plt.vlines(x=[bl_length, bl_length+stim_length], ymin=-1, ymax=1, color=\"red\")\n",
    "#plt.xlim((295, 390))\n",
    "#plt.xlim((0, 20))\n",
    "plt.show()\n",
    "# TODO: come up with a constant offset, apply it to all recordings and check roughly if they match. Then decide whether use LFP or LabView (make sure labview > 10 min, so we can use loco quantities)\n",
    "# TODO: then assemble the dataset, include in loco analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee728e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fpath = os.path.join(output_dir, os.path.splitext(os.path.split(lfp_fpath)[-1])[0] + \"_segmented.h5\")\n",
    "print(output_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = create_dt(belt_dict[\"time_s\"])\n",
    "totdist_abs = create_totdist_abs(belt_dict[\"speed\"], dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(output_fpath, \"w\") as hf:\n",
    "    hf.attrs[\"uuid\"] = uuid\n",
    "    hf.attrs[\"stim_start\"] = bl_length\n",
    "    hf.attrs[\"poststim_start\"] = bl_length + stim_length\n",
    "    hf.attrs[\"exp_type\"] = exp_type\n",
    "    hf.attrs[\"win_type\"] = win_type\n",
    "    hf.attrs[\"mouse_id\"] = mouse_id\n",
    "    \n",
    "    hf.create_dataset(\"lfp_mov_t\", data=lfp_t)\n",
    "    hf.create_dataset(\"lfp_mov_y\", data=lfp_loco)    \n",
    "    hf.create_dataset(\"lfp_t\", data=lfp_t)    \n",
    "    hf.create_dataset(\"lfp_y\", data=lfp_y) \n",
    "    \n",
    "    hf.create_dataset(\"lv_dist\", data=belt_dict[\"distancePR\"])     \n",
    "    hf.create_dataset(\"lv_dt\", data=dt) \n",
    "    hf.create_dataset(\"lv_speed\", data=belt_dict[\"speed\"]) \n",
    "    hf.create_dataset(\"lv_running\", data=belt_dict[\"running\"]) \n",
    "    hf.create_dataset(\"lv_t_s\", data=belt_dict[\"time_s\"]-offset) # match to lfp\n",
    "    hf.create_dataset(\"lv_totdist\", data=belt_dict[\"distance\"])  # totdist - where does it come from? Is it distance?\n",
    "    hf.create_dataset(\"lv_totdist_abs\", data=totdist_abs) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d9710",
   "metadata": {},
   "source": [
    "# Open all recordings, calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_folder = \"C:\\\\Data\\\\bilat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5cf4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_attrs = dict()\n",
    "dict_data = dict()\n",
    "\n",
    "for root, dirs, files in os.walk(dset_folder):\n",
    "    for file in files:\n",
    "        fpath = os.path.join(root, file)\n",
    "        assert os.path.exists(fpath)\n",
    "        with h5py.File(fpath, \"r\") as hf:\n",
    "            dict_current_attrs = dict()\n",
    "            for key in hf.attrs.keys():\n",
    "                dict_current_attrs[key] = hf.attrs[key]\n",
    "            uuid = dict_current_attrs[\"uuid\"]\n",
    "            dict_attrs[uuid] = dict_current_attrs\n",
    "            \n",
    "            dict_current_data = dict()\n",
    "            for key in hf.keys():\n",
    "                dict_current_data[key] = hf[key][:]\n",
    "            dict_data[uuid] = dict_current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3e8e8",
   "metadata": {},
   "source": [
    "### Calculate pre-stim, post stim metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0290ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_uuids = []\n",
    "mouse_ids = []\n",
    "window_types = []\n",
    "exp_types = []\n",
    "segment_types = []\n",
    "segment_lengths = []\n",
    "totdists = []\n",
    "totdists_abs = []\n",
    "runnings = []\n",
    "totdists_norm = []\n",
    "totdists_abs_norm = []\n",
    "\n",
    "#df_stats[\"totdist_abs_norm\"] = 10000*df_stats[\"totdist_abs\"]/df_stats[\"segment_length\"]  # for totdist_abs, can use 4500 as length\n",
    "\n",
    "for uuid in dict_attrs.keys():\n",
    "    mouse_id = dict_attrs[uuid][\"mouse_id\"]\n",
    "    win_type = dict_attrs[uuid][\"win_type\"]\n",
    "    exp_type = dict_attrs[uuid][\"exp_type\"]\n",
    "    \n",
    "    # separate loco data into pre-stim and post-stim\n",
    "    dict_pre = dict()\n",
    "    dict_post = dict()\n",
    "    t_stim = dict_attrs[uuid][\"stim_start\"]\n",
    "    t_poststim = dict_attrs[uuid][\"poststim_start\"] \n",
    "    t_data = dict_data[uuid][\"lv_t_s\"]\n",
    "    \n",
    "    i_pre = t_data < t_stim\n",
    "    pre_length = np.sum(i_pre)\n",
    "    \n",
    "    # create matching post segment\n",
    "    i_first_post = np.argmax(t_data >= t_poststim)\n",
    "    i_post = np.zeros(t_data.shape)\n",
    "    i_post[i_first_post:i_first_post+pre_length] = 1\n",
    "    i_post = np.bool_(i_post)\n",
    "    post_length = np.sum(i_post)\n",
    "    if not pre_length == post_length:\n",
    "        print(pre_length)\n",
    "        print(post_length)\n",
    "    #i_post = np.logical_and(t_data >= t_poststim, t_data < )\n",
    "    \n",
    "    post_length = pre_length\n",
    "    for key in dict_data[uuid].keys():\n",
    "        if \"lv_\" in key:\n",
    "            data_arr = dict_data[uuid][key]\n",
    "            dict_pre[key] = data_arr[i_pre]\n",
    "            dict_post[key] = data_arr[i_post]\n",
    "    # calculate values\n",
    "    totdist_pre = dict_pre[\"lv_totdist\"][-1] - dict_pre[\"lv_totdist\"][0]\n",
    "    totdist_post = dict_post[\"lv_totdist\"][-1] - dict_post[\"lv_totdist\"][0]\n",
    "    \n",
    "    totdist_abs_pre = dict_pre[\"lv_totdist_abs\"][-1] - dict_pre[\"lv_totdist_abs\"][0]\n",
    "    totdist_abs_post = dict_post[\"lv_totdist_abs\"][-1] - dict_post[\"lv_totdist_abs\"][0]\n",
    "    \n",
    "    running_pre = np.sum(dict_pre[\"lv_running\"])*4500/pre_length  # normalize to other data\n",
    "    running_post = np.sum(dict_pre[\"lv_running\"])*4500/post_length\n",
    "    \n",
    "    totdist_norm_pre = 10000*totdist_pre/4500.\n",
    "    totdist_norm_post = 10000*totdist_post/4500.\n",
    "    \n",
    "    totdist_abs_norm_pre = 10000*totdist_abs_pre/4500.\n",
    "    totdist_abs_norm_post = 10000*totdist_abs_post/4500.\n",
    "    \n",
    "    # add pre\n",
    "    event_uuids.append(uuid)\n",
    "    mouse_ids.append(mouse_id)\n",
    "    window_types.append(win_type)\n",
    "    exp_types.append(exp_type)\n",
    "    segment_types.append(\"baseline\")  # \"post-stimulation\"\n",
    "    segment_lengths.append(4500)\n",
    "    totdists.append(totdist_pre)\n",
    "    totdists_abs.append(totdist_abs_pre)\n",
    "    runnings.append(running_pre)\n",
    "    totdists_norm.append(totdist_norm_pre)\n",
    "    totdists_abs_norm.append(totdist_abs_norm_pre)    \n",
    "    # add post\n",
    "    event_uuids.append(uuid)\n",
    "    mouse_ids.append(mouse_id)\n",
    "    window_types.append(win_type)\n",
    "    exp_types.append(exp_type)\n",
    "    segment_types.append(\"post-stimulation\")\n",
    "    segment_lengths.append(4500)\n",
    "    totdists.append(totdist_post)\n",
    "    totdists_abs.append(totdist_abs_post)\n",
    "    runnings.append(running_post)\n",
    "    totdists_norm.append(totdist_norm_post)\n",
    "    totdists_abs_norm.append(totdist_abs_norm_post)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa5b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(data={\"event_uuid\": event_uuids, \"mouse_id\": mouse_ids, \"window_type\": window_types, \"exp_type\": exp_types, \"segment_type\": segment_types,\n",
    "                  \"segment_length\": segment_lengths, \"totdist\": totdists, \"totdist_abs\": totdists_abs, \"running\": runnings, \"totdist_norm\": totdists_norm, \"totdist_abs_norm\": totdists_abs_norm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa73534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.to_excel(\"C:\\\\Data\\\\bilat_loco_metrics.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bde679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

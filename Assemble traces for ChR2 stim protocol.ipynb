{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import labrotation.file_handling as fh\n",
    "import datadoc_util as ddutil\n",
    "from labrotation import two_photon_session as tps\n",
    "import h5py\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70973db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"SERVER_SYMBOL\" in env_dict.keys():\n",
    "    SERVER_SYMBOL = env_dict[\"SERVER_SYMBOL\"]\n",
    "else:\n",
    "    SERVER_SYMBOL = \"R\"\n",
    "    print(f\"Server symbol not found in .env file. Setting it to {SERVER_SYMBOL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064784a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = fh.open_dir(\"Choose export directory for results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b502d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = ddutil.DataDocumentation(env_dict[\"DATA_DOCU_FOLDER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643cadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.setDataDriveSymbol(SERVER_SYMBOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16588e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.checkFileConsistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdbeccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.GROUPING_DF[ddoc.GROUPING_DF[\"uuid\"] == \"513ed3d7c54042edab0f64df10882446\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = dt.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f88b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0813ad5",
   "metadata": {},
   "source": [
    "# Define recordings to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupings = ddoc.getRecordingsWithExperimentType([\"chr2_ctl\", \"chr2_sz\", \"chr2_szsd\", \"chr2_sd\", \"chr2_lfpsz_sd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b563dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the filtering by mouse\n",
    "df_groupings = df_groupings[df_groupings[\"mouse_id\"].isin([\"T370\", \"T413\", \"T430\", \"T452\", \"OPI-2239\", \"WEZ-8917\", \"WEZ-8924\", \"WEZ-8922\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9637e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupings.mouse_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e4baa",
   "metadata": {},
   "source": [
    "# Consistency check\n",
    "If no output, then everything looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_grouping, grouping in df_groupings.iterrows():\n",
    "    nd2_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"nd2\"])[1:]  # replace server symbol\n",
    "    lv_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"labview\"])[1:] \n",
    "    lvtime_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], os.path.splitext(grouping[\"labview\"])[0]+\"time.txt\")[1:] \n",
    "    nikmeta_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"nikon_meta\"])[1:] \n",
    "    \n",
    "    \n",
    "    if type(grouping[\"lfp\"]) is float:  # NaN has type float, otherwise should be string\n",
    "        lfp_fpath = None\n",
    "    else:\n",
    "        lfp_fpath =  SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"lfp\"])[1:] \n",
    "        if not os.path.exists(lfp_fpath):\n",
    "            print(lfp_fpath)\n",
    "    if not os.path.exists(nd2_fpath):\n",
    "        print(nd2_fpath)\n",
    "    if not os.path.exists(lv_fpath):\n",
    "        print(lv_fpath)\n",
    "    if not os.path.exists(lvtime_fpath):\n",
    "        print(lvtime_fpath)\n",
    "    if not os.path.exists(nikmeta_fpath):\n",
    "        print(nikmeta_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_file = True\n",
    "if append_to_file:\n",
    "    existing_uuids = []\n",
    "    original_fpath = fh.open_file(\"Choose h5 file to append to!\")\n",
    "    with h5py.File(original_fpath, \"r\") as hf:\n",
    "        for uuid in hf.keys():\n",
    "            existing_uuids.append(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272189b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_dict = dict()\n",
    "has_lfp_dict = dict()\n",
    "for i_grouping, grouping in df_groupings.iterrows():\n",
    "    uuid = grouping.uuid\n",
    "    if append_to_file:\n",
    "        if uuid in existing_uuids:\n",
    "            print(f\"skipping {uuid}...\")\n",
    "            continue\n",
    "    if uuid in sessions_dict.keys():\n",
    "        print(f\"skipping {uuid}...\")\n",
    "        continue\n",
    "    \n",
    "    nd2_fpath = os.path.join(grouping[\"folder\"], grouping[\"nd2\"]) # replace server symbol\n",
    "    lv_fpath =  os.path.join(grouping[\"folder\"], grouping[\"labview\"])\n",
    "    lvtime_fpath =  os.path.join(grouping[\"folder\"], os.path.splitext(grouping[\"labview\"])[0]+\"time.txt\") \n",
    "    nikmeta_fpath =  os.path.join(grouping[\"folder\"], grouping[\"nikon_meta\"])\n",
    "    \n",
    "    has_lfp = True\n",
    "   \n",
    "    \n",
    "    if type(grouping[\"lfp\"]) is float:  # NaN has type float, otherwise should be string\n",
    "        lfp_fpath = None\n",
    "        has_lfp = False\n",
    "    else:\n",
    "        lfp_fpath =  SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"lfp\"])[1:] \n",
    "    \n",
    "    session = tps.TwoPhotonSession.init_and_process(nd2_fpath, nikmeta_fpath, lv_fpath, lvtime_fpath, lfp_fpath, matlab_2p_folder)\n",
    "    \n",
    "    sessions_dict[uuid] = session\n",
    "    has_lfp_dict[uuid] = has_lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not append_to_file:\n",
    "    output_assembled_fpath = os.path.join(output_dir, f\"assembled_traces_{get_datetime_for_fname()}_ChR2.h5\")\n",
    "    print(f\"Saving traces to {output_assembled_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(t):\n",
    "    t1 = t[1:]\n",
    "    t0 = t[:-1]\n",
    "    dt = np.zeros(len(t))\n",
    "    dt[1:] = t1 - t0\n",
    "    dt[0] = dt[1]  # assume same step size to avoid 0\n",
    "    return dt\n",
    "def create_totdist_abs(speed, dt):\n",
    "    totdist_abs = np.zeros(len(speed))\n",
    "    totdist_abs[0] = speed[0]*dt[0]\n",
    "    for i in range(1, len(totdist_abs)):\n",
    "        totdist_abs[i] = totdist_abs[i-1] + abs(speed[i]*dt[i])\n",
    "    return totdist_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if append_to_file:\n",
    "    export_fpath = original_fpath\n",
    "    access_type = \"r+\"\n",
    "else:\n",
    "    access_type = \"w-\"\n",
    "    export_fpath = output_assembled_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbf568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with h5py.File(export_fpath, access_type) as hf:\n",
    "    for event_uuid in sessions_dict.keys():\n",
    "        \n",
    "        if append_to_file:\n",
    "            if event_uuid in existing_uuids:\n",
    "                continue\n",
    "        \n",
    "        \n",
    "        session = sessions_dict[event_uuid]\n",
    "        exp_type = ddoc.getExperimentTypeForUuid(event_uuid) \n",
    "        \n",
    "        segments = ddoc.getSegmentsForUUID(event_uuid).sort_values(by=\"frame_begin\")\n",
    "        if len(segments[segments[\"interval_type\"] == \"stimulation\"]) > 0:\n",
    "            stim_segment = segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0]\n",
    "        else:\n",
    "            print(event_uuid)\n",
    "            raise Exception()\n",
    "        n_frames = len(sessions_dict[event_uuid].mean_fluo)\n",
    "        \n",
    "        # bl frames: beginning until stimulation\n",
    "        # am frames: from first SD wave frame until end (to be consistent with TMEV am definition)\n",
    "        #            if no SD: then from end of stimulation\n",
    "        n_bl_frames = stim_segment[\"frame_begin\"] - 1  # frames 1 to x = x frames. stim_segment[\"frame_begin\"] is x+1 \n",
    "        n_stim_frames = stim_segment[\"frame_end\"] - stim_segment[\"frame_begin\"] + 1 # both end points inclusive -> +1 \n",
    "        \n",
    "        df = ddoc.getSegmentsForUUID(uuid)\n",
    "        df = df[df[\"interval_type\"] == \"stimulation\"].iloc[0]\n",
    "        i_stim_begin = df.frame_begin - 1\n",
    "        i_stim_end = df.frame_end - 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        if \"sd_wave\" in segments.interval_type.unique():\n",
    "            # first frame of SD wave until end\n",
    "            n_am_frames = n_frames - segments[segments[\"interval_type\"] == \"sd_wave\"].iloc[0].frame_begin + 1\n",
    "        else:\n",
    "            # first frame AFTER end of stim until end\n",
    "            n_am_frames = n_frames - segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0].frame_end\n",
    "        event_uuid_grp = hf.create_group(event_uuid)\n",
    "        #df_attributes = df_events[df_events[\"event_uuid\"] == event_uuid]\n",
    "        \n",
    "        mouse_id = ddoc.getMouseIdForUuid(event_uuid)\n",
    "        \n",
    "        event_uuid_grp.attrs[\"session_uuids\"] = [event_uuid]  # only one uuid, as ChR2 protocol is always single recording\n",
    "        event_uuid_grp.attrs[\"has_lfp\"] = [has_lfp_dict[event_uuid]]\n",
    "        event_uuid_grp.attrs[\"window_type\"] =  ddoc.getMouseWinInjInfo(mouse_id).window_type.iloc[0]\n",
    "        event_uuid_grp.attrs[\"n_frames\"] = n_frames\n",
    "        event_uuid_grp.attrs[\"mouse_id\"] = mouse_id\n",
    "        event_uuid_grp.attrs[\"exp_type\"] = exp_type\n",
    "        \n",
    "\n",
    "        event_uuid_grp.attrs[\"n_bl_frames\"] = n_bl_frames\n",
    "        event_uuid_grp.attrs[\"n_am_frames\"] = n_am_frames\n",
    "        hf[uuid].attrs[\"i_stim_begin_frame\"] = i_stim_begin\n",
    "        hf[uuid].attrs[\"i_stim_end_frame\"] = i_stsim_end\n",
    "        \n",
    "        lv_dist = session.belt_scn_dict['distance']\n",
    "        lv_speed = session.belt_scn_dict['speed']\n",
    "        lv_running = session.belt_scn_dict['running']\n",
    "        lv_totdist = session.belt_scn_dict['totdist']\n",
    "        lv_rounds = session.belt_scn_dict['rounds']\n",
    "        lv_t_s = session.belt_scn_dict['tsscn']/1000.\n",
    "        mean_fluo = session.mean_fluo\n",
    "        \n",
    "        lv_dt = create_dt(lv_t_s)\n",
    "        lv_totdist_abs = create_totdist_abs(lv_speed, lv_dt)\n",
    "        \n",
    "\n",
    "\n",
    "        # get lfp data\n",
    "        # lfp already matched to labview. lfp and movement channels t values should be same, but save them to be sure\n",
    "\n",
    "        if has_lfp_dict[event_uuid]:\n",
    "            lfp_t, lfp_y = session.lfp_lfp()\n",
    "            lfp_mov_t, lfp_mov_y = session.lfp_movement()\n",
    "        else:\n",
    "            lfp_t = lv_t_s.copy()\n",
    "            lfp_mov_t = lv_t_s.copy()\n",
    "\n",
    "            lfp_y = np.zeros(len(lfp_t))\n",
    "            lfp_mov_y = np.zeros(len(lfp_t))\n",
    "                \n",
    "        event_uuid_grp.attrs[\"n_lfp_steps\"] = len(lfp_t)\n",
    "        event_uuid_grp.attrs[\"n_lfp_mov_steps\"] = len(lfp_mov_t)\n",
    "        \n",
    "        event_uuid_grp.create_dataset(\"lfp_mov_t\", data=lfp_mov_t)\n",
    "        event_uuid_grp.create_dataset(\"lfp_mov_y\", data=lfp_mov_y)\n",
    "        event_uuid_grp.create_dataset(\"lfp_t\", data=lfp_t)\n",
    "        event_uuid_grp.create_dataset(\"lfp_y\", data=lfp_y)\n",
    "        event_uuid_grp.create_dataset(\"lv_dist\", data=lv_dist)\n",
    "        event_uuid_grp.create_dataset(\"lv_dt\", data=lv_dt)\n",
    "        event_uuid_grp.create_dataset(\"lv_rounds\", data=lv_rounds)\n",
    "        event_uuid_grp.create_dataset(\"lv_running\", data=lv_running)\n",
    "        event_uuid_grp.create_dataset(\"lv_speed\", data=lv_speed)\n",
    "        event_uuid_grp.create_dataset(\"lv_t_s\", data=lv_t_s)\n",
    "        event_uuid_grp.create_dataset(\"lv_totdist\", data=lv_totdist)\n",
    "        event_uuid_grp.create_dataset(\"lv_totdist_abs\", data=lv_totdist_abs)\n",
    "        event_uuid_grp.create_dataset(\"mean_fluo\", data=mean_fluo)\n",
    "        \n",
    "        \n",
    "        # replicate joint_session_metadata_dict from tmev assembled traces\n",
    "        if \"sd_wave\" in segments.interval_type.unique():\n",
    "            break_points = np.array([0, n_bl_frames, n_bl_frames + n_stim_frames, segments[segments[\"interval_type\"] == \"sd_wave\"].iloc[0].frame_begin + 1])\n",
    "        else:\n",
    "            break_points = np.array([0, n_bl_frames, n_bl_frames + n_stim_frames, segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0].frame_end + 1])\n",
    "        \n",
    "        event_uuid_grp.attrs[\"break_points\"] = break_points\n",
    "        event_uuid_grp.attrs[\"break_points_lfp\"] = np.searchsorted(lfp_t, lv_t_s[break_points])\n",
    "        \n",
    "        segment_type_break_points = np.array([row[\"frame_begin\"] - 1 for i_row, row in ddoc.getSegmentsForUUID(event_uuid).sort_values(by=\"frame_begin\").iterrows()])\n",
    "        event_uuid_grp.attrs[\"segment_type_break_points\"] = segment_type_break_points\n",
    "        event_uuid_grp.attrs[\"segment_type_break_points_lfp\"] = np.searchsorted(lfp_t, lv_t_s[segment_type_break_points])\n",
    "        event_uuid_grp.attrs[\"recording_break_points\"] =  np.array([0])\n",
    "        event_uuid_grp.attrs[\"recording_break_points_lfp\"] = np.array([0]) \n",
    "        \n",
    "        event_uuid_grp.attrs[\"recording_break_points_lfp\"] = np.array([0]) \n",
    "        \n",
    "        \n",
    "        if \"Time [s]\" in session.df_stim.columns:\n",
    "            event_uuid_grp.attrs[\"stim_start_end_time\"] = np.array(session.df_stim[\"Time [s]\"])\n",
    "        else:\n",
    "            event_uuid_grp.attrs[\"stim_start_end_time\"] = np.array(session.df_stim[\"Time [m:s.ms]\"])\n",
    "            \n",
    "        event_uuid_grp.attrs[\"stim_start_end_sw_time\"] = np.array(session.df_stim[\"SW Time [s]\"])  \n",
    "        event_uuid_grp.attrs[\"stim_start_end_nidaq_time\"] = np.array(session.df_stim[\"NIDAQ Time [s]\"])  \n",
    "    \n",
    "    \n",
    "        # get first imaging frame falling into stim, last imaging frame falling into stim\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d98cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: first check that all data is available (data documentation includes new mice etc...) before attempting to write to h5 file!\n",
    "# TODO: manually correct lfp-labview mismatch! put them in \"lfp_corrections.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a3496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45460bab",
   "metadata": {},
   "source": [
    "# Quality control\n",
    "TODO: do a waterfall plot of both locomotion traces to check matching quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968eb1a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce781759",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_speeds = []\n",
    "lv_ts = []\n",
    "lfp_speeds = []\n",
    "lfp_ts = []\n",
    "has_lfp_arr = []\n",
    "uuids_lis = []\n",
    "\n",
    "with h5py.File(export_fpath, \"r\") as hf:\n",
    "    for event_uuid in hf.keys():\n",
    "        uuids_lis.append(event_uuid)\n",
    "        has_lfp = hf[event_uuid].attrs[\"has_lfp\"]\n",
    "        #print(has_lfp)\n",
    "        #print(f'{len(hf[event_uuid][\"lfp_mov_t\"][()])} {len(hf[event_uuid][\"lv_t_s\"][()])}')\n",
    "        lv_speeds.append(hf[event_uuid][\"lv_speed\"][()])\n",
    "        lv_ts.append(hf[event_uuid][\"lv_t_s\"][()])\n",
    "        lfp_speeds.append(hf[event_uuid][\"lfp_mov_y\"][()])\n",
    "        lfp_ts.append(hf[event_uuid][\"lfp_mov_t\"][()])\n",
    "        lfp_mov_t_data = hf[event_uuid][\"lfp_mov_t\"][()]\n",
    "        has_lfp_arr.append(hf[event_uuid].attrs[\"has_lfp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa050df4",
   "metadata": {},
   "source": [
    "## Normalize traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 100\n",
    "lv_speeds_norm = []\n",
    "lfp_speeds_norm = []\n",
    "\n",
    "for i_event in range(len(lv_speeds)):\n",
    "    print(i_event)\n",
    "    min_lv_y = np.min(lv_speeds[i_event])\n",
    "    max_lv_y = np.max(lv_speeds[i_event])\n",
    "    lv_y = amplitude*(lv_speeds[i_event] - min_lv_y)/(max_lv_y - min_lv_y)\n",
    "    \n",
    "    min_lfp_y = min(lfp_speeds[i_event][1000:])\n",
    "    max_lfp_y = max(lfp_speeds[i_event][1000:])\n",
    "    lfp_y = amplitude*(lfp_speeds[i_event] - min_lfp_y)/(max_lfp_y - min_lfp_y)\n",
    "    \n",
    "    \n",
    "    lv_speeds_norm.append(lv_y)\n",
    "    lfp_speeds_norm.append(lfp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ccf83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offset = 0.0\n",
    "fig = plt.figure(figsize=(18,72))\n",
    "for i_event in range(len(lv_speeds)):\n",
    "    color1=\"black\"\n",
    "    color2=\"grey\"\n",
    "    lw = 1\n",
    "    if not has_lfp_arr[i_event]:\n",
    "        lw = 4\n",
    "        color1=\"red\"\n",
    "        color2=\"orange\"\n",
    "    plt.plot(lv_ts[i_event], lv_speeds_norm[i_event]+offset, linewidth=lw, c=color1)\n",
    "    offset += 0.5*amplitude\n",
    "    plt.plot(lfp_ts[i_event], lfp_speeds_norm[i_event]+offset, linewidth=lw, c=color2)\n",
    "    offset += 2*amplitude\n",
    "ax = plt.gca()\n",
    "#plt.xlim((0, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bbdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_bad = [11, 41, 63, 76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sessions = dict()\n",
    "for ind in i_bad:\n",
    "    uuid = uuids_lis[ind]\n",
    "    grouping = ddoc.getSessionFilesForUuid(uuid)\n",
    "    grouping = grouping.iloc[0]\n",
    "    \n",
    "    \n",
    "    nd2_fpath = os.path.join(grouping[\"folder\"], grouping[\"nd2\"])\n",
    "    lv_fpath = os.path.join(grouping[\"folder\"], grouping[\"labview\"])\n",
    "    lvtime_fpath = os.path.join(grouping[\"folder\"], os.path.splitext(grouping[\"labview\"])[0]+\"time.txt\")\n",
    "    nikmeta_fpath = os.path.join(grouping[\"folder\"], grouping[\"nikon_meta\"])\n",
    "    lfp_fpath =  os.path.join(grouping[\"folder\"], grouping[\"lfp\"])\n",
    "    \n",
    "    session = tps.TwoPhotonSession.init_and_process(nd2_fpath, nikmeta_fpath, lv_fpath, lvtime_fpath, lfp_fpath, matlab_2p_folder)\n",
    "    \n",
    "    bad_sessions[ind] = session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a32d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses = bad_sessions[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses.time_offs_lfp_nik\n",
    "# 11: 4.668004000000002\n",
    "# 41: 16.23998\n",
    "# 63: 4.544002000000001\n",
    "# 76: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sessions_dict[uuids_lis[76]].shift_lfp(6.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_t, lfp_y = sessions_dict[uuids_lis[76]].lfp_movement()\n",
    "lv_t = sessions_dict[uuids_lis[76]].belt_scn_dict[\"tsscn\"]\n",
    "lv_y = sessions_dict[uuids_lis[76]].belt_scn_dict[\"speed\"]\n",
    "lv_t_s = lv_t/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 10))\n",
    "ampl = 100.\n",
    "\n",
    "min_lfp = min(lfp_y[1000:])\n",
    "max_lfp = max(lfp_y[1000:])\n",
    "\n",
    "min_lv = min(lv_y)\n",
    "max_lv = max(lv_y)\n",
    "\n",
    "plt.plot(lv_t_s, ampl*(lv_y-min_lv)/(max_lv - min_lv), c=\"black\")\n",
    "plt.plot(lfp_t, ampl*(lfp_y-min_lfp)/(max_lfp - min_lfp) + ampl)\n",
    "plt.gca()\n",
    "plt.ylim((0, 300))\n",
    "plt.xlim((700, 800))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ea610",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(export_fpath, \"r+\") as hf:\n",
    "    for i in i_bad:\n",
    "        uuid = uuids_lis[i]\n",
    "        \n",
    "        del hf[uuid][\"lfp_mov_y\"]\n",
    "        del hf[uuid][\"lfp_mov_t\"]\n",
    "        del hf[uuid][\"lfp_t\"] \n",
    "        del hf[uuid][\"lfp_y\"] \n",
    "        \n",
    "        ses = bad_sessions[i]\n",
    "        lfp_t, lfp_y = ses.lfp_lfp()\n",
    "        mov_t, mov_y = ses.lfp_movement()\n",
    "        hf.create_dataset(f\"{uuid}/lfp_mov_t\", data=np.array(mov_t))\n",
    "        hf.create_dataset(f\"{uuid}/lfp_mov_y\", data=np.array(mov_y))\n",
    "        \n",
    "        hf.create_dataset(f\"{uuid}/lfp_y\", data=np.array(lfp_y))\n",
    "        hf.create_dataset(f\"{uuid}/lfp_t\", data=np.array(lfp_t))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

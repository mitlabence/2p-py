{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import labrotation.file_handling as fh\n",
    "import datadoc_util as ddutil\n",
    "from labrotation import two_photon_session as tps\n",
    "import h5py\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70973db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"SERVER_SYMBOL\" in env_dict.keys():\n",
    "    SERVER_SYMBOL = env_dict[\"SERVER_SYMBOL\"]\n",
    "else:\n",
    "    SERVER_SYMBOL = \"R\"\n",
    "    print(f\"Server symbol not found in .env file. Setting it to {SERVER_SYMBOL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064784a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = fh.open_dir(\"Choose export directory for results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b502d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = ddutil.DataDocumentation(env_dict[\"DATA_DOCU_FOLDER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643cadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.setDataDriveSymbol(SERVER_SYMBOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16588e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.checkFileConsistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdbeccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.GROUPING_DF[ddoc.GROUPING_DF[\"uuid\"] == \"513ed3d7c54042edab0f64df10882446\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = dt.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f88b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0813ad5",
   "metadata": {},
   "source": [
    "# Define recordings to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupings = ddoc.getRecordingsWithExperimentType([\"chr2_ctl\", \"chr2_sz\", \"chr2_szsd\", \"chr2_sd\", \"chr2_lfpsz_sd\", \"jrgeco_sd\", \"jrgeco_ctl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b563dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the filtering by mouse\n",
    "dset_dict = {\"all ChR2\": [\"T370\", \"T413\", \"T430\", \"T452\", \"OPI-2239\", \"WEZ-8917\", \"WEZ-8924\", \"WEZ-8922\"],\n",
    "            \"filtered ChR2\": [\"OPI-2239\", \"WEZ-8917\", \"WEZ-8924\", \"WEZ-8922\"],\n",
    "            \"filtered ChR2 CA1+NC\": [\"OPI-2239\", \"WEZ-8917\", \"WEZ-8924\", \"WEZ-8922\", \"T413\", \"T430\"]}\n",
    "\n",
    "df_groupings = df_groupings[df_groupings[\"mouse_id\"].isin(dset_dict[\"filtered ChR2 CA1+NC\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9637e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupings.mouse_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e4baa",
   "metadata": {},
   "source": [
    "# Consistency check\n",
    "If no output, then everything looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_grouping, grouping in df_groupings.iterrows():\n",
    "    nd2_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"nd2\"])[1:]  # replace server symbol\n",
    "    lv_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"labview\"])[1:] \n",
    "    lvtime_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], os.path.splitext(grouping[\"labview\"])[0]+\"time.txt\")[1:] \n",
    "    nikmeta_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"nikon_meta\"])[1:] \n",
    "    \n",
    "    \n",
    "    if type(grouping[\"lfp\"]) is float:  # NaN has type float, otherwise should be string\n",
    "        lfp_fpath = None\n",
    "    else:\n",
    "        lfp_fpath =  SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"lfp\"])[1:] \n",
    "        if not os.path.exists(lfp_fpath):\n",
    "            print(lfp_fpath)\n",
    "    if not os.path.exists(nd2_fpath):\n",
    "        print(nd2_fpath)\n",
    "    if not os.path.exists(lv_fpath):\n",
    "        print(lv_fpath)\n",
    "    if not os.path.exists(lvtime_fpath):\n",
    "        print(lvtime_fpath)\n",
    "    if not os.path.exists(nikmeta_fpath):\n",
    "        print(nikmeta_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_file = False\n",
    "if append_to_file:\n",
    "    existing_uuids = []\n",
    "    original_fpath = fh.open_file(\"Choose h5 file to append to!\")\n",
    "    with h5py.File(original_fpath, \"r\") as hf:\n",
    "        for uuid in hf.keys():\n",
    "            existing_uuids.append(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272189b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_dict = dict()\n",
    "has_lfp_dict = dict()\n",
    "for i_grouping, grouping in df_groupings.iterrows():\n",
    "    uuid = grouping.uuid\n",
    "    if append_to_file:\n",
    "        if uuid in existing_uuids:\n",
    "            print(f\"skipping {uuid}...\")\n",
    "            continue\n",
    "    if uuid in sessions_dict.keys():\n",
    "        print(f\"skipping {uuid}...\")\n",
    "        continue\n",
    "    \n",
    "    nd2_fpath = os.path.join(grouping[\"folder\"], grouping[\"nd2\"]) # replace server symbol\n",
    "    lv_fpath =  os.path.join(grouping[\"folder\"], grouping[\"labview\"])\n",
    "    lvtime_fpath =  os.path.join(grouping[\"folder\"], os.path.splitext(grouping[\"labview\"])[0]+\"time.txt\") \n",
    "    nikmeta_fpath =  os.path.join(grouping[\"folder\"], grouping[\"nikon_meta\"])\n",
    "    \n",
    "    has_lfp = True\n",
    "   \n",
    "    \n",
    "    if type(grouping[\"lfp\"]) is float:  # NaN has type float, otherwise should be string\n",
    "        lfp_fpath = None\n",
    "        has_lfp = False\n",
    "    else:\n",
    "        lfp_fpath =  SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"lfp\"])[1:] \n",
    "    \n",
    "    session = tps.TwoPhotonSession.init_and_process(nd2_fpath, nikmeta_fpath, lv_fpath, lvtime_fpath, lfp_fpath, matlab_2p_folder)\n",
    "    \n",
    "    sessions_dict[uuid] = session\n",
    "    has_lfp_dict[uuid] = has_lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not append_to_file:\n",
    "    output_assembled_fpath = os.path.join(output_dir, f\"assembled_traces_{get_datetime_for_fname()}_ChR2.h5\")\n",
    "    print(f\"Saving traces to {output_assembled_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(t):\n",
    "    t1 = t[1:]\n",
    "    t0 = t[:-1]\n",
    "    dt = np.zeros(len(t))\n",
    "    dt[1:] = t1 - t0\n",
    "    dt[0] = dt[1]  # assume same step size to avoid 0\n",
    "    return dt\n",
    "def create_totdist_abs(speed, dt):\n",
    "    totdist_abs = np.zeros(len(speed))\n",
    "    totdist_abs[0] = speed[0]*dt[0]\n",
    "    for i in range(1, len(totdist_abs)):\n",
    "        totdist_abs[i] = totdist_abs[i-1] + abs(speed[i]*dt[i])\n",
    "    return totdist_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1491bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if append_to_file:\n",
    "    export_fpath = original_fpath\n",
    "    access_type = \"r+\"\n",
    "else:\n",
    "    access_type = \"w-\"\n",
    "    export_fpath = output_assembled_fpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbf568",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(export_fpath, access_type) as hf:\n",
    "    for event_uuid in sessions_dict.keys():\n",
    "        \n",
    "        if append_to_file:\n",
    "            if event_uuid in existing_uuids:\n",
    "                continue\n",
    "        \n",
    "        session = sessions_dict[event_uuid]\n",
    "        exp_type = ddoc.getExperimentTypeForUuid(event_uuid) \n",
    "        \n",
    "        segments = ddoc.getSegmentsForUUID(event_uuid).sort_values(by=\"frame_begin\")\n",
    "        if len(segments[segments[\"interval_type\"] == \"stimulation\"]) > 0:\n",
    "            stim_segment = segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0]\n",
    "        else:\n",
    "            print(f\"Skipping recording with no data doc entry: {event_uuid}\")\n",
    "            continue\n",
    "            #raise Exception()\n",
    "        n_frames = len(sessions_dict[event_uuid].mean_fluo)\n",
    "        \n",
    "        # bl frames: beginning until stimulation\n",
    "        # am frames: from first SD wave frame until end (to be consistent with TMEV am definition)\n",
    "        #            if no SD: then from end of stimulation\n",
    "        n_bl_frames = stim_segment[\"frame_begin\"] - 1  # frames 1 to x = x frames. stim_segment[\"frame_begin\"] is x+1 \n",
    "        n_stim_frames = stim_segment[\"frame_end\"] - stim_segment[\"frame_begin\"] + 1 # both end points inclusive -> +1 \n",
    "        i_stim_begin_frame = stim_segment[\"frame_begin\"] - 1\n",
    "        i_stim_end_frame = stim_segment[\"frame_end\"] - 1\n",
    "        \n",
    "        \n",
    "        df = ddoc.getSegmentsForUUID(uuid)\n",
    "        df = df[df[\"interval_type\"] == \"stimulation\"].iloc[0]\n",
    "        i_stim_begin = df.frame_begin - 1\n",
    "        i_stim_end = df.frame_end - 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        if \"sd_wave\" in segments.interval_type.unique():\n",
    "            # first frame of SD wave until end\n",
    "            n_am_frames = n_frames - segments[segments[\"interval_type\"] == \"sd_wave\"].iloc[0].frame_begin + 1\n",
    "        else:\n",
    "            # first frame AFTER end of stim until end\n",
    "            n_am_frames = n_frames - segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0].frame_end\n",
    "        event_uuid_grp = hf.create_group(event_uuid)\n",
    "        #df_attributes = df_events[df_events[\"event_uuid\"] == event_uuid]\n",
    "        \n",
    "        mouse_id = ddoc.getMouseIdForUuid(event_uuid)\n",
    "        \n",
    "        event_uuid_grp.attrs[\"session_uuids\"] = [event_uuid]  # only one uuid, as ChR2 protocol is always single recording\n",
    "        event_uuid_grp.attrs[\"has_lfp\"] = [has_lfp_dict[event_uuid]]\n",
    "        event_uuid_grp.attrs[\"window_type\"] =  ddoc.getMouseWinInjInfo(mouse_id).window_type.iloc[0]\n",
    "        event_uuid_grp.attrs[\"n_frames\"] = n_frames\n",
    "        event_uuid_grp.attrs[\"mouse_id\"] = mouse_id\n",
    "        event_uuid_grp.attrs[\"exp_type\"] = exp_type\n",
    "        event_uuid_grp.attrs[\"i_stim_begin_frame\"] = i_stim_begin_frame\n",
    "        event_uuid_grp.attrs[\"i_stim_end_frame\"] = i_stim_end_frame\n",
    "        # add stim time\n",
    "        event_uuid_grp.attrs[\"stim_duration_s\"] = df_groupings[df_groupings[\"uuid\"] == event_uuid].iloc[0].stim_length\n",
    "        \n",
    "\n",
    "        event_uuid_grp.attrs[\"n_bl_frames\"] = n_bl_frames\n",
    "        event_uuid_grp.attrs[\"n_am_frames\"] = n_am_frames\n",
    "        event_uuid_grp.attrs[\"i_stim_begin_frame\"] = i_stim_begin\n",
    "        event_uuid_grp.attrs[\"i_stim_end_frame\"] = i_stim_end\n",
    "        \n",
    "        lv_dist = session.belt_scn_dict['distance']\n",
    "        lv_speed = session.belt_scn_dict['speed']\n",
    "        lv_running = session.belt_scn_dict['running']\n",
    "        lv_totdist = session.belt_scn_dict['totdist']\n",
    "        lv_rounds = session.belt_scn_dict['rounds']\n",
    "        lv_t_s = session.belt_scn_dict['tsscn']/1000.\n",
    "        mean_fluo = session.mean_fluo\n",
    "        \n",
    "        lv_dt = create_dt(lv_t_s)\n",
    "        lv_totdist_abs = create_totdist_abs(lv_speed, lv_dt)\n",
    "        \n",
    "\n",
    "\n",
    "        # get lfp data\n",
    "        # lfp already matched to labview. lfp and movement channels t values should be same, but save them to be sure\n",
    "\n",
    "        if has_lfp_dict[event_uuid]:\n",
    "            lfp_t, lfp_y = session.lfp_lfp()\n",
    "            lfp_mov_t, lfp_mov_y = session.lfp_movement()\n",
    "        else:\n",
    "            lfp_t = lv_t_s.copy()\n",
    "            lfp_mov_t = lv_t_s.copy()\n",
    "\n",
    "            lfp_y = np.zeros(len(lfp_t))\n",
    "            lfp_mov_y = np.zeros(len(lfp_t))\n",
    "                \n",
    "        event_uuid_grp.attrs[\"n_lfp_steps\"] = len(lfp_t)\n",
    "        event_uuid_grp.attrs[\"n_lfp_mov_steps\"] = len(lfp_mov_t)\n",
    "        \n",
    "        event_uuid_grp.create_dataset(\"lfp_mov_t\", data=lfp_mov_t)\n",
    "        event_uuid_grp.create_dataset(\"lfp_mov_y\", data=lfp_mov_y)\n",
    "        event_uuid_grp.create_dataset(\"lfp_t\", data=lfp_t)\n",
    "        event_uuid_grp.create_dataset(\"lfp_y\", data=lfp_y)\n",
    "        event_uuid_grp.create_dataset(\"lv_dist\", data=lv_dist)\n",
    "        event_uuid_grp.create_dataset(\"lv_dt\", data=lv_dt)\n",
    "        event_uuid_grp.create_dataset(\"lv_rounds\", data=lv_rounds)\n",
    "        event_uuid_grp.create_dataset(\"lv_running\", data=lv_running)\n",
    "        event_uuid_grp.create_dataset(\"lv_speed\", data=lv_speed)\n",
    "        event_uuid_grp.create_dataset(\"lv_t_s\", data=lv_t_s)\n",
    "        event_uuid_grp.create_dataset(\"lv_totdist\", data=lv_totdist)\n",
    "        event_uuid_grp.create_dataset(\"lv_totdist_abs\", data=lv_totdist_abs)\n",
    "        event_uuid_grp.create_dataset(\"mean_fluo\", data=mean_fluo)\n",
    "        \n",
    "        \n",
    "        # replicate joint_session_metadata_dict from tmev assembled traces\n",
    "        if \"sd_wave\" in segments.interval_type.unique():\n",
    "            break_points = np.array([0, n_bl_frames, n_bl_frames + n_stim_frames, segments[segments[\"interval_type\"] == \"sd_wave\"].iloc[0].frame_begin + 1])\n",
    "        else:\n",
    "            break_points = np.array([0, n_bl_frames, n_bl_frames + n_stim_frames, segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0].frame_end + 1])\n",
    "        \n",
    "        event_uuid_grp.attrs[\"break_points\"] = break_points\n",
    "        event_uuid_grp.attrs[\"break_points_lfp\"] = np.searchsorted(lfp_t, lv_t_s[break_points])\n",
    "        \n",
    "        segment_type_break_points = np.array([row[\"frame_begin\"] - 1 for i_row, row in ddoc.getSegmentsForUUID(event_uuid).sort_values(by=\"frame_begin\").iterrows()])\n",
    "        event_uuid_grp.attrs[\"segment_type_break_points\"] = segment_type_break_points\n",
    "        event_uuid_grp.attrs[\"segment_type_break_points_lfp\"] = np.searchsorted(lfp_t, lv_t_s[segment_type_break_points])\n",
    "        event_uuid_grp.attrs[\"recording_break_points\"] =  np.array([0])\n",
    "        event_uuid_grp.attrs[\"recording_break_points_lfp\"] = np.array([0]) \n",
    "        \n",
    "        event_uuid_grp.attrs[\"recording_break_points_lfp\"] = np.array([0]) \n",
    "        \n",
    "        \n",
    "        if \"Time [s]\" in session.df_stim.columns:\n",
    "            event_uuid_grp.attrs[\"stim_start_end_time\"] = np.array(session.df_stim[\"Time [s]\"])\n",
    "        else:\n",
    "            event_uuid_grp.attrs[\"stim_start_end_time\"] = np.array(session.df_stim[\"Time [m:s.ms]\"])\n",
    "            \n",
    "        event_uuid_grp.attrs[\"stim_start_end_sw_time\"] = np.array(session.df_stim[\"SW Time [s]\"])  \n",
    "        event_uuid_grp.attrs[\"stim_start_end_nidaq_time\"] = np.array(session.df_stim[\"NIDAQ Time [s]\"])  \n",
    "    \n",
    "    \n",
    "        # get first imaging frame falling into stim, last imaging frame falling into stim\n",
    "print(f\"Saved to {export_fpath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a3496",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45460bab",
   "metadata": {},
   "source": [
    "# Quality control\n",
    "TODO: do a waterfall plot of both locomotion traces to check matching quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968eb1a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce781759",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fluos = []\n",
    "lv_speeds = []\n",
    "lv_ts = []\n",
    "lfp = []\n",
    "lfp_speeds = []\n",
    "lfp_ts = []\n",
    "has_lfp_arr = []\n",
    "uuids_lis = []\n",
    "\n",
    "with h5py.File(export_fpath, \"r\") as hf:\n",
    "    for event_uuid in hf.keys():\n",
    "        uuids_lis.append(event_uuid)\n",
    "        has_lfp = hf[event_uuid].attrs[\"has_lfp\"]\n",
    "        #print(has_lfp)\n",
    "        #print(f'{len(hf[event_uuid][\"lfp_mov_t\"][()])} {len(hf[event_uuid][\"lv_t_s\"][()])}')\n",
    "        mean_fluos.append(hf[event_uuid][\"mean_fluo\"][()])\n",
    "        lv_speeds.append(hf[event_uuid][\"lv_speed\"][()])\n",
    "        lv_ts.append(hf[event_uuid][\"lv_t_s\"][()])\n",
    "        lfp.append(hf[event_uuid][\"lfp_y\"][()])\n",
    "        lfp_speeds.append(hf[event_uuid][\"lfp_mov_y\"][()])\n",
    "        lfp_ts.append(hf[event_uuid][\"lfp_mov_t\"][()])\n",
    "        lfp_mov_t_data = hf[event_uuid][\"lfp_mov_t\"][()]\n",
    "        has_lfp_arr.append(hf[event_uuid].attrs[\"has_lfp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa050df4",
   "metadata": {},
   "source": [
    "## Normalize traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73537f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.getSegmentsForUUID(uuids_lis[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = 100\n",
    "mean_fluos_norm = []\n",
    "lfp_norm = []\n",
    "lv_speeds_norm = []\n",
    "lfp_speeds_norm = []\n",
    "\n",
    "def norm_trace(trace):\n",
    "    min_trace = np.min(trace)\n",
    "    max_trace = np.max(trace)\n",
    "    return (trace - min_trace)/(max_trace - min_trace)\n",
    "\n",
    "for i_event in range(len(lv_speeds)):\n",
    "    print(i_event)\n",
    "    df_event = ddoc.getSegmentsForUUID(uuids_lis[i_event])\n",
    "    mean_fluo_raw = mean_fluos[i_event]\n",
    "    i_begin_stim = df_event[df_event[\"interval_type\"] == \"stimulation\"].frame_begin.iloc[0] - 1\n",
    "    i_end_stim = df_event[df_event[\"interval_type\"] == \"stimulation\"].frame_end.iloc[0]\n",
    "    mean_fluo_raw[i_begin_stim:i_end_stim] = np.max(mean_fluo_raw[i_end_stim:])\n",
    "    \n",
    "    mean_fluo = amplitude*norm_trace(mean_fluo_raw)\n",
    "    lfp_y = amplitude*norm_trace(lfp[i_event])\n",
    "    lv_y = amplitude*norm_trace(lv_speeds[i_event])\n",
    "    lfp_mov_y = amplitude*norm_trace(lfp_speeds[i_event])\n",
    "    \n",
    "    \n",
    "    mean_fluos_norm.append(mean_fluo)\n",
    "    lfp_norm.append(lfp_y)\n",
    "    lv_speeds_norm.append(lv_y)\n",
    "    lfp_speeds_norm.append(lfp_mov_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ccf83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offset = 0.0\n",
    "fig = plt.figure(figsize=(18,72))\n",
    "for i_event in range(len(lv_speeds)):\n",
    "    color1=\"black\"\n",
    "    color2=\"grey\"\n",
    "    color3=\"blue\"\n",
    "    color4=\"green\"\n",
    "    lw = 1\n",
    "    if not has_lfp_arr[i_event]:\n",
    "        lw = 4\n",
    "        color1=\"red\"\n",
    "        color2=\"orange\"\n",
    "    plt.plot(lv_ts[i_event], lv_speeds_norm[i_event]+offset, linewidth=lw, c=color1)\n",
    "    plt.text(320, offset+0.2*amplitude, s=uuids_lis[i_event], fontdict={\"fontsize\":20, \"color\": \"red\"})\n",
    "    offset += 0.5*amplitude\n",
    "    plt.plot(lfp_ts[i_event], lfp_speeds_norm[i_event]+offset, linewidth=lw, c=color2)\n",
    "    offset += amplitude\n",
    "    plt.plot(lfp_ts[i_event], lfp_norm[i_event]+offset, linewidth=lw, c=color3)\n",
    "    offset += amplitude\n",
    "    plt.plot(lv_ts[i_event], mean_fluos_norm[i_event]+offset, linewidth=lw, c=color4)\n",
    "    offset += 1.5*amplitude\n",
    "    \n",
    "ax = plt.gca()\n",
    "plt.xlim((250, 400))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"C:\\\\Data\\\\lfpmismatch.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93561f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matched nikon, lfp, lv loco, plus open lv complete, uncut trace and adjust it. Goal is to see how much loco is cut out before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "lv_t = []\n",
    "lv_speed = []\n",
    "with open(os.path.normpath(\"R:\\\\AG-Wenzel\\\\Group\\\\jrgeco\\\\OPI_2239_jrgeco\\\\locomotion_exp\\\\231018_OPI_2239_optostim_d2\\\\OPI2239.181023.1541.txt\"), \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line_list = line.rstrip().split(\"\\t\")\n",
    "        l.append(line_list)\n",
    "        lv_t.append(int(line_list[8]))\n",
    "        lv_speed.append(int(line_list[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b4279",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_dict = {}\n",
    "for uuid in uuids_lis:\n",
    "    df_session = ddoc.getSessionFilesForUuid(uuid)\n",
    "    lv_fpath = os.path.join(os.path.normpath(df_session[\"folder\"].iloc[0]), df_session[\"labview\"].iloc[0])\n",
    "    l = []\n",
    "    lv_t = []\n",
    "    lv_speed = []\n",
    "    with open(lv_fpath, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            line_list = line.rstrip().split(\"\\t\")\n",
    "            l.append(line_list)\n",
    "            lv_t.append(int(line_list[8]))\n",
    "            lv_speed.append(int(line_list[1]))\n",
    "    if len(l[-1]) < len(l[0]):\n",
    "        lv_t = lv_t[:-1]\n",
    "        lv_speed = lv_speed[:-1]\n",
    "    assert len(lv_speed) == len(lv_t)\n",
    "    lv_dict[uuid] = [np.array(lv_t), np.array(lv_speed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0.0\n",
    "fig = plt.figure(figsize=(18,72))\n",
    "for i_event in range(len(lv_speeds)):\n",
    "    uuid = uuids_lis[i_event]\n",
    "    color1=\"black\"\n",
    "    color2=\"red\"\n",
    "    color3=\"blue\"\n",
    "    color4=\"green\"\n",
    "    lw = 1\n",
    "    if not has_lfp_arr[i_event]:\n",
    "        lw = 4\n",
    "        color1=\"red\"\n",
    "        color2=\"orange\"\n",
    "    plt.plot(lv_ts[i_event], lv_speeds_norm[i_event]+offset, linewidth=lw, c=color1)\n",
    "    plt.text(320, offset+0.2*amplitude, s=uuid, fontdict={\"fontsize\":20, \"color\": \"red\"})\n",
    "    offset += amplitude\n",
    "    plt.plot(lv_dict[uuid][0]/1000., amplitude*norm_trace(lv_dict[uuid][1])+offset, linewidth=lw, c=color2)\n",
    "    offset += amplitude\n",
    "    plt.plot(lfp_ts[i_event], lfp_norm[i_event]+offset, linewidth=lw, c=color3)\n",
    "    offset += amplitude\n",
    "    plt.plot(lv_ts[i_event], mean_fluos_norm[i_event]+offset, linewidth=lw, c=color4)\n",
    "    offset += 1.5*amplitude\n",
    "    \n",
    "ax = plt.gca()\n",
    "plt.xlim((200, 500))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"C:\\\\Data\\\\lfp_vs_lv.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idea: take original raw data as well as tps original frequency but cut data. find latter in the former to get time stamps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282c947",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = tps.TwoPhotonSession.init_and_process_uuid(\"09e0277c86234572ac586ab18be1cd58\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add uncut stuff to assembled_traces?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c538ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_t_uncut, lv_y_uncut = lv_dict[\"09e0277c86234572ac586ab18be1cd58\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_y_cut = ses.belt_dict[\"speed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe3492",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_t_cut = ses.belt_dict[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e00f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_t_uncut = lv_t_uncut/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d3677",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_t_cut = lv_t_cut/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd7c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find the time where the 250-400 seconds happens (in frame indices)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = lv_y_uncut[250:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fcce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = lv_y_cut[np.logical_and(lv_t_cut > 250, lv_t_cut < 400) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = lv_y_cut[5000:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e834ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_y_uncut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f59b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_y_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lv_y_uncut) - len(lv_y_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa80b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_begin in range(0, len(lv_y_cut) - len(subset)):\n",
    "    if np.array_equal(subset, lv_y_uncut[i_begin:i_begin+len(subset)]):\n",
    "        print(i_begin)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d603599",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lv_y_uncut[5000:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f97d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_begin in range(len(lv_y_uncut) - len(lv_y_cut)):\n",
    "    if np.array_equal(lv_y_cut, lv_y_uncut[i_begin:i_begin+2000]):\n",
    "        print(i_begin)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lv_y_cut[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lv_y_uncut[450:1550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b183f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = lv_y_cut[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_lis = []\n",
    "for i_begin in range(len(lv_y_uncut) - len(subset)):\n",
    "    corrcoef = np.corrcoef(subset, lv_y_uncut[i_begin:i_begin + len(subset)])[0, 1]\n",
    "    if np.isnan(corrcoef):\n",
    "        c_lis.append(0)\n",
    "    else:\n",
    "        c_lis.append(corrcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232ba1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_lis = np.array(c_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815eb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_t_uncut_shifted = lv_t_uncut - lv_t_uncut[425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f76853",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.plot(lv_t_uncut_shifted, norm_trace(lv_y_uncut))\n",
    "plt.plot(lv_t_cut, norm_trace(lv_y_cut))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lv_y_uncut[425:425+len(subset)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93624418",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lv_y_cut[i_begin:i_begin+len(subset)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6044807",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_event in range(len(uuids_lis)):\n",
    "    uuid = uuids_lis[i_event]\n",
    "    lv_t_uncut, lv_y_uncut = lv_dict[uuid]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3480c8c",
   "metadata": {},
   "source": [
    "# Manually review bad sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bbdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_bad = [11, 41, 63, 76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sessions = dict()\n",
    "for ind in i_bad:\n",
    "    uuid = uuids_lis[ind]\n",
    "    grouping = ddoc.getSessionFilesForUuid(uuid)\n",
    "    grouping = grouping.iloc[0]\n",
    "    \n",
    "    \n",
    "    nd2_fpath = os.path.join(grouping[\"folder\"], grouping[\"nd2\"])\n",
    "    lv_fpath = os.path.join(grouping[\"folder\"], grouping[\"labview\"])\n",
    "    lvtime_fpath = os.path.join(grouping[\"folder\"], os.path.splitext(grouping[\"labview\"])[0]+\"time.txt\")\n",
    "    nikmeta_fpath = os.path.join(grouping[\"folder\"], grouping[\"nikon_meta\"])\n",
    "    lfp_fpath =  os.path.join(grouping[\"folder\"], grouping[\"lfp\"])\n",
    "    \n",
    "    session = tps.TwoPhotonSession.init_and_process(nd2_fpath, nikmeta_fpath, lv_fpath, lvtime_fpath, lfp_fpath, matlab_2p_folder)\n",
    "    \n",
    "    bad_sessions[ind] = session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsl = [\"9f57f50bf31a41c7af3da2a600bf7e42\",\n",
    "\"171693d0988c458a96c8198c7b8cfc28\",\n",
    "\"a6099849121f44ccbec237037971ab57\",\n",
    "\"e40f26d410ab452e8f8d59e5394ae0fe\",\n",
    "\"ae564f8c867f4f35aa971b6562c33a7c\",\n",
    "\"ccc54ca6dff843cb8c9abcc1251adf74\",\n",
    "\"65bff16a4cf04930a5cb14f489a8f99b\",\n",
    "\"30dc55d1a5dc4b0286d132e72f208ca6\",\n",
    "\"cdf06c160be947f59d6a03927d4e61e4\",\n",
    "\"d7a5ac8e2bc74382b3db503a6a5a07a5\",\n",
    "\"5ea6fd9c4cb542dbbc1f65305725cede\",\n",
    "\"06ebcf354f5c41519669f187e16de364\",\n",
    "\"50ab5da48817456fa63caa01a9f194ad\",\n",
    "\"73a27053f4bf4ae1b4ad96064b6dabc0\",\n",
    "\"cc7f02d61d66478b80f839221531c826\",\n",
    "\"8dd54649e47046239ebafc56eeb8b5b2\",\n",
    "\"44ca941252064dcabb0fe3d24a8dab49\",\n",
    "\"21c83d0b69ec4585a9a11f4ce6c24b99\",\n",
    "\"3dd896d33a0f42c698228fbe254ebd60\",\n",
    "\"b4d9a66fb341473d8cd9d845a2a26155\",\n",
    "\"a9694ce2973349cb9cb6b51f77c46b49\",\n",
    "\"4083acdccf8c4f158aa0a5e188861c2b\",\n",
    "\"db7a5cfc43954c19a439e71b9ff30c0f\",\n",
    "\"99efe8d2c15940e49ee66018023d0e99\",\n",
    "\"dc0f7ce9625940b5b2ca76d728458f0c\",\n",
    "\"717a0fb5afa247b3915768acf410db70\",\n",
    "\"757c430daa2349e198ddefa7a0277769\",\n",
    "\"92062a977958443e83011619b34eabb8\",\n",
    "\"3cb9934ddcc24cf7a922dca01bdb9448\",\n",
    "\"1f6388ca8d7f48a2bd8dbe250749e413\",\n",
    "\"7435d24e54b647e792ffd0b3c7bcda5a\",\n",
    "\"b48b7bfa08b7424390c067b2695ff712\",]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uuid in bsl:\n",
    "    if uuid in uuids_lis:\n",
    "        print(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a32d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses = bad_sessions[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ses.time_offs_lfp_nik\n",
    "# 11: 4.668004000000002\n",
    "# 41: 16.23998\n",
    "# 63: 4.544002000000001\n",
    "# 76: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa96f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sessions_dict[uuids_lis[76]].shift_lfp(6.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lfp_t, lfp_y = sessions_dict[uuids_lis[76]].lfp_movement()\n",
    "lv_t = sessions_dict[uuids_lis[76]].belt_scn_dict[\"tsscn\"]\n",
    "lv_y = sessions_dict[uuids_lis[76]].belt_scn_dict[\"speed\"]\n",
    "lv_t_s = lv_t/1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 10))\n",
    "ampl = 100.\n",
    "\n",
    "min_lfp = min(lfp_y[1000:])\n",
    "max_lfp = max(lfp_y[1000:])\n",
    "\n",
    "min_lv = min(lv_y)\n",
    "max_lv = max(lv_y)\n",
    "\n",
    "plt.plot(lv_t_s, ampl*(lv_y-min_lv)/(max_lv - min_lv), c=\"black\")\n",
    "plt.plot(lfp_t, ampl*(lfp_y-min_lfp)/(max_lfp - min_lfp) + ampl)\n",
    "plt.gca()\n",
    "plt.ylim((0, 300))\n",
    "plt.xlim((700, 800))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ea610",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(export_fpath, \"r+\") as hf:\n",
    "    for i in i_bad:\n",
    "        uuid = uuids_lis[i]\n",
    "        \n",
    "        del hf[uuid][\"lfp_mov_y\"]\n",
    "        del hf[uuid][\"lfp_mov_t\"]\n",
    "        del hf[uuid][\"lfp_t\"] \n",
    "        del hf[uuid][\"lfp_y\"] \n",
    "        \n",
    "        ses = bad_sessions[i]\n",
    "        lfp_t, lfp_y = ses.lfp_lfp()\n",
    "        mov_t, mov_y = ses.lfp_movement()\n",
    "        hf.create_dataset(f\"{uuid}/lfp_mov_t\", data=np.array(mov_t))\n",
    "        hf.create_dataset(f\"{uuid}/lfp_mov_y\", data=np.array(mov_y))\n",
    "        \n",
    "        hf.create_dataset(f\"{uuid}/lfp_y\", data=np.array(lfp_y))\n",
    "        hf.create_dataset(f\"{uuid}/lfp_t\", data=np.array(lfp_t))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

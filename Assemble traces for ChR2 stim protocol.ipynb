{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import labrotation.file_handling as fh\n",
    "import datadoc_util as ddutil\n",
    "from labrotation import two_photon_session as tps\n",
    "import h5py\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3989e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_SYMBOL = \"R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064784a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = fh.open_dir(\"Choose export directory for results!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b502d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = ddutil.DataDocumentation(env_dict[\"DATA_DOCU_FOLDER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643cadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = dt.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f88b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0813ad5",
   "metadata": {},
   "source": [
    "# Define recordings to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupings = ddoc.getRecordingsWithExperimentType([\"chr2_ctl\", \"chr2_sz\", \"chr2_szsd\", \"chr2_sd\", \"chr2_lfpsz_sd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b563dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the filtering by mouse\n",
    "df_groupings = df_groupings[df_groupings[\"mouse_id\"].isin([\"T370\", \"T413\", \"T430\", \"T452\", \"OPI-2239\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e4baa",
   "metadata": {},
   "source": [
    "# Consistency check\n",
    "If no output, then everything looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_grouping, grouping in df_groupings.iterrows():\n",
    "    nd2_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"nd2\"])[1:]  # replace server symbol\n",
    "    lv_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"labview\"])[1:] \n",
    "    lvtime_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], os.path.splitext(grouping[\"labview\"])[0]+\"time.txt\")[1:] \n",
    "    nikmeta_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"nikon_meta\"])[1:] \n",
    "    \n",
    "    \n",
    "    if type(grouping[\"lfp\"]) is float:  # NaN has type float, otherwise should be string\n",
    "        lfp_fpath = None\n",
    "    else:\n",
    "        lfp_fpath =  SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"lfp\"])[1:] \n",
    "        if not os.path.exists(lfp_fpath):\n",
    "            print(lfp_fpath)\n",
    "    if not os.path.exists(nd2_fpath):\n",
    "        print(nd2_fpath)\n",
    "    if not os.path.exists(lv_fpath):\n",
    "        print(lv_fpath)\n",
    "    if not os.path.exists(lvtime_fpath):\n",
    "        print(lvtime_fpath)\n",
    "    if not os.path.exists(nikmeta_fpath):\n",
    "        print(nikmeta_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_file = True\n",
    "if append_to_file:\n",
    "    existing_uuids = []\n",
    "    original_fpath = fh.open_file(\"Choose h5 file to append to!\")\n",
    "    with h5py.File(original_fpath, \"r\") as hf:\n",
    "        for uuid in hf.keys():\n",
    "            existing_uuids.append(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272189b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_dict = dict()\n",
    "has_lfp_dict = dict()\n",
    "for i_grouping, grouping in df_groupings.iterrows():\n",
    "    uuid = grouping.uuid\n",
    "    if append_to_file:\n",
    "        if uuid in existing_uuids:\n",
    "            print(f\"skipping {uuid}...\")\n",
    "            continue\n",
    "    \n",
    "    nd2_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"nd2\"])[1:]  # replace server symbol\n",
    "    lv_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"labview\"])[1:] \n",
    "    lvtime_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], os.path.splitext(grouping[\"labview\"])[0]+\"time.txt\")[1:] \n",
    "    nikmeta_fpath = SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"nikon_meta\"])[1:] \n",
    "    \n",
    "    has_lfp = True\n",
    "   \n",
    "    \n",
    "    if type(grouping[\"lfp\"]) is float:  # NaN has type float, otherwise should be string\n",
    "        lfp_fpath = None\n",
    "        has_lfp = False\n",
    "    else:\n",
    "        lfp_fpath =  SERVER_SYMBOL + os.path.join(grouping[\"folder\"], grouping[\"lfp\"])[1:] \n",
    "    \n",
    "    session = tps.TwoPhotonSession.init_and_process(nd2_fpath, nikmeta_fpath, lv_fpath, lvtime_fpath, lfp_fpath, matlab_2p_folder)\n",
    "    \n",
    "    sessions_dict[uuid] = session\n",
    "    has_lfp_dict[uuid] = has_lfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not append_to_file:\n",
    "    output_assembled_fpath = os.path.join(output_dir, f\"assembled_traces_{get_datetime_for_fname()}_ChR2.h5\")\n",
    "    print(f\"Saving traces to {output_assembled_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0a667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(t):\n",
    "    t1 = t[1:]\n",
    "    t0 = t[:-1]\n",
    "    dt = np.zeros(len(t))\n",
    "    dt[1:] = t1 - t0\n",
    "    dt[0] = dt[1]  # assume same step size to avoid 0\n",
    "    return dt\n",
    "def create_totdist_abs(speed, dt):\n",
    "    totdist_abs = np.zeros(len(speed))\n",
    "    totdist_abs[0] = speed[0]*dt[0]\n",
    "    for i in range(1, len(totdist_abs)):\n",
    "        totdist_abs[i] = totdist_abs[i-1] + abs(speed[i]*dt[i])\n",
    "    return totdist_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbf568",
   "metadata": {},
   "outputs": [],
   "source": [
    "if append_to_file:\n",
    "    export_fpath = original_fpath\n",
    "    access_type = \"r+\"\n",
    "else:\n",
    "    access_type = \"w-\"\n",
    "    export_fpath = output_assembled_fpath\n",
    "with h5py.File(export_fpath, access_type) as hf:\n",
    "    for event_uuid in sessions_dict.keys():\n",
    "        \n",
    "        if append_to_file:\n",
    "            if event_uuid in existing_uuids:\n",
    "                continue\n",
    "        \n",
    "        session = sessions_dict[event_uuid]\n",
    "        exp_type = ddoc.getExperimentTypeForUuid(event_uuid) \n",
    "        \n",
    "        segments = ddoc.getSegmentsForUUID(event_uuid).sort_values(by=\"frame_begin\")\n",
    "        if len(segments[segments[\"interval_type\"] == \"stimulation\"]) > 0:\n",
    "            stim_segment = segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0]\n",
    "        else:\n",
    "            print(event_uuid)\n",
    "            raise Exception()\n",
    "        n_frames = len(sessions_dict[event_uuid].mean_fluo)\n",
    "        \n",
    "        # bl frames: beginning until stimulation\n",
    "        # am frames: from first SD wave frame until end (to be consistent with TMEV am definition)\n",
    "        #            if no SD: then from end of stimulation\n",
    "        n_bl_frames = stim_segment[\"frame_begin\"] - 1  # frames 1 to x = x frames. stim_segment[\"frame_begin\"] is x+1 \n",
    "        n_stim_frames = stim_segment[\"frame_end\"] - stim_segment[\"frame_begin\"] + 1 # both end points inclusive -> +1 \n",
    "        \n",
    "        if \"sd_wave\" in segments.interval_type.unique():\n",
    "            # first frame of SD wave until end\n",
    "            n_am_frames = n_frames - segments[segments[\"interval_type\"] == \"sd_wave\"].iloc[0].frame_begin + 1\n",
    "        else:\n",
    "            # first frame AFTER end of stim until end\n",
    "            n_am_frames = n_frames - segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0].frame_end\n",
    "        event_uuid_grp = hf.create_group(event_uuid)\n",
    "        #df_attributes = df_events[df_events[\"event_uuid\"] == event_uuid]\n",
    "        \n",
    "        mouse_id = ddoc.getMouseIdForUuid(event_uuid)\n",
    "        \n",
    "        event_uuid_grp.attrs[\"session_uuids\"] = [event_uuid]  # only one uuid, as ChR2 protocol is always single recording\n",
    "        event_uuid_grp.attrs[\"has_lfp\"] = [has_lfp_dict[event_uuid]]\n",
    "        event_uuid_grp.attrs[\"window_type\"] =  ddoc.getMouseWinInjInfo(mouse_id).window_type.iloc[0]\n",
    "        event_uuid_grp.attrs[\"n_frames\"] = n_frames\n",
    "        event_uuid_grp.attrs[\"mouse_id\"] = mouse_id\n",
    "        event_uuid_grp.attrs[\"exp_type\"] = exp_type\n",
    "        \n",
    "\n",
    "        event_uuid_grp.attrs[\"n_bl_frames\"] = n_bl_frames\n",
    "        event_uuid_grp.attrs[\"n_am_frames\"] = n_am_frames\n",
    "        \n",
    "        \n",
    "        lv_dist = session.belt_scn_dict['distance']\n",
    "        lv_speed = session.belt_scn_dict['speed']\n",
    "        lv_running = session.belt_scn_dict['running']\n",
    "        lv_totdist = session.belt_scn_dict['totdist']\n",
    "        lv_rounds = session.belt_scn_dict['rounds']\n",
    "        lv_t_s = session.belt_scn_dict['tsscn']/1000.\n",
    "        mean_fluo = session.mean_fluo\n",
    "        \n",
    "        lv_dt = create_dt(lv_t_s)\n",
    "        lv_totdist_abs = create_totdist_abs(lv_speed, lv_dt)\n",
    "        \n",
    "\n",
    "\n",
    "        # get lfp data\n",
    "        # lfp already matched to labview. lfp and movement channels t values should be same, but save them to be sure\n",
    "\n",
    "        if has_lfp_dict[event_uuid]:\n",
    "            lfp_t, lfp_y = session.lfp_lfp()\n",
    "            lfp_mov_t, lfp_mov_y = session.lfp_movement()\n",
    "        else:\n",
    "            lfp_t = lv_t_s.copy()\n",
    "            lfp_mov_t = lv_t_s.copy()\n",
    "\n",
    "            lfp_y = np.zeros(len(lfp_t))\n",
    "            lfp_mov_y = np.zeros(len(lfp_t))\n",
    "                \n",
    "        event_uuid_grp.attrs[\"n_lfp_steps\"] = len(lfp_t)\n",
    "        event_uuid_grp.attrs[\"n_lfp_mov_steps\"] = len(lfp_mov_t)\n",
    "        \n",
    "        event_uuid_grp.create_dataset(\"lfp_mov_t\", data=lfp_mov_t)\n",
    "        event_uuid_grp.create_dataset(\"lfp_mov_y\", data=lfp_mov_y)\n",
    "        event_uuid_grp.create_dataset(\"lfp_t\", data=lfp_t)\n",
    "        event_uuid_grp.create_dataset(\"lfp_y\", data=lfp_y)\n",
    "        event_uuid_grp.create_dataset(\"lv_dist\", data=lv_dist)\n",
    "        event_uuid_grp.create_dataset(\"lv_dt\", data=lv_dt)\n",
    "        event_uuid_grp.create_dataset(\"lv_rounds\", data=lv_rounds)\n",
    "        event_uuid_grp.create_dataset(\"lv_running\", data=lv_running)\n",
    "        event_uuid_grp.create_dataset(\"lv_speed\", data=lv_speed)\n",
    "        event_uuid_grp.create_dataset(\"lv_t_s\", data=lv_t_s)\n",
    "        event_uuid_grp.create_dataset(\"lv_totdist\", data=lv_totdist)\n",
    "        event_uuid_grp.create_dataset(\"lv_totdist_abs\", data=lv_totdist_abs)\n",
    "        event_uuid_grp.create_dataset(\"mean_fluo\", data=mean_fluo)\n",
    "        \n",
    "        \n",
    "        # replicate joint_session_metadata_dict from tmev assembled traces\n",
    "        if \"sd_wave\" in segments.interval_type.unique():\n",
    "            break_points = np.array([0, n_bl_frames, n_bl_frames + n_stim_frames, segments[segments[\"interval_type\"] == \"sd_wave\"].iloc[0].frame_begin + 1])\n",
    "        else:\n",
    "            break_points = np.array([0, n_bl_frames, n_bl_frames + n_stim_frames, segments[segments[\"interval_type\"] == \"stimulation\"].iloc[0].frame_end + 1])\n",
    "        \n",
    "        event_uuid_grp.attrs[\"break_points\"] = break_points\n",
    "        event_uuid_grp.attrs[\"break_points_lfp\"] = np.searchsorted(lfp_t, lv_t_s[break_points])\n",
    "        \n",
    "        segment_type_break_points = np.array([row[\"frame_begin\"] - 1 for i_row, row in ddoc.getSegmentsForUUID(event_uuid).sort_values(by=\"frame_begin\").iterrows()])\n",
    "        event_uuid_grp.attrs[\"segment_type_break_points\"] = segment_type_break_points\n",
    "        event_uuid_grp.attrs[\"segment_type_break_points_lfp\"] = np.searchsorted(lfp_t, lv_t_s[segment_type_break_points])\n",
    "        event_uuid_grp.attrs[\"recording_break_points\"] =  np.array([0])\n",
    "        event_uuid_grp.attrs[\"recording_break_points_lfp\"] = np.array([0]) \n",
    "        \n",
    "        event_uuid_grp.attrs[\"recording_break_points_lfp\"] = np.array([0]) \n",
    "        \n",
    "        \n",
    "        if \"Time [s]\" in session.df_stim.columns:\n",
    "            event_uuid_grp.attrs[\"stim_start_end_time\"] = np.array(session.df_stim[\"Time [s]\"])\n",
    "        else:\n",
    "            event_uuid_grp.attrs[\"stim_start_end_time\"] = np.array(session.df_stim[\"Time [m:s.ms]\"])\n",
    "            \n",
    "        event_uuid_grp.attrs[\"stim_start_end_sw_time\"] = np.array(session.df_stim[\"SW Time [s]\"])  \n",
    "        event_uuid_grp.attrs[\"stim_start_end_nidaq_time\"] = np.array(session.df_stim[\"NIDAQ Time [s]\"])  \n",
    "    \n",
    "    \n",
    "        # get first imaging frame falling into stim, last imaging frame falling into stim\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce781759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

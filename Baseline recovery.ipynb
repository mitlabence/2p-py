{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labrotation.file_handling as fh\n",
    "import h5py\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps\n",
    "import seaborn as sns\n",
    "import uuid  # for unique labeling of sessions and coupling arrays (mouse velocity, distance, ...) to sessions in dataframe \n",
    "from matplotlib import cm  # colormap\n",
    "import datadoc_util\n",
    "from labrotation import two_photon_session as tps\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47211f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dsets = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = False\n",
    "save_as_eps = False\n",
    "save_as_pdf = False\n",
    "if save_as_eps:\n",
    "    output_format = \".eps\"\n",
    "elif save_as_pdf:\n",
    "    output_format=\".pdf\"\n",
    "else:\n",
    "    output_format = \".jpg\"\n",
    "if save_figs:\n",
    "    print(output_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    docu_folder = fh.open_dir(\"Choose folder containing folders for each mouse!\")\n",
    "print(f\"Selected folder:\\n\\t{docu_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25389df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"documentation\" in os.listdir(docu_folder):\n",
    "    mouse_folder = os.path.join(docu_folder, \"documentation\")\n",
    "else:\n",
    "    mouse_folder = docu_folder\n",
    "mouse_names = os.listdir(mouse_folder)\n",
    "print(f\"Mice detected:\")\n",
    "for mouse in mouse_names:\n",
    "    print(f\"\\t{mouse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = datetime.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb446ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = env_dict[\"DOWNLOADS_FOLDER\"]\n",
    "print(f\"Output files will be saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24259d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = datadoc_util.DataDocumentation(docu_folder)\n",
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cba8cd",
   "metadata": {},
   "source": [
    "## Load all seizures dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd358659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = ddoc.getEventsDf()\n",
    "df_events = df_events[df_events[\"event_type\"] == \"sz\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2dee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_traces_fpath = fh.open_file(\"Open .h5 file containing assembled traces for all seizures!\")\n",
    "print(event_traces_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6793c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colors = ddoc.getColorings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fab3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d391371",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_ca1 = []\n",
    "traces_nc = []\n",
    "\n",
    "mouse_ids_ca1 = []\n",
    "mouse_ids_nc = []\n",
    "\n",
    "uuids_ca1 = []\n",
    "uuids_nc = []\n",
    "\n",
    "session_uuids_ca1 = []\n",
    "session_uuids_nc = []\n",
    "\n",
    "recording_break_points_ca1 = []\n",
    "recording_break_points_nc = []\n",
    "\n",
    "n_bl_frames = 5000\n",
    "n_am_frames = 5000\n",
    "\n",
    "# first keys are event uuids, inside the following dataset names:\n",
    "# 'lfp_mov_t', 'lfp_mov_y', 'lfp_t', 'lfp_y', 'lv_dist', 'lv_rounds', \n",
    "# 'lv_running', 'lv_speed', 'lv_t_s', 'lv_totdist', 'mean_fluo'\n",
    "with h5py.File(event_traces_fpath, \"r\") as hf:\n",
    "    for uuid in hf.keys():\n",
    "        win_type = hf[uuid].attrs[\"window_type\"]\n",
    "        mean_fluo = np.array(hf[uuid][\"mean_fluo\"])\n",
    "        assert n_bl_frames == hf[uuid].attrs[\"n_bl_frames\"]\n",
    "        assert n_am_frames == hf[uuid].attrs[\"n_am_frames\"]\n",
    "        mouse_id = hf[uuid].attrs[\"mouse_id\"]\n",
    "        if win_type == \"Cx\":\n",
    "            traces_nc.append(mean_fluo)\n",
    "            uuids_nc.append(uuid)\n",
    "            session_uuids_nc.append(hf[uuid].attrs[\"session_uuids\"])\n",
    "            recording_break_points_nc.append(hf[uuid].attrs[\"recording_break_points\"])\n",
    "            mouse_ids_nc.append(mouse_id)\n",
    "        elif win_type == \"CA1\":\n",
    "            traces_ca1.append(mean_fluo)\n",
    "            uuids_ca1.append(uuid)\n",
    "            session_uuids_ca1.append(hf[uuid].attrs[\"session_uuids\"])\n",
    "            recording_break_points_ca1.append(hf[uuid].attrs[\"recording_break_points\"])\n",
    "            mouse_ids_ca1.append(mouse_id)\n",
    "        else:\n",
    "            print(f\"{win_type} not recognized window type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eee785",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_ca1 = [df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0] for mouse_id in mouse_ids_ca1]\n",
    "colors_nc = [df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0] for mouse_id in mouse_ids_nc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed964b",
   "metadata": {},
   "source": [
    "## Get baseline values\n",
    "Calculated as lowest 5% of data points in baseline segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fbe04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_percent = 0.05  # 5% of baseline to be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: these take lowest values of the whole traces!\n",
    "#baselines_ca1 = [np.sort(traces_ca1[i][:floor(lowest_percent*n_bl_frames)]) for i in range(len(traces_ca1))]\n",
    "#baselines_nc = [np.sort(traces_nc[i][:floor(lowest_percent*n_bl_frames)]) for i in range(len(traces_nc))]\n",
    "\n",
    "baselines_ca1 = [np.min(traces_ca1[i][:n_bl_frames]) for i in range(len(traces_ca1))]\n",
    "baselines_nc = [np.min(traces_nc[i][:n_bl_frames]) for i in range(len(traces_nc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcafc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amplitude between bl and sz ampl, sd ampl!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc2e3d",
   "metadata": {},
   "source": [
    "## Get aftermath values\n",
    "in 20 sec windows, get minimum value of fluorescence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2b480",
   "metadata": {},
   "source": [
    "### Calculate first normal frames\n",
    "Use data documentation for corresponding recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ca1: need to find first segment after the \"sd_extinction\" segment, and find the corresponding index in the (5000 + sz + 5000) traces\n",
    "first_frames_ca1 = []\n",
    "rec_uuids_ca1 = []\n",
    "for i_event in range(len(traces_ca1)):\n",
    "    event_uuid = uuids_ca1[i_event]\n",
    "    # get all segments belonging to aftermath\n",
    "    df_event = df_events[(df_events[\"event_uuid\"] == event_uuid) & (df_events[\"interval_type\"] == \"am\")]\n",
    "    # for all recordings contributing to aftermath, look which one contains sd_extinction\n",
    "    i_frame = len(traces_ca1[i_event]) - n_am_frames  # points to first am frame right now\n",
    "    next_segment_stop = False  # flag to stop on reaching next segment\n",
    "    found_frame = False  # flag to mark if first frame to take was found\n",
    "    am_rec_uuid = None\n",
    "    for i_row, am_row in df_event.iterrows():  # loop over recordings participating in aftermath trace\n",
    "        # begin and end frames of am in current recording\n",
    "        am_begin_frame = am_row[\"begin_frame\"]\n",
    "        am_end_frame = am_row[\"end_frame\"]\n",
    "        # uuid of current recording\n",
    "        rec_uuid = am_row[\"recording_uuid\"]\n",
    "        # get all segments after start of am\n",
    "        i_first_am = ddoc.getSegmentForFrame(rec_uuid, am_begin_frame).index[0]\n",
    "        i_last_am = ddoc.getSegmentForFrame(rec_uuid, am_end_frame).index[0]\n",
    "        am_segments = ddoc.getSegmentsForUUID(rec_uuid).loc[i_first_am:i_last_am+1]\n",
    "        am_rec_uuid = rec_uuid\n",
    "        for i_segment_row, segment_row in am_segments.iterrows():\n",
    "            if next_segment_stop:  # first segment after sd_extinction reached. Take this as start for baseline return observation\n",
    "                break\n",
    "            if segment_row[\"interval_type\"] == \"sd_extinction\":\n",
    "                next_segment_stop = True\n",
    "            segment_length = segment_row[\"frame_end\"] - segment_row[\"frame_begin\"] + 1  # both inclusive -> need +1\n",
    "            i_frame += segment_length\n",
    "        if found_frame:\n",
    "            break\n",
    "    first_frames_ca1.append(i_frame)\n",
    "    rec_uuids_ca1.append(am_rec_uuid)\n",
    "\n",
    "# nc: there is no SD, so just take first am frame as it is\n",
    "first_frames_nc = [len(traces_nc[i]) - n_am_frames for i in range(len(traces_nc))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_length_seconds = 10\n",
    "interval_length = 15*interval_length_seconds  # 15 Hz * 20 seconds\n",
    "n_intervals = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8546f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "aftermath_ca1 = [ np.array([np.min( traces_ca1[i][ first_frames_ca1[i] + j*interval_length : first_frames_ca1[i] + (j+1)*interval_length  ] )  for j in range(n_intervals)]) for i in range(len(traces_ca1)) ] \n",
    "aftermath_nc = [ np.array([np.min( traces_nc[i][ first_frames_nc[i] + j*interval_length : first_frames_nc[i] + (j+1)*interval_length  ] )  for j in range(n_intervals)]) for i in range(len(traces_nc)) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fae122",
   "metadata": {},
   "source": [
    "## Create dataframe\n",
    "Columns should be: uuid, value (numeric), value_type (bl, 20s, 40s, ... 200 s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_names = [\"baseline_mean\", \"baseline_std\"] + [f\"{20*i}s\" for i in range(1, n_intervals+1)]\n",
    "data_dict = {\"uuid\": [], \"value\": [], \"value_type\": []}\n",
    "\n",
    "# get baseline values for CA1 and NC\n",
    "\n",
    "for i_event_ca1 in range(len(baselines_ca1)):\n",
    "    uuids = [uuids_ca1[i_event_ca1]]  # only one baseline value per event\n",
    "    value_types = [\"bl\"]\n",
    "    data_dict[\"uuid\"] += uuids\n",
    "    data_dict[\"value\"] += [baselines_ca1[i_event_ca1]]\n",
    "    data_dict[\"value_type\"] += value_types\n",
    "\n",
    "for i_event_nc in range(len(baselines_nc)):\n",
    "    uuids = [uuids_nc[i_event_nc]] # only one baseline value per event\n",
    "    value_types = [\"bl\"]\n",
    "    data_dict[\"uuid\"] += uuids\n",
    "    data_dict[\"value\"] += [baselines_nc[i_event_nc]]\n",
    "    data_dict[\"value_type\"] += value_types        \n",
    "\n",
    "# get 20, 40, ..., 200 s values for CA1 and NC\n",
    "\n",
    "for i_event_ca1 in range(len(aftermath_ca1)):\n",
    "    uuids = [uuids_ca1[i_event_ca1]]*len(aftermath_ca1[i_event_ca1])\n",
    "    value_types = [f\"{(i+1)*interval_length_seconds}s\" for i in range(n_intervals)]\n",
    "    assert len(uuids) == len(value_types)\n",
    "    assert len(uuids) == len(aftermath_ca1[i_event_ca1])\n",
    "    data_dict[\"uuid\"] += uuids\n",
    "    data_dict[\"value\"] += list(aftermath_ca1[i_event_ca1])\n",
    "    data_dict[\"value_type\"] += value_types\n",
    "\n",
    "for i_event_nc in range(len(aftermath_nc)):\n",
    "    uuids = [uuids_nc[i_event_nc]]*len(aftermath_nc[i_event_nc])\n",
    "    value_types = [f\"{(i+1)*interval_length_seconds}s\" for i in range(n_intervals)]\n",
    "    assert len(uuids) == len(value_types)\n",
    "    assert len(uuids) == len(aftermath_nc[i_event_nc])\n",
    "    data_dict[\"uuid\"] += uuids\n",
    "    data_dict[\"value\"] += list(aftermath_nc[i_event_nc])\n",
    "    data_dict[\"value_type\"] += value_types   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "sns.lineplot(data=df, palette=\"tab10\", x=\"value_type\", y=\"value\", hue=\"uuid\", linewidth=2.5, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bl_traces = []\n",
    "all_am_traces = []\n",
    "for i_tr in range(len(traces_ca1)):\n",
    "    all_am_traces.append(traces_ca1[i_tr][first_frames_ca1[i_tr]:])\n",
    "    all_bl_traces.append(traces_ca1[i_tr][n_bl_frames - 1000 :n_bl_frames])\n",
    "for i_tr in range(len(traces_nc)):\n",
    "    all_am_traces.append( traces_nc[i_tr][first_frames_nc[i_tr]:])\n",
    "    all_bl_traces.append(traces_nc[i_tr][n_bl_frames - 1000 :n_bl_frames])\n",
    "    \n",
    "bl_x = np.array([i-len(all_bl_traces[0])+1 for i in range(len(all_bl_traces[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: lowess filter? Somehow filter this signal!\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "for tr in all_bl_traces:\n",
    "    plt.plot(bl_x, tr)\n",
    "for tr in all_am_traces:\n",
    "    plt.plot(tr)\n",
    "plt.ylim((0, 60))\n",
    "#plt.xlim((-10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5055887",
   "metadata": {},
   "source": [
    "# Recovery analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of trace indices that are sorted by mouse\n",
    "event_uuid_mouse_id_i_trace_ca1 = []  # list of (event_uuid, mouse_id, i_trace) tuples\n",
    "event_uuid_mouse_id_i_trace_nc  = []  # list of (event_uuid, mouse_id, i_trace) tuples\n",
    "\n",
    "\n",
    "for event_uuid in df_events[\"event_uuid\"].unique():\n",
    "    mouse_id = df_events[df_events[\"event_uuid\"] == event_uuid].mouse_id.iloc[0]\n",
    "    if event_uuid in uuids_ca1:\n",
    "        i_trace = uuids_ca1.index(event_uuid)\n",
    "        event_uuid_mouse_id_i_trace_ca1.append((event_uuid, mouse_id, i_trace))\n",
    "    elif event_uuid in uuids_nc:\n",
    "        i_trace = uuids_nc.index(event_uuid)\n",
    "        event_uuid_mouse_id_i_trace_nc.append((event_uuid, mouse_id, i_trace))\n",
    "        \n",
    "    else:\n",
    "        print(f\"Unknown event_uuid: {event_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b43ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_width_s = 10\n",
    "window_step_s = 5\n",
    "imaging_frequency = 15. # in Hz\n",
    "n_frames_before_nc = 200  # include 200 frames just before aftermath for NC recordings  \n",
    "n_frames_before_ca1 = 0\n",
    "n_windows_post_darkest = 40 # dataset consists of bl, darkest point, and this many windows post darkest point\n",
    "\n",
    "# define baseline windows\n",
    "bl_windows_nc = [(3950, 4100) for i in range(len(traces_nc))]  # for neocortex, allow for ~1 min before Sz (LFP sz comes earlier)\n",
    "bl_windows_ca1 = [(4850, 5000) for i in range(len(traces_ca1))]  # for CA1, immediately before Sz onset\n",
    "\n",
    "i_frame_begin_bl = 3850  # in 0-indexing, the first frame to be included in baseline\n",
    "i_frame_end_bl = 4000  # in 0-indexing, the first frame after baseline (i.e. not included)\n",
    "\n",
    "time_points = [\"bl\", \"darkest\"] + [f\"{(i+1)*window_step_s}s\" for i in range(n_windows_post_darkest)]\n",
    "time_points_numeric = [-1, 0] + [(i+1)*window_step_s for i in range(n_windows_post_darkest)]\n",
    "time_points_numeric = np.array(time_points_numeric)\n",
    "\n",
    "window_width_frames = int(window_width_s*imaging_frequency)\n",
    "window_step_frames = int(window_step_s*imaging_frequency)\n",
    "\n",
    "def get_metric_for_window(trace_window):\n",
    "    lowest_5p_indices = np.argsort(trace_window)[:int(0.05*len(trace_window))]\n",
    "    lowest_5p = trace_window[lowest_5p_indices]\n",
    "    return np.median(lowest_5p)\n",
    "\n",
    "def get_recovery_data(complete_trace, i_frame_begin_bl, i_frame_end_bl, n_frames_before_am=0):\n",
    "    # n_frames_before_am: for NC, need to include a few frames before the segment \"aftermath\" begins, due to mistakes in \n",
    "    # manual classification. In CA1, this is not necessary\n",
    "    \n",
    "    metrics_list = []\n",
    "    x_list = []\n",
    "    \n",
    "    \n",
    "    # The complete trace should consist of 5000 bl, x Sz, 5000 am frames.\n",
    "    # get bl as just before Sz begin\n",
    "    bl_trace = complete_trace[i_frame_begin_bl:i_frame_end_bl]\n",
    "    x_bl = (i_frame_begin_bl + i_frame_end_bl)//2  # TODO: assign proper x\n",
    "    y_bl = get_metric_for_window(bl_trace)\n",
    "    \n",
    "    # add bl to dataset\n",
    "    x_list.append(x_bl)\n",
    "    metrics_list.append(y_bl)\n",
    "    \n",
    "    # get am 5p darkest points\n",
    "    sorted_indices = np.argsort(complete_trace)\n",
    "    sorted_am_indices = sorted_indices[sorted_indices > len(complete_trace) - 5000 - n_frames_before_am]\n",
    "    am_x_5p_lowest = sorted_am_indices[:int(0.05*(5000+n_frames_before_am))] \n",
    "    \n",
    "    # get single coordinate for darkest part\n",
    "    # find darkest 5p, take earliest 50 of them, get median frame index of these, round down to integer frame\n",
    "    x_am_darkest = int(floor(np.median(np.sort(am_x_5p_lowest)[:50])))\n",
    "    \n",
    "    # create sliding windows, calculate metric\n",
    "    for i_window in range(n_windows_post_darkest+1):  # window around darkest point + n_windows_post_darkest windows\n",
    "        x_val = x_am_darkest + i_window*window_step_frames\n",
    "        window_half_width = window_width_frames//2\n",
    "        window_trace = complete_trace[x_val - window_half_width : x_val + window_half_width]\n",
    "        y_val = get_metric_for_window(window_trace)\n",
    "        \n",
    "        x_list.append(x_val)\n",
    "        metrics_list.append(y_val)\n",
    "        \n",
    "    return (x_list, metrics_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745a53e",
   "metadata": {},
   "source": [
    "## Calculate metrics for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9699f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recovery_ca1 = [[] for i in range(len(traces_ca1))]\n",
    "y_recovery_ca1 = [[] for i in range(len(traces_ca1))]\n",
    "\n",
    "x_recovery_nc = [[] for i in range(len(traces_nc))]\n",
    "y_recovery_nc = [[] for i in range(len(traces_nc))]\n",
    "\n",
    "\n",
    "for event_uuid, mouse_id, i_trace in event_uuid_mouse_id_i_trace_nc:\n",
    "    x_data, y_data = get_recovery_data(traces_nc[i_trace], bl_windows_nc[i_trace][0], bl_windows_nc[i_trace][1], n_frames_before_nc)\n",
    "    x_recovery_nc[i_trace] = x_data\n",
    "    y_recovery_nc[i_trace] = y_data\n",
    "\n",
    "    \n",
    "for event_uuid, mouse_id, i_trace in event_uuid_mouse_id_i_trace_ca1:\n",
    "    x_data, y_data = get_recovery_data(traces_ca1[i_trace], bl_windows_ca1[i_trace][0], bl_windows_ca1[i_trace][1], n_frames_before_ca1)\n",
    "    x_recovery_ca1[i_trace] = x_data\n",
    "    y_recovery_ca1[i_trace] = y_data\n",
    "    \n",
    "x_recovery_ca1 = np.array(x_recovery_ca1, dtype=np.int16)\n",
    "x_recovery_nc = np.array(x_recovery_nc, dtype=np.int16)\n",
    "\n",
    "y_recovery_ca1 = np.array(y_recovery_ca1,)\n",
    "y_recovery_nc = np.array(y_recovery_nc, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d865561",
   "metadata": {},
   "source": [
    "## Get time points of recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_recovery_nc = []\n",
    "i_recovery_ca1 = []\n",
    "\n",
    "recovery_ratio = 0.95  # reach 99% of baseline to be considered recovered\n",
    "\n",
    "def get_recovery_index(recovery_trace):\n",
    "    baseline = recovery_trace[0]  # bl, darkest, windows...\n",
    "    if np.max(recovery_trace[2:]) < recovery_ratio*baseline:\n",
    "        return -1\n",
    "    i_recovery = np.argmax(recovery_trace[2:] >= recovery_ratio*baseline) + 2  # shift back to index in whole trace\n",
    "    return i_recovery\n",
    "\n",
    "for recovery_trace in y_recovery_nc:\n",
    "    i_recovery = get_recovery_index(recovery_trace)\n",
    "    i_recovery_nc.append(i_recovery)\n",
    "    \n",
    "for recovery_trace in y_recovery_ca1:\n",
    "    i_recovery = get_recovery_index(recovery_trace)\n",
    "    i_recovery_ca1.append(i_recovery)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3964c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_points_numeric[i_recovery_nc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd7f260",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6aac7c",
   "metadata": {},
   "source": [
    "## CA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ebf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "amplitude = 100.\n",
    "offset = 0.\n",
    "\n",
    "for event_uuid, mouse_id, i_trace in event_uuid_mouse_id_i_trace_ca1:\n",
    "    c = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "    plt.plot(amplitude*(traces_ca1[i_trace] - min(traces_ca1[i_trace]))/(max(traces_ca1[i_trace] - min(traces_ca1[i_trace])))+offset, color=c )\n",
    "    plt.vlines(x=x_recovery_ca1[i_trace], ymin=offset-0.1*amplitude, ymax=offset+1.1*amplitude)\n",
    "    for window_center in x_recovery_ca1[i_trace]:\n",
    "        plt.hlines(y=offset-5, xmin=window_center-window_width_frames//2, xmax= window_center+window_width_frames//2, color=\"red\")\n",
    "    offset += 1.3*amplitude\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    output_fpath = os.path.join(output_folder, f\"ca1_recovery_overview_{get_datetime_for_fname()}{output_format}\")\n",
    "    plt.savefig(output_fpath)\n",
    "    print(f\"Saved as {output_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f81d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,18))\n",
    "x_ticks = [i for i in range(len(y_recovery_ca1[0]))]\n",
    "offset = 0.0\n",
    "for event_uuid, mouse_id, i_trace in event_uuid_mouse_id_i_trace_ca1:\n",
    "    c = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "    plt.plot(y_recovery_ca1[i_trace] - y_recovery_ca1[i_trace][0] + offset, \"o-\", color=c, markersize=10 )\n",
    "    plt.hlines(y=offset, xmin=0, xmax=len(y_recovery_ca1[i_trace]), color=\"red\")\n",
    "    plt.vlines(ymin=offset-5, ymax=offset+5, x=i_recovery_ca1[i_trace], linewidth=5, color=c)\n",
    "    offset += 10\n",
    "plt.xticks(x_ticks, time_points)\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    output_fpath = os.path.join(output_folder, f\"ca1_recovery_time_points_{get_datetime_for_fname()}{output_format}\")\n",
    "    plt.savefig(output_fpath)\n",
    "    print(f\"Saved as {output_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b0855",
   "metadata": {},
   "source": [
    "## NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "amplitude = 100.\n",
    "offset = 0.\n",
    "\n",
    "for event_uuid, mouse_id, i_trace in event_uuid_mouse_id_i_trace_nc:\n",
    "    c = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "    plt.plot(amplitude*(traces_nc[i_trace] - min(traces_nc[i_trace]))/(max(traces_nc[i_trace] - min(traces_nc[i_trace])))+offset, color=c )\n",
    "    plt.vlines(x=x_recovery_nc[i_trace], ymin=offset-0.1*amplitude, ymax=offset+1.1*amplitude)\n",
    "    for window_center in x_recovery_nc[i_trace]:\n",
    "        plt.hlines(y=offset-5, xmin=window_center-window_width_frames//2, xmax= window_center+window_width_frames//2, color=\"red\")\n",
    "    offset += 1.3*amplitude\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    output_fpath = os.path.join(output_folder, f\"nc_recovery_overview_{get_datetime_for_fname()}{output_format}\")\n",
    "    plt.savefig(output_fpath)\n",
    "    print(f\"Saved as {output_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02483dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "offset = 0.0\n",
    "for event_uuid, mouse_id, i_trace in event_uuid_mouse_id_i_trace_nc:\n",
    "    c = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "    plt.plot(y_recovery_nc[i_trace] - y_recovery_nc[i_trace][0] + offset, \"o-\", color=c, markersize=10 )\n",
    "    plt.hlines(y=offset, xmin=0, xmax=len(y_recovery_nc[i_trace]), color=\"red\")\n",
    "    plt.vlines(ymin=offset-5, ymax=offset+5, x=i_recovery_nc[i_trace], linewidth=5, color=c)\n",
    "    offset += 10\n",
    "plt.xticks(x_ticks, time_points)\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    output_fpath = os.path.join(output_folder, f\"nc_recovery_time_points_{get_datetime_for_fname()}{output_format}\")\n",
    "    plt.savefig(output_fpath)\n",
    "    print(f\"Saved as {output_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc890f0",
   "metadata": {},
   "source": [
    "### Baseline - darkest difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_minus_darkest_ca1 = y_recovery_ca1[:,0] - y_recovery_ca1[:,1]\n",
    "bl_minus_darkest_nc = y_recovery_nc[:,0] - y_recovery_nc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be342a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bl_minus_darkest_ca1 = pd.DataFrame(data=bl_minus_darkest_ca1, columns=[\"bl-darkest\"])\n",
    "df_bl_minus_darkest_ca1[\"window_type\"] = \"ca1\"\n",
    "\n",
    "df_bl_minus_darkest_nc = pd.DataFrame(data=bl_minus_darkest_nc, columns=[\"bl-darkest\"])\n",
    "df_bl_minus_darkest_nc[\"window_type\"] = \"nc\"\n",
    "\n",
    "df_bl_minus_darkest_combined = pd.concat([df_bl_minus_darkest_ca1, df_bl_minus_darkest_nc]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa50745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(1,2,figsize=(8,6), sharey=True)\n",
    "left= sns.barplot(data=df_bl_minus_darkest_combined, x=\"window_type\", y=\"bl-darkest\", ax=axs[0])\n",
    "right = sns.stripplot(data=df_bl_minus_darkest_combined, x=\"window_type\", y=\"bl-darkest\", hue=\"window_type\", legend=False, s=15, ax=axs[1])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7111ac",
   "metadata": {},
   "source": [
    "## Create dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93054669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add np.nan for not found onset values\n",
    "time_points_numeric_extended = np.concatenate([time_points_numeric, np.array([np.nan])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5352fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids_nc = [\"\" for i in range(len(i_recovery_nc))]\n",
    "event_uuids_nc = [\"\" for i in range(len(i_recovery_nc))]\n",
    "for event_uuid, mouse_id, i_trace in event_uuid_mouse_id_i_trace_nc:\n",
    "    mouse_ids_nc[i_trace] = mouse_id\n",
    "    event_uuids_nc[i_trace] = event_uuid\n",
    "df_recovery_nc = pd.DataFrame(columns=[\"i_recovery\"],data=i_recovery_nc)\n",
    "df_recovery_nc[\"t_recovery\"] = time_points_numeric_extended[i_recovery_nc]\n",
    "df_recovery_nc[\"event_uuid\"] =  event_uuids_nc\n",
    "df_recovery_nc[\"mouse_id\"] = mouse_ids_nc\n",
    "df_recovery_nc[\"window_type\"] = \"nc\"\n",
    "#df_recovery_nc = df_recovery_nc.sort_values(by=\"mouse_id\").reset_index().drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b6062",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_ids_ca1 = [\"\" for i in range(len(i_recovery_ca1))]\n",
    "event_uuids_ca1 = [\"\" for i in range(len(i_recovery_ca1))]\n",
    "for event_uuid, mouse_id, i_trace in event_uuid_mouse_id_i_trace_ca1:\n",
    "    mouse_ids_ca1[i_trace] = mouse_id\n",
    "    event_uuids_ca1[i_trace] = event_uuid\n",
    "df_recovery_ca1 = pd.DataFrame(columns=[\"i_recovery\"],data=i_recovery_ca1)\n",
    "df_recovery_ca1[\"t_recovery\"] = time_points_numeric_extended[i_recovery_ca1]\n",
    "df_recovery_ca1[\"event_uuid\"] =  event_uuids_ca1\n",
    "df_recovery_ca1[\"mouse_id\"] = mouse_ids_ca1\n",
    "df_recovery_ca1[\"window_type\"] = \"ca1\"\n",
    "#df_recovery_ca1 = df_recovery_nc.sort_values(by=\"mouse_id\").reset_index().drop(columns=[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec849de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovery_combined = pd.concat([df_recovery_ca1, df_recovery_nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408fe54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8,6), sharey=True)\n",
    "left = sns.barplot(x=\"window_type\", y=\"t_recovery\", data=df_recovery_combined, ax= axs[0])\n",
    "right = sns.stripplot(x=\"window_type\", y=\"t_recovery\", hue=\"window_type\", data=df_recovery_combined.dropna(), ax=axs[1], s=15, legend=False)\n",
    "left.set(ylim=(0, 200))\n",
    "#right.set(ylim=(0, 200))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f715db",
   "metadata": {},
   "source": [
    "## Export datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ab680",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_dsets:\n",
    "    fpath_df_recovery_nc = os.path.join(output_folder, f\"bl_recovery_nc_{get_datetime_for_fname()}.xlsx\")\n",
    "    fpath_df_recovery_ca1 = os.path.join(output_folder, f\"bl_recovery_ca1_{get_datetime_for_fname()}.xlsx\")\n",
    "    df_recovery_nc.to_excel(fpath_df_recovery_nc, index=False)\n",
    "    print(f\"Saved NC data to {fpath_df_recovery_nc}\")\n",
    "    df_recovery_ca1.to_excel(fpath_df_recovery_ca1, index=False)\n",
    "    print(f\"Saved NC data to {fpath_df_recovery_ca1}\")\n",
    "    \n",
    "    fpath_recovery_bl_minus_darkest_slope = os.path.join(output_folder, f\"bl_recovery_bl-minus-darkest_slope-darkest-2min_{get_datetime_for_fname()}.xlsx\")\n",
    "    df_recovery_combined[[\"mouse_id\", \"window_type\", \"bl-darkest\", \"slope_darkest_to_2min\"]].to_excel(fpath_recovery_bl_minus_darkest_slope, index=False)\n",
    "    print(f\"Saved recovery baseline - darkest and slope darkest to 2min post to {fpath_recovery_bl_minus_darkest_slope}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0edffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recovery_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802f319",
   "metadata": {},
   "source": [
    "## Compare bl-darkest in CA1 vs NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0438a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,10))\n",
    "ax = plt.gca()\n",
    "sns.stripplot(data=df_recovery_combined, x=\"window_type\", y=\"bl-darkest\", hue=\"window_type\", s=20,  ax=ax, legend=None)\n",
    "sns.barplot(data=df_recovery_combined, x=\"window_type\", y=\"bl-darkest\", ax=ax, alpha=0.5)\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    savefig_fpath = os.path.join(output_folder, f\"recovery_bl-minus-darkest_{get_datetime_for_fname()}{output_format}\")\n",
    "    plt.savefig(savefig_fpath)\n",
    "    print(f\"Saved as {savefig_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,10))\n",
    "ax = plt.gca()\n",
    "sns.violinplot(data=df_recovery_combined, x=\"window_type\", y=\"bl-darkest\", ax=ax, inner=\"quart\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0df145",
   "metadata": {},
   "source": [
    "### Test significance of difference\n",
    "t-test assumes normal distribution, which probably is not the case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ab7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(df_recovery_combined[df_recovery_combined[\"window_type\"] == \"ca1\"][\"bl-darkest\"], df_recovery_combined[df_recovery_combined[\"window_type\"] == \"nc\"][\"bl-darkest\"], equal_var=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd330da",
   "metadata": {},
   "source": [
    "## Compare recovery rates CA1 vs NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,10))\n",
    "ax = plt.gca()\n",
    "sns.barplot(data=df_recovery_combined.dropna(), x=\"window_type\", y=\"slope_darkest_to_2min\", errorbar=\"sd\",ax=ax, alpha=0.5)\n",
    "sns.stripplot(data=df_recovery_combined.dropna(), x=\"window_type\", y=\"slope_darkest_to_2min\", hue=\"window_type\", s=20, legend=None)\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    savefig_fpath = os.path.join(output_folder, f\"recovery_slope_darkest-to-2minpost_{get_datetime_for_fname()}{output_format}\")\n",
    "    plt.savefig(savefig_fpath)\n",
    "    print(f\"Saved as {savefig_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b646859",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,10))\n",
    "\n",
    "sns.violinplot(data=df_recovery_combined.dropna(), x=\"window_type\", y=\"slope_darkest_to_2min\", inner=\"quart\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71571c21",
   "metadata": {},
   "source": [
    "# Simple amplitude comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate baseline value as follows: take n_bl_window_frames frames before Sz; get 5% lowest values, take mean of these.\n",
    "n_bl_window_frames = 30*15  # 30 s (*15 Hz) frames to look at to get baseline fluorescence\n",
    "lowest_percent_bl_window = 0.05  # lowest 5%\n",
    "amplitudes_ca1 = []\n",
    "for i in range(len(traces_ca1)):\n",
    "    bl_val_ca1 = np.sort(traces_ca1[i][n_bl_frames-n_bl_window_frames+1:n_bl_frames])[:int(lowest_percent_bl_window*n_bl_window_frames)].mean()  # take mean of lowest 5% of baseline values\n",
    "    len_sz = len(traces_ca1[i]) -  n_am_frames - n_bl_frames\n",
    "    sz_amp_val_ca1 = np.flip(np.sort(traces_ca1[i][n_bl_frames:n_bl_frames+len_sz+1]))[:int(0.05*len_sz)].mean()  # take mean of highest 5% of sz values\n",
    "    sd_amp_val_ca1 = np.flip(np.sort(traces_ca1[i][n_bl_frames+len_sz+1:]))[:int(0.05*n_am_frames)].mean()\n",
    "    amplitudes_ca1.append([bl_val_ca1, sz_amp_val_ca1, sd_amp_val_ca1])\n",
    "amplitudes_ca1 = np.array(amplitudes_ca1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adebc3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_nc = []\n",
    "for i in range(len(traces_nc)):\n",
    "    bl_val_nc = np.sort(traces_nc[i][:n_bl_frames])[:int(0.5*n_bl_frames)].mean()  # take mean of lowest 5% of baseline values\n",
    "    len_sz = len(traces_nc[i]) -  n_am_frames - n_bl_frames\n",
    "    sz_amp_val_nc = np.flip(np.sort(traces_nc[i][n_bl_frames:n_bl_frames+len_sz+1]))[:int(0.05*len_sz)].mean()  # take mean of highest 5% of sz values\n",
    "    amplitudes_nc.append([bl_val_nc, sz_amp_val_nc])\n",
    "amplitudes_nc = np.array(amplitudes_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,12))\n",
    "for i_sz in range(len(amplitudes_ca1)):\n",
    "    plt.plot(amplitudes_ca1[i_sz], color=colors_ca1[i_sz])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f736e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check SD category was recognized properly\n",
    "fig = plt.figure()\n",
    "for i in range(len(traces_ca1)):\n",
    "    len_sz = len(traces_ca1[i]) -  n_am_frames - n_bl_frames\n",
    "    plt.plot(traces_ca1[i][n_bl_frames+len_sz+1:], color=colors_ca1[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2c84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_ratios_ca1 = []  # [i][0] is sz:bl ratio, [i][1] is sd:sz\n",
    "for i, amplitudes in enumerate(amplitudes_ca1):\n",
    "    ratio_sz_bl = amplitudes[1]/amplitudes[0]\n",
    "    ratio_sd_sz = amplitudes[2]/amplitudes[1]\n",
    "    amplitude_ratios_ca1.append((mouse_ids_ca1[i], uuids_ca1[i], \"CA1\", ratio_sz_bl, ratio_sd_sz))\n",
    "df_ratios_ca1 = pd.DataFrame(data=amplitude_ratios_ca1, columns=[\"mouse_id\", \"sz_uuid\", \"win_type\", \"sz:bl\", \"sd:sz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bd658",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude_ratios_nc = []  # [i][0] is sz:bl ratio, [i][1] is sd:sz\n",
    "for i, amplitudes in enumerate(amplitudes_nc):\n",
    "    ratio_sz_bl = amplitudes[1]/amplitudes[0]\n",
    "    amplitude_ratios_nc.append((mouse_ids_nc[i], uuids_nc[i], \"NC\", ratio_sz_bl))\n",
    "df_ratios_nc = pd.DataFrame(data=amplitude_ratios_nc, columns=[\"mouse_id\", \"sz_uuid\", \"win_type\", \"sz:bl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d343cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios = pd.concat([df_ratios_ca1, df_ratios_nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b30e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_long = pd.melt(df_ratios, id_vars=[\"sz_uuid\", \"mouse_id\", \"win_type\"], value_vars=[\"sz:bl\", \"sd:sz\"], var_name = [\"ratio_type\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790b99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios_long[df_ratios_long[\"ratio_type\"] == \"sz:bl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de54cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,14))\n",
    "for i_sz in range(len(amplitudes_ca1)):\n",
    "    plt.plot(amplitudes_ca1[i_sz], \"o-\", color=colors_ca1[i_sz], )\n",
    "for i_sz_nc in range(len(amplitudes_nc)):\n",
    "    plt.plot(amplitudes_nc[i_sz_nc], \"o-\", color=colors_nc[i_sz_nc])\n",
    "plt.ylabel(\"fluorescence (a.u.)\")\n",
    "    \n",
    "plt.vlines([0,1,2], 0, 500)\n",
    "    \n",
    "plt.text(0.05, 450, \"BL\", fontdict=None)\n",
    "plt.text(1.05, 450, \"Sz\", fontdict=None)\n",
    "plt.text(1.8, 450, \"SD\", fontdict=None)\n",
    "\n",
    "frame1 = plt.gca()\n",
    "frame1.axes.xaxis.set_ticklabels([])\n",
    "frame1.axes.xaxis.grid(False)\n",
    "#frame1.axes.yaxis.set_ticklabels([])\n",
    "if save_figs:\n",
    "    output_fpath = os.path.join(output_folder, f\"amplitudes_{get_datetime_for_fname()}{output_format}\")\n",
    "    plt.savefig(output_fpath)\n",
    "    print(f\"Saved as {output_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501abb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_ca1_to_bl = amplitudes_ca1[:,1:] - amplitudes_ca1[:,0, None]\n",
    "amplitudes_nc_to_bl = amplitudes_nc[:,1:] - amplitudes_nc[:,0, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35029b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,10))\n",
    "for i_sz in range(len(amplitudes_ca1_to_bl)):\n",
    "    plt.plot(amplitudes_ca1_to_bl[i_sz], \"o-\", color=colors_ca1[i_sz], )\n",
    "#for i_sz_nc in range(len(amplitudes_nc_to_bl)):\n",
    "#    plt.plot(amplitudes_nc_to_bl[i_sz_nc], \"o-\", color=colors_nc[i_sz_nc])\n",
    "plt.ylabel(\"fluorescence (a.u.)\")\n",
    "    \n",
    "plt.vlines([0,1], 0, 500)\n",
    "    \n",
    "plt.text(0.05, 450, \"Sz-bl\", fontdict=None)\n",
    "plt.text(0.68, 450, \"SD-bl\", fontdict=None)\n",
    "\n",
    "frame1 = plt.gca()\n",
    "frame1.axes.xaxis.set_ticklabels([])\n",
    "frame1.axes.xaxis.grid(False)\n",
    "#frame1.axes.yaxis.set_ticklabels([])\n",
    "if save_figs:\n",
    "    output_fpath = os.path.join(output_folder, f\"amplitudes_to_bl_{get_datetime_for_fname()}{output_format}\")\n",
    "    plt.savefig(output_fpath)\n",
    "    print(f\"Saved as {output_fpath}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cfb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_result = ttest_rel(amplitudes_ca1_to_bl.T[1][:-1], amplitudes_ca1_to_bl.T[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a64b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amplitudes_ca1 = pd.DataFrame(columns=[\"Sz-bl\", \"SD-bl\"], data=amplitudes_ca1_to_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_xlsx = False\n",
    "if save_to_xlsx:\n",
    "    amplitudes_export_fpath_ca1 = f\"D:\\\\Downloads\\\\amplitudes_to_bl_ca1_{get_datetime_for_fname()}.xlsx\"\n",
    "    df_amplitudes_ca1.to_excel(amplitudes_export_fpath_ca1, index=False)\n",
    "    print(f\"Saved file to {amplitudes_export_fpath_ca1}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1e0a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

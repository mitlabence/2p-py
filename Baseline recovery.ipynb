{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f3982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labrotation.file_handling as fh\n",
    "import h5py\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps\n",
    "import seaborn as sns\n",
    "import uuid  # for unique labeling of sessions and coupling arrays (mouse velocity, distance, ...) to sessions in dataframe \n",
    "from matplotlib import cm  # colormap\n",
    "import datadoc_util\n",
    "from labrotation import two_photon_session as tps\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47211f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d4abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    docu_folder = fh.open_dir(\"Choose folder containing folders for each mouse!\")\n",
    "print(f\"Selected folder:\\n\\t{docu_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25389df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"documentation\" in os.listdir(docu_folder):\n",
    "    mouse_folder = os.path.join(docu_folder, \"documentation\")\n",
    "else:\n",
    "    mouse_folder = docu_folder\n",
    "mouse_names = os.listdir(mouse_folder)\n",
    "print(f\"Mice detected:\")\n",
    "for mouse in mouse_names:\n",
    "    print(f\"\\t{mouse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = datetime.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb446ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = env_dict[\"DOWNLOADS_FOLDER\"]\n",
    "print(f\"Output files will be saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24259d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = datadoc_util.DataDocumentation(docu_folder)\n",
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cba8cd",
   "metadata": {},
   "source": [
    "## Load all seizures dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd358659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = ddoc.getEventsDf()\n",
    "df_events = df_events[df_events[\"event_type\"] == \"sz\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2dee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_traces_fpath = fh.open_file(\"Open .h5 file containing assembled traces for all seizures!\")\n",
    "print(event_traces_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d391371",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_ca1 = []\n",
    "traces_nc = []\n",
    "\n",
    "uuids_ca1 = []\n",
    "uuids_nc = []\n",
    "\n",
    "session_uuids_ca1 = []\n",
    "session_uuids_nc = []\n",
    "\n",
    "recording_break_points_ca1 = []\n",
    "recording_break_points_nc = []\n",
    "\n",
    "n_bl_frames = 5000\n",
    "n_am_frames = 5000\n",
    "\n",
    "# first keys are event uuids, inside the following dataset names:\n",
    "# 'lfp_mov_t', 'lfp_mov_y', 'lfp_t', 'lfp_y', 'lv_dist', 'lv_rounds', \n",
    "# 'lv_running', 'lv_speed', 'lv_t_s', 'lv_totdist', 'mean_fluo'\n",
    "with h5py.File(event_traces_fpath, \"r\") as hf:\n",
    "    for uuid in hf.keys():\n",
    "        win_type = hf[uuid].attrs[\"window_type\"]\n",
    "        mean_fluo = np.array(hf[uuid][\"mean_fluo\"])\n",
    "        assert n_bl_frames == hf[uuid].attrs[\"n_bl_frames\"]\n",
    "        assert n_am_frames == hf[uuid].attrs[\"n_am_frames\"]\n",
    "        if win_type == \"Cx\":\n",
    "            traces_nc.append(mean_fluo)\n",
    "            uuids_nc.append(uuid)\n",
    "            session_uuids_nc.append(hf[uuid].attrs[\"session_uuids\"])\n",
    "            recording_break_points_nc.append(hf[uuid].attrs[\"recording_break_points\"])\n",
    "        elif win_type == \"CA1\":\n",
    "            traces_ca1.append(mean_fluo)\n",
    "            uuids_ca1.append(uuid)\n",
    "            session_uuids_ca1.append(hf[uuid].attrs[\"session_uuids\"])\n",
    "            recording_break_points_ca1.append(hf[uuid].attrs[\"recording_break_points\"])\n",
    "        else:\n",
    "            print(f\"{win_type} not recognized window type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ed964b",
   "metadata": {},
   "source": [
    "## Get baseline values\n",
    "Calculated as lowest 5% of data points in baseline segment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fbe04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_percent = 0.05  # 5% of baseline to be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: these take lowest values of the whole traces!\n",
    "#baselines_ca1 = [np.sort(traces_ca1[i][:floor(lowest_percent*n_bl_frames)]) for i in range(len(traces_ca1))]\n",
    "#baselines_nc = [np.sort(traces_nc[i][:floor(lowest_percent*n_bl_frames)]) for i in range(len(traces_nc))]\n",
    "\n",
    "baselines_ca1 = [np.min(traces_ca1[i][:n_bl_frames]) for i in range(len(traces_ca1))]\n",
    "baselines_nc = [np.min(traces_nc[i][:n_bl_frames]) for i in range(len(traces_nc))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfc2e3d",
   "metadata": {},
   "source": [
    "## Get aftermath values\n",
    "in 20 sec windows, get minimum value of fluorescence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f2b480",
   "metadata": {},
   "source": [
    "### Calculate first normal frames\n",
    "Use data documentation for corresponding recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ca1: need to find first segment after the \"sd_extinction\" segment, and find the corresponding index in the (5000 + sz + 5000) traces\n",
    "first_frames_ca1 = []\n",
    "rec_uuids_ca1 = []\n",
    "for i_event in range(len(traces_ca1)):\n",
    "    event_uuid = uuids_ca1[i_event]\n",
    "    # get all segments belonging to aftermath\n",
    "    df_event = df_events[(df_events[\"event_uuid\"] == event_uuid) & (df_events[\"interval_type\"] == \"am\")]\n",
    "    # for all recordings contributing to aftermath, look which one contains sd_extinction\n",
    "    i_frame = len(traces_ca1[i_event]) - n_am_frames  # points to first am frame right now\n",
    "    next_segment_stop = False  # flag to stop on reaching next segment\n",
    "    found_frame = False  # flag to mark if first frame to take was found\n",
    "    am_rec_uuid = None\n",
    "    for i_row, am_row in df_event.iterrows():  # loop over recordings participating in aftermath trace\n",
    "        # begin and end frames of am in current recording\n",
    "        am_begin_frame = am_row[\"begin_frame\"]\n",
    "        am_end_frame = am_row[\"end_frame\"]\n",
    "        # uuid of current recording\n",
    "        rec_uuid = am_row[\"recording_uuid\"]\n",
    "        # get all segments after start of am\n",
    "        i_first_am = ddoc.getSegmentForFrame(rec_uuid, am_begin_frame).index[0]\n",
    "        i_last_am = ddoc.getSegmentForFrame(rec_uuid, am_end_frame).index[0]\n",
    "        am_segments = ddoc.getSegmentsForUUID(rec_uuid).loc[i_first_am:i_last_am+1]\n",
    "        am_rec_uuid = rec_uuid\n",
    "        for i_segment_row, segment_row in am_segments.iterrows():\n",
    "            if next_segment_stop:  # first segment after sd_extinction reached. Take this as start for baseline return observation\n",
    "                break\n",
    "            if segment_row[\"interval_type\"] == \"sd_extinction\":\n",
    "                next_segment_stop = True\n",
    "            segment_length = segment_row[\"frame_end\"] - segment_row[\"frame_begin\"] + 1  # both inclusive -> need +1\n",
    "            i_frame += segment_length\n",
    "        if found_frame:\n",
    "            break\n",
    "    first_frames_ca1.append(i_frame)\n",
    "    rec_uuids_ca1.append(am_rec_uuid)\n",
    "\n",
    "# nc: there is no SD, so just take first am frame as it is\n",
    "first_frames_nc = [len(traces_nc[i]) - n_am_frames for i in range(len(traces_nc))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_length_seconds = 10\n",
    "interval_length = 15*interval_length_seconds  # 15 Hz * 20 seconds\n",
    "n_intervals = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8546f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "aftermath_ca1 = [ np.array([np.min( traces_ca1[i][ first_frames_ca1[i] + j*interval_length : first_frames_ca1[i] + (j+1)*interval_length  ] )  for j in range(n_intervals)]) for i in range(len(traces_ca1)) ] \n",
    "aftermath_nc = [ np.array([np.min( traces_nc[i][ first_frames_nc[i] + j*interval_length : first_frames_nc[i] + (j+1)*interval_length  ] )  for j in range(n_intervals)]) for i in range(len(traces_nc)) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fae122",
   "metadata": {},
   "source": [
    "## Create dataframe\n",
    "Columns should be: uuid, value (numeric), value_type (bl, 20s, 40s, ... 200 s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_names = [\"baseline_mean\", \"baseline_std\"] + [f\"{20*i}s\" for i in range(1, n_intervals+1)]\n",
    "data_dict = {\"uuid\": [], \"value\": [], \"value_type\": []}\n",
    "\n",
    "# get baseline values for CA1 and NC\n",
    "\n",
    "for i_event_ca1 in range(len(baselines_ca1)):\n",
    "    uuids = [uuids_ca1[i_event_ca1]]  # only one baseline value per event\n",
    "    value_types = [\"bl\"]\n",
    "    data_dict[\"uuid\"] += uuids\n",
    "    data_dict[\"value\"] += [baselines_ca1[i_event_ca1]]\n",
    "    data_dict[\"value_type\"] += value_types\n",
    "\n",
    "for i_event_nc in range(len(baselines_nc)):\n",
    "    uuids = [uuids_nc[i_event_nc]] # only one baseline value per event\n",
    "    value_types = [\"bl\"]\n",
    "    data_dict[\"uuid\"] += uuids\n",
    "    data_dict[\"value\"] += [baselines_nc[i_event_nc]]\n",
    "    data_dict[\"value_type\"] += value_types        \n",
    "\n",
    "# get 20, 40, ..., 200 s values for CA1 and NC\n",
    "\n",
    "for i_event_ca1 in range(len(aftermath_ca1)):\n",
    "    uuids = [uuids_ca1[i_event_ca1]]*len(aftermath_ca1[i_event_ca1])\n",
    "    value_types = [f\"{(i+1)*interval_length_seconds}s\" for i in range(n_intervals)]\n",
    "    assert len(uuids) == len(value_types)\n",
    "    assert len(uuids) == len(aftermath_ca1[i_event_ca1])\n",
    "    data_dict[\"uuid\"] += uuids\n",
    "    data_dict[\"value\"] += list(aftermath_ca1[i_event_ca1])\n",
    "    data_dict[\"value_type\"] += value_types\n",
    "\n",
    "for i_event_nc in range(len(aftermath_nc)):\n",
    "    uuids = [uuids_nc[i_event_nc]]*len(aftermath_nc[i_event_nc])\n",
    "    value_types = [f\"{(i+1)*interval_length_seconds}s\" for i in range(n_intervals)]\n",
    "    assert len(uuids) == len(value_types)\n",
    "    assert len(uuids) == len(aftermath_nc[i_event_nc])\n",
    "    data_dict[\"uuid\"] += uuids\n",
    "    data_dict[\"value\"] += list(aftermath_nc[i_event_nc])\n",
    "    data_dict[\"value_type\"] += value_types   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "sns.lineplot(data=df, palette=\"tab10\", x=\"value_type\", y=\"value\", hue=\"uuid\", linewidth=2.5, legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26b3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bl_traces = []\n",
    "all_am_traces = []\n",
    "for i_tr in range(len(traces_ca1)):\n",
    "    all_am_traces.append(traces_ca1[i_tr][first_frames_ca1[i_tr]:])\n",
    "    all_bl_traces.append(traces_ca1[i_tr][n_bl_frames - 1000 :n_bl_frames])\n",
    "for i_tr in range(len(traces_nc)):\n",
    "    all_am_traces.append( traces_nc[i_tr][first_frames_nc[i_tr]:])\n",
    "    all_bl_traces.append(traces_nc[i_tr][n_bl_frames - 1000 :n_bl_frames])\n",
    "    \n",
    "bl_x = np.array([i-len(all_bl_traces[0])+1 for i in range(len(all_bl_traces[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,18))\n",
    "for tr in all_bl_traces:\n",
    "    plt.plot(bl_x, tr)\n",
    "for tr in all_am_traces:\n",
    "    plt.plot(tr)\n",
    "plt.ylim((0, 60))\n",
    "#plt.xlim((-10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f736e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: lowess filter? Somehow filter this signal!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

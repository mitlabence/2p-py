{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ea0b7d",
   "metadata": {},
   "source": [
    "# Pure Python Pipeline\n",
    "Ripple noise removal, motion correction, trace deconvoloution and extraction in one notebook. This should replace demo_pipeline as the standard analysis notebook! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa2fc9",
   "metadata": {},
   "source": [
    "## TODO list (from demo_pipeline)\n",
    "- TODO: test string attributes in moco_pars.h5 file. Are they complete (check dimensions of arrays like coord_shifts_els.\n",
    "- TODO: clean up memmap and temporary files after opened in caim (F-order mmap stays until end). Need good naming here! Create ok/cancel dialog to confirm if delete temporary files\n",
    "- TODO: first, MoCO result is exported to C-order mmap (motion_correct() save_file=True), then F-order, this latter one is opened in CaImAn. Do we need both?\n",
    "- TODO: rnr save file: should have rnr in the hdf5 file name, otherwise too confusing!\n",
    "- TODO: create a small txt file with the file names and their purpose (whether they can be deleted, how to use them, what do they contain) at some point (early) in the analysis, save it in export folder.\n",
    "- FIXME: _pars.json and _results.hdf5 contain nd2 file name twice: T301_tmev_d1T301_tmev_d1.270820.1110_22-10-20_14-18-40_pars.json and T301_tmev_d1T301_tmev_d1.270820.1110_22-10-20_14-18-40_results.hdf5\n",
    "- IMPORTANT: make it more convenient to enter pipeline from any point. This includes defining parameters in one location, naming variables appropriately (F memmap, C memmap, nd2 file, hd5 file...) so user is aware which file they are supposed to open at which point of entry into analysis!\n",
    "- memmap_ results in conflicting names if recordings are from same day. Include date time of analysis in name? Not a big problem as it is temporary file\n",
    "- Study parallel processing of caiman (start server step, cleaning up server). It might be useful for RNR too.\n",
    "- Evaluating components: cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview), the contents of model/ in CaImAn are used but looking for the model files in another directory (in my case, Users/Bence/caiman_data/model/)\n",
    "- Export h5 file should have date time in filename to avoid overwriting. Both raw data and final results!\n",
    "- Plot with slider: watch all the frames, compare RNR and original, then MC and original/RNR... QC\n",
    "- Save RNR directly to memmap (opening as caiman movie, save to memmap?)? Although the problem is how slow RNR is...\n",
    "- Maybe working with numpy array in motion correction (movie.motion_correct) is not that bad? Although no parameters...\n",
    "- Plot frame before RNR and after RNR to set parameters... Interactive?\n",
    "- Read Tips on analysis: https://caiman.readthedocs.io/en/master/CaImAn_Tips.html#motion-correction-tips\n",
    "- RNR results in 4x size (uint16 to float64)! Need to clean up or use uint16 again.\n",
    "- Check 2-channel recordings. Might want to save red channel, too, for matching?\n",
    "- Save memmap files is inconsistent in naming (C order is memmap__d1_512_d2_512_d3_1_order_C_frames_577_ instead of T386_20211202_green_ex_els__d1_512_d2_512_d3_1_order_C_frames_577_)\n",
    "- Include nd2 to h5 here (from nd2 to multipage tiff test.ipynb)\n",
    "- It takes a lot of time to open nd2 file. Useful to copy data to be analyzed to local HDD on a previous day?\n",
    "- way to manually reject/accept components\n",
    "- IMPORTANT: https://caiman.readthedocs.io/en/master/On_file_types_and_sizes.html caiman works best when files are 1-2 GB big! It means we might want to split them in small pieces, or make sure they are multi-page tiff files!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd663b68",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df788f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from RippleNoiseRemoval import RNR\n",
    "import h5py\n",
    "from time import time\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "import cv2\n",
    "import glob\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "\n",
    "from movie_splitting import numpy_to_hdf5\n",
    "\n",
    "import json  # for exporting parameters\n",
    "\n",
    "# for exporting moco data:\n",
    "from caiman.motion_correction import sliding_window\n",
    "import cv2\n",
    "\n",
    "import pandas as pd  # for opening data documentation\n",
    "import warnings\n",
    "import uuid  # for generating UUID in case of missing value\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b987cf5",
   "metadata": {},
   "source": [
    "# If exists, load environmental variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe78365",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ff1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fname = fh.get_filename_with_date(\"caim_log\", \".txt\")\n",
    "if \"LOG_FOLDER\" in env_dict.keys():\n",
    "    log_fname = os.path.join(env_dict[\"LOG_FOLDER\"], log_fname)\n",
    "else:\n",
    "    log_fname = fh.choose_dir_for_saving_file(\"Select folder to save log file\", log_fname)\n",
    "print(f\"Saving log file to\\n{log_fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87dc936",
   "metadata": {},
   "source": [
    "## Set up logging (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1836eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\\\n",
    "                    filename=log_fname,\n",
    "                    level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add761f",
   "metadata": {},
   "source": [
    "## Set input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee969c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nd2 input file\n",
    "nd2_fpath = fh.open_file(\"Select nd2 file\")\n",
    "\n",
    "# set folder to export temporary and result files\n",
    "export_folder = fh.open_dir(\"Select folder to save results\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31384685",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_fname = os.path.split(nd2_fpath)[-1]\n",
    "# export_fname: get rid of .nd2 extension, append date and .h5 extension\n",
    "#export_fname = fh.get_filename_with_date(os.path.splitext(os.path.split(nd2_fpath)[1])[0] + \"_caim\", \".h5\")\n",
    "#export_hd5_fpath = os.path.join(export_folder, export_fname)\n",
    "#print(f\"Export file selected: {export_hd5_fpath}\")\n",
    "\n",
    "results_root = fh.get_filename_with_date(os.path.splitext(os.path.split(nd2_fpath)[1])[0], \"\")\n",
    "\n",
    "rnr_fname = results_root + \"_rnr.hdf5\"\n",
    "rnr_fpath = os.path.join(export_folder, rnr_fname)\n",
    "\n",
    "# input for motion correction; moco comes after RNR\n",
    "moco_fnames = [rnr_fpath]\n",
    "\n",
    "# rnr_fpath should be hdf5 for now. Not sure if MoCo/CaImAn supports h5.\n",
    "assert rnr_fpath.split(\".\")[-1] in [\"h5\", \"hdf5\"], f\"Invalid file extension: .{rnr_fpath.split('.')[-1]}, expected .h5\"\n",
    "\n",
    "cnmf_results_save_path = os.path.join(export_folder, results_root + \"_cnmf.hdf5\")  # caiman only supports saving hdf5, not h5\n",
    "\n",
    "json_fname = results_root + \"_pars.json\"\n",
    "json_fpath = os.path.join(export_folder, json_fname)\n",
    "\n",
    "moco_pars_fname = results_root + \"_moco_pars.h5\"\n",
    "moco_pars_fpath = os.path.join(export_folder, moco_pars_fname)\n",
    "\n",
    "denoised_optional_fpath = os.path.join(export_folder, results_root + \"_denoised.tif\") \n",
    "\n",
    "\n",
    "print(f\"Input file selected:\\n\\t{nd2_fpath}\")\n",
    "\n",
    "print(f\"Temporary file after RNR will be saved as\\n\\t{rnr_fpath}\")\n",
    "print(f\"Going to perform MoCo on\\n\\t{moco_fnames}\")\n",
    "print(f\"Results of trace extraction will be saved as\\n\\t{cnmf_results_save_path}\")\n",
    "print(f\"Parameters will be saved as\\n\\t{json_fpath}\")\n",
    "print(f\"MoCo parameters will be saved as\\n\\t{moco_pars_fpath}\")\n",
    "print(f\"\\nOptional denoised results will be saved as\\n\\t{denoised_optional_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12922fa2",
   "metadata": {},
   "source": [
    "# Add UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"DATA_DOCU_FOLDER\" in env_dict:  # try default location\n",
    "    data_docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    data_docu_folder = fh.open_dir(\"Open Data Documentation folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7890d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docu_files_list = []\n",
    "session_uuid = None\n",
    "for root, dirs, files in os.walk(data_docu_folder):\n",
    "    for name in files:\n",
    "        if \"grouping\" in name:\n",
    "            if \"~\" in name: # \"~\" on windows is used for temporary files that are opened in excel\n",
    "                docu_files_list = []\n",
    "                raise Exception(f\"Please close all excel files and try again. Found temporary file in:\\n{os.path.join(root, name)}\")\n",
    "            fpath = os.path.join(root, name)\n",
    "            df = pd.read_excel(fpath)\n",
    "            df = df[df[\"nd2\"] == nd2_fname]\n",
    "            if len(df) > 0:\n",
    "                if len(df) > 1:\n",
    "                    raise Exception(f\"File name appears several times in data documentation:\\n\\t{nd2_fname}\\n{df}\")\n",
    "                else:\n",
    "                    session_uuid = df[\"uuid\"].iloc[0]\n",
    "                break\n",
    "            docu_files_list.append(fpath)\n",
    "if session_uuid is None:\n",
    "    session_uuid = uuid.uuid4().hex \n",
    "    warnings.warn(f\"Warning: movie does not have entry (uuid) in data documentation!\\nYou should add data to documentation. The generated uuid for this session is: {session_uuid}\", UserWarning)\n",
    "print(f\"UUID is {session_uuid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9af84",
   "metadata": {},
   "source": [
    "## Ripple Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c992111",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = 40\n",
    "amplitude_threshold = 10.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13631d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnr = RNR(win, amplitude_threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf57982",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_open = time()\n",
    "rnr.open_recording(nd2_fpath)  # opens usual recording size (8.8-9 GB) in about 830 s\n",
    "print(f\"File opened in {time() - t0_open} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d186c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_single = time()\n",
    "rnr_data = rnr.rnr_singlethread()  # a bit faster than opening file, around 500s for 8.8-9 GB\n",
    "t1_single = time()\n",
    "print(f\"RNR single thread finished in {t1_single - t0_single} s\")\n",
    "print(f\"Result is a {type(rnr_data)} with datatype {rnr_data.dtype}\")\n",
    "print(f\"Shape: {rnr_data.shape[0]} frames of {rnr_data.shape[1]}x{rnr_data.shape[2]} pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb83ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rnr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ca462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnr_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c54b85",
   "metadata": {},
   "source": [
    "### Export RNR movie to hd5 file.\n",
    "The reason to this otherwise unnecessary step is that motion correction cannot work from numpy array... Or at least the movie.motion_correct() does not have many options. See https://caiman.readthedocs.io/en/master/core_functions.html#movie-handling motion_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06987303",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_to_hdf5(rnr_data.astype(np.uint16), rnr_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35566572",
   "metadata": {},
   "source": [
    "## Motion Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156dad4e",
   "metadata": {},
   "source": [
    "### For compatibility of exported moco params file (with pure python pipeline splitting), need to define splitting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_intervals = [(1, len(rnr.nd2_data))]\n",
    "moco_flags = [True]\n",
    "cnmf_intervals = moco_intervals.copy()\n",
    "cnmf_flags = [True]\n",
    "\n",
    "# in RNR (first import of nd2 file), there is the choice to import part of the file\n",
    "begin_end_frames = (1, len(rnr.nd2_data))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9809c7f",
   "metadata": {},
   "source": [
    "### Optional: Play the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_movie = False\n",
    "if display_movie:\n",
    "    ds_ratio = 0.2\n",
    "    movie.resize(1, 1, ds_ratio).play(\n",
    "        q_max=99.5, fr=30, magnification=2)  # this should not change size of movie itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11be371",
   "metadata": {},
   "source": [
    "### Setup some parameters\n",
    "We set some parameters that are relevant to the file, and then parameters for motion correction, processing with CNMF and component quality evaluation. Note that the dataset `Sue_2x_3000_40_-46.tif` has been spatially downsampled by a factor of 2 and has a lower than usual spatial resolution (2um/pixel). As a result several parameters (`gSig, strides, max_shifts, rf, stride_cnmf`) have lower values (halved compared to a dataset with spatial resolution 1um/pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = 15                             # imaging rate in frames per second\n",
    "decay_time = 0.4                    # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)         # overlap between pathes (size of patch strides+overlaps)\n",
    "max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels)\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "# see https://www.youtube.com/watch?v=wUhKkNtSu_s 21:10\n",
    "p = 2                       # order of the autoregressive system (original: 1 (2 advised for slow signal like GCaMP6s))\n",
    "gnb = 2                     # number of global background components\n",
    "merge_thr = 0.8             # merging threshold, max correlation allowed. (original: 0.85)\n",
    "# WARNING: for photostim, seizures etc., this might be the reason why neurons (all highly correlated) get drawn together.\n",
    "\n",
    "rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "K = 4                       # number of components per patch\n",
    "gSig = [6, 6]               # expected half size of neurons in pixels (original value: 4, 4)\n",
    "method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.5 # neurons with cnn probability lower than this value are rejected \n",
    "                # (original: 0.1; found a lot of artefacts accepted with CNN classifier predicting <0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e18361e",
   "metadata": {},
   "source": [
    "### Create a parameters object\n",
    "You can creating a parameters object by passing all the parameters as a single dictionary. Parameters not defined in the dictionary will assume their default values. The resulting `params` object is a collection of subdictionaries pertaining to the dataset to be analyzed `(params.data)`, motion correction `(params.motion)`, data pre-processing `(params.preprocess)`, initialization `(params.init)`, patch processing `(params.patch)`, spatial and temporal component `(params.spatial), (params.temporal)`, quality evaluation `(params.quality)` and online processing `(params.online)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts_dict = {'fnames': moco_fnames, \n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest,\n",
    "            'var_name_hdf5': 'data',}  # FIXME: does not work! Check where does this setting get lost?\n",
    "\n",
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7deefe1",
   "metadata": {},
   "source": [
    "### Setup a cluster\n",
    "To enable parallel processing a (local) cluster needs to be set up. This is done with a cell below. The variable `backend` determines the type of cluster used. The default value `'local'` uses the multiprocessing package. The `ipyparallel` option is also available. More information on these choices can be found [here](https://github.com/flatironinstitute/CaImAn/blob/master/CLUSTER.md). The resulting variable `dview` expresses the cluster option. If you use `dview=dview` in the downstream analysis then parallel processing will be used. If you use `dview=None` then no parallel processing will be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d971b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce27b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MotionCorrect(moco_fnames, dview=dview, **opts.get_group('motion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ALTERNATIVE to exporting h5 and importing it again!\n",
    "\"\"\"\n",
    "Args:\n",
    "            max_shift_w,max_shift_h: maximum pixel shifts allowed when correcting\n",
    "                                     in the width and height direction\n",
    "\n",
    "            template: if a good template for frame by frame correlation exists\n",
    "                      it can be passed. If None it is automatically computed\n",
    "\n",
    "            method: depends on what is installed 'opencv' or 'skimage'. 'skimage'\n",
    "                    is an order of magnitude slower\n",
    "\n",
    "            num_frames_template: if only a subset of the movies needs to be loaded\n",
    "                                 for efficiency/speed reasons\n",
    "                                 \n",
    "max_shift_w=5,\n",
    "max_shift_h=5,\n",
    "num_frames_template=None,\n",
    "template=None,\n",
    "method: str = 'opencv',\n",
    "remove_blanks: bool = False,\n",
    "interpolation: str = 'cubic'\n",
    "\"\"\"\n",
    "\n",
    "# movie.motion_correct()   # this might change movie itself! Alternative: extract_shifts, apply_shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ab322",
   "metadata": {},
   "source": [
    "### Perform motion correction and save as C-order memmap\n",
    "The filename is mc.fname_tot_els and mc.mmap_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f48163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#%% Run piecewise-rigid motion correction using NoRMCorre\n",
    "mc.motion_correct(save_movie=True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "border_to_0 = 0 if mc.border_nan is 'copy' else mc.border_to_0  # FIXME: gives warning, should use \"==\" with literals\n",
    "    # maximum shift to be used for trimming against NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72ba3f",
   "metadata": {},
   "source": [
    "### Optional: show comparison with original movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475845b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% compare with original movie\n",
    "display_movie = False  # TODO: does not seem to work. Create own function to show result?\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(moco_fnames)\n",
    "    ds_ratio = 0.2\n",
    "    cm.concatenate([m_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie,\n",
    "                    m_els.resize(1, 1, ds_ratio)], \n",
    "                   axis=2).play(fr=60, gain=15, magnification=2, offset=0)  # press q to exit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bebffe",
   "metadata": {},
   "source": [
    "### Save C-order memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f25a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% MEMORY MAPPING\n",
    "fname_mmap_f = mc.mmap_file\n",
    "# memory map the file in order 'C'\n",
    "fname_mmap_c = cm.save_memmap(fname_mmap_f, base_name='memmap', order='C',\n",
    "                           border_to_0=border_to_0, dview=dview) # exclude borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512badb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fname_mmap_c' not in locals():\n",
    "    fname_mmap_c = fh.open_file(\"Select C-memmap file.\")\n",
    "print(f\"Working with C-memmap\\n{fname_mmap_c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434eceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "if \"dview\" in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10177b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the file\n",
    "Yr, dims, T = cm.load_memmap(fname_mmap_c)\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "    #load frames in python format (T x X x Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c678e",
   "metadata": {},
   "source": [
    "### Clean up memory now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5098551",
   "metadata": {},
   "source": [
    "### Run CNMF on patches in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RUN CNMF ON PATCHES\n",
    "# First extract spatial and temporal components on patches and combine them\n",
    "# for this step deconvolution is turned off (p=0). If you want to have\n",
    "# deconvolution within each patch change params.patch['p_patch'] to a\n",
    "# nonzero value\n",
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "cnm = cnm.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f726f4",
   "metadata": {},
   "source": [
    "### Inspecting the results\n",
    "Briefly inspect the results by plotting contours of identified components against correlation image.\n",
    "The results of the algorithm are stored in the object `cnm.estimates`. More information can be found in the definition of the `estimates` object and in the [wiki](https://github.com/flatironinstitute/CaImAn/wiki/Interpreting-Results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot contours of found components\n",
    "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.nb_view_components(img=Cn, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f92cc",
   "metadata": {},
   "source": [
    "## Re-run (seeded) CNMF  on the full Field of View  \n",
    "You can re-run the CNMF algorithm seeded on just the selected components from the previous step. Be careful, because components rejected on the previous step will not be recovered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589132f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
    "cnm2 = cnm.refit(images, dview=dview)  \n",
    "# cnm and cnm2 reference the same object! Still useful, as existence of cnm2 implies that this step was made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffa170f",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "# if performed re-run:\n",
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)\n",
    "else:\n",
    "    cnm.estimates.evaluate_components(images, cnm.params, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8ab3e",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components)\n",
    "else:\n",
    "    cnm.estimates.plot_contours_nb(img=Cn, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22338682",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "plot_accepted = True\n",
    "if plot_accepted:\n",
    "    if \"cnm2\" in locals():\n",
    "        cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components)\n",
    "    else:\n",
    "        cnm.estimates.nb_view_components(img=Cn, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "plot_rejected = False\n",
    "if plot_rejected:\n",
    "    if \"cnm2\" in locals():\n",
    "        if len(cnm2.estimates.idx_components_bad) > 0:\n",
    "            cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components_bad)\n",
    "        else:\n",
    "            print(\"No components were rejected.\")\n",
    "    else:\n",
    "        if len(cnm.estimates.idx_components_bad) > 0:\n",
    "            cnm.estimates.nb_view_components(img=Cn, idx=cnm.estimates.idx_components_bad)\n",
    "        else:\n",
    "            print(\"No components were rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb126b89",
   "metadata": {},
   "source": [
    "# Manually review and correct classifications\n",
    "It is only possible to check rejected and accepted components individually. A unified view can not be shown probably due to JavaScript limitations (or Bokeh limitations, more precisely). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from labrotation.two_photon_session import nb_view_components_manual_control, reopen_manual_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebdc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.idx_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484f48d",
   "metadata": {},
   "source": [
    "## Check rejected components first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bcca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_accepted_fname = nb_view_components_manual_control(cnm2.estimates, img=Cn, denoised_color=None, cmap='jet', thr=0.99, mode=\"rejected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd2502",
   "metadata": {},
   "source": [
    "## Move selected components to accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_rejected = reopen_manual_control(manual_accepted_fname)\n",
    "print(false_rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_old_accepted = len(cnm2.estimates.idx_components)\n",
    "n_old_rejected = len(cnm2.estimates.idx_components_bad)\n",
    "n_false_rejected = len(false_rejected)\n",
    "\n",
    "arr_accepted = np.zeros(shape=(n_old_accepted + n_false_rejected,), dtype=cnm2.estimates.idx_components.dtype) \n",
    "arr_rejected = np.zeros(shape=(n_old_rejected - n_false_rejected,), dtype=cnm2.estimates.idx_components_bad.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ae1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new accepted list. Consists of old accepted components plus elements of false_rejected.\n",
    "# TODO: alternative is np.concatenate(cnm2.estimates.idx_components, false_rejected)\n",
    "for i in range(n_old_accepted):\n",
    "    arr_accepted[i] = cnm2.estimates.idx_components[i]\n",
    "for i_extra in range(n_false_rejected):\n",
    "    arr_accepted[n_old_accepted + i_extra] = false_rejected[i_extra]\n",
    "arr_accepted = np.sort(arr_accepted)\n",
    "\n",
    "# copy all rejected elements minus falsely rejected into new array of rejected components\n",
    "i_new_rejected = 0\n",
    "for i in range(n_old_rejected):\n",
    "    if cnm2.estimates.idx_components_bad[i] not in false_rejected:\n",
    "        arr_rejected[i_new_rejected] = cnm2.estimates.idx_components_bad[i]\n",
    "        i_new_rejected += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for false_rejection in false_rejected:\n",
    "    assert false_rejection not in arr_rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabfa18f",
   "metadata": {},
   "source": [
    "## Warning: old classification data will be overwritten here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cea9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(false_rejected) > 0:\n",
    "    cnm2.estimates.idx_components = arr_accepted.copy()\n",
    "    cnm2.estimates.idx_components_bad = arr_rejected.copy()\n",
    "    print(\"Replaced cnm2.estimates fields with new component lists\")\n",
    "del arr_accepted\n",
    "del arr_rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766972b0",
   "metadata": {},
   "source": [
    "## Check accepted components, reject falsely classified neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_rejected_fname = nb_view_components_manual_control(cnm2.estimates, img=Cn, denoised_color=None, cmap='jet', thr=0.99, mode=\"accepted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_accepted = reopen_manual_control(manual_rejected_fname)\n",
    "print(false_accepted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a794193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_old_accepted = len(cnm2.estimates.idx_components)\n",
    "n_old_rejected = len(cnm2.estimates.idx_components_bad)\n",
    "n_false_accepted = len(false_accepted)\n",
    "\n",
    "arr_accepted = np.zeros(shape=(n_old_accepted - n_false_accepted,), dtype=cnm2.estimates.idx_components.dtype) \n",
    "arr_rejected = np.zeros(shape=(n_old_rejected + n_false_accepted,), dtype=cnm2.estimates.idx_components_bad.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new rejected list. Consists of old rejected components plus elements of false_accepted.\n",
    "for i in range(n_old_rejected):\n",
    "    arr_rejected[i] = cnm2.estimates.idx_components_bad[i]\n",
    "for i_extra in range(n_false_accepted):\n",
    "    arr_rejected[n_old_rejected + i_extra] = false_accepted[i_extra]\n",
    "arr_rejected = np.sort(arr_rejected)\n",
    "\n",
    "# copy all accepted elements minus falsely accepted into new array of accepted components\n",
    "i_new_accepted = 0\n",
    "for i in range(n_old_accepted):\n",
    "    if cnm2.estimates.idx_components[i] not in false_accepted:\n",
    "        arr_accepted[i_new_accepted] = cnm2.estimates.idx_components[i]\n",
    "        i_new_accepted += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1c7a6",
   "metadata": {},
   "source": [
    "## Warning: old classification data will be overwritten here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a320ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(false_accepted) > 0:\n",
    "    cnm2.estimates.idx_components = arr_accepted.copy()\n",
    "    cnm2.estimates.idx_components_bad = arr_rejected.copy()\n",
    "    print(\"Replaced cnm2.estimates fields with new component lists\")\n",
    "del arr_accepted\n",
    "del arr_rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211af05",
   "metadata": {},
   "source": [
    "## Experimental: merge components\n",
    "WARNING: right now, it takes a lot of memory (for 9 GB video, around 100 GB). Could be reduced to significantly less, maybe 18 GB, maybe even to 9GB, with optimizations... Main source of RAM requirement is working with 64-bit float instead of 16-bit integers, defining the components as individual parameters instead of just using one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69258cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnm2.skip_refinement:\n",
    "    print(\"Merging did not take place. It makes sense to merge components.\")\n",
    "    to_merge = True\n",
    "else:\n",
    "    print(\"Merging did take place in fit()! No need to merge again.\")\n",
    "    to_merge = False\n",
    "\n",
    "# Set to true to save movie of background for checking algorithm correctness \n",
    "save_background = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf348373",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_merge:\n",
    "    AC = (cnm2.estimates.A * cnm2.estimates.C)\n",
    "    AC = AC.reshape((512,512,AC.shape[1]))\n",
    "    # create global background components\n",
    "    bf1 = np.outer(cnm2.estimates.b[:,0],cnm2.estimates.f[0]).reshape((512,512,bf1.shape[1]))\n",
    "    bf2 = np.outer(cnm2.estimates.b[:,1],cnm2.estimates.f[1]).reshape((512,512,bf2.shape[1]))\n",
    "    \n",
    "    # the parameters should have shape (x, y, n_frames), for example, (512, 512, n_frames)\n",
    "    assert bf1.shape[-1] == AC.shape[-1]\n",
    "    assert iamges.shape[0] == bf1.shape[-1]  # assert that the images is of dimensions (n_frames, 512, 512)\n",
    "    print(bf1.shape)\n",
    "    \n",
    "    # reformat all information-carrying components to same shape as original movie (images)\n",
    "    AC = np.moveaxis(AC, [0, 1], [-2, -1])\n",
    "    bf1 = np.moveaxis(bf1, [0, 1], [-2, -1])\n",
    "    bf2 = np.moveaxis(bf2, [0, 1], [-2, -1])\n",
    "    \n",
    "    # Get residual movie: Y_res = Y - A*C - b*f\n",
    "    Y_res = images - AC - bf1 - bf2\n",
    "    Y_res = Y_res.astype(np.int16)  # reduce variable size\n",
    "    \n",
    "    del bf1, bf2, AC\n",
    "    \n",
    "    cnm2.merge_comps(Y=Y_res.reshape((Y_res.shape[0]*Y_res.shape[1], Y_res.shape[2])))\n",
    "    \n",
    "    # Optional: save background as tif to check correctness\n",
    "    if save_background:\n",
    "        import tifffile as tif\n",
    "        tif.imsave(os.path.join(export_folder, 'background.tif'), Y_res, bigtiff=True)\n",
    "else:\n",
    "    print(\"No merging took place.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d505d",
   "metadata": {},
   "source": [
    "### Extract DF/F values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4969205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "#FIXME: \"Oops!\" printed when cnm2 not in locals (i.e. no refitting was done). Possibly this function never returns.\n",
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)\n",
    "else:\n",
    "    cnm.estimates.detrend_df_f(quantileMin=8, frames_window=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85965e4",
   "metadata": {},
   "source": [
    "### Select only high quality components\n",
    "**IMPORTANT** up until running `select_components()`, `cnm2.estimates.idx_components` and `cnm2.estimates.idx_components_bad` contain the indices of the accepted and rejected components, respectively. After running select_components, these entries disappear (are set to None). Then, in `cnm2.estimates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573c329",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(cnm2.estimates.idx_components)} accepted, {len(cnm2.estimates.idx_components_bad)} rejected components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expicitly state to save discarded components (default is also True)\n",
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.select_components(use_object=True, save_discarded_components=True)\n",
    "else:\n",
    "    cnm.estimates.select_components(use_object=True, save_discarded_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f00b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"{len(cnm2.estimates.idx_components)} accepted, {len(cnm2.estimates.idx_components_bad)} rejected components\")\n",
    "cnm2.estimates.nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5363a",
   "metadata": {},
   "source": [
    "## Optional: Display final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fade4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"cnm2\" in locals():\n",
    "    cnm2.estimates.nb_view_components(img=Cn, denoised_color='red')\n",
    "else:\n",
    "    cnm.estimates.nb_view_components(img=Cn, denoised_color='red')\n",
    "print('you may need to change the data rate to generate this one: use jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 before opening jupyter notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031a099",
   "metadata": {},
   "source": [
    "## Saving, closing, and creating denoised version\n",
    "### You can save an hdf5 file with all the fields of the cnmf object. Use load_CNMF() to open the results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b763da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = True\n",
    "if save_results:\n",
    "    if \"cnm2\" in locals():\n",
    "        cnm2.save(cnmf_results_save_path)\n",
    "    else:\n",
    "        cnm.save(cnmf_results_save_path)\n",
    "    print(f\"saved to\\n{cnmf_results_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cad0bb",
   "metadata": {},
   "source": [
    "### Add uuid as attribute to cnmf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59220b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(cnmf_results_save_path, 'r+') as hf:\n",
    "    hf.attrs[\"uuid\"] = session_uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2075472",
   "metadata": {},
   "source": [
    "### Stop cluster and clean up log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d445936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3c392",
   "metadata": {},
   "source": [
    "### Export parameters and metadata as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dict = opts_dict.copy()\n",
    "json_dict[\"original_fnames\"] = nd2_fpath\n",
    "json_dict[\"rnr_win\"] = win\n",
    "json_dict[\"amplitude_threshold\"] = amplitude_threshold\n",
    "json_dict[\"uuid\"] = session_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8925391",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_fpath, 'w') as f:\n",
    "    json.dump(json_dict, f, indent=4)\n",
    "print(f\"Saved parameters to\\n{json_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b46207",
   "metadata": {},
   "source": [
    "### Optional: View movie with the results\n",
    "We can inspect the denoised results by reconstructing the movie and playing alongside the original data and the resulting (amplified) residual movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224db7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_movie = False\n",
    "if play_movie:\n",
    "    if \"cnm2\" in locals():\n",
    "        cnm2.estimates.play_movie(images, q_max=99.9, gain_res=2,\n",
    "                                          magnification=2,\n",
    "                                          bpx=border_to_0,\n",
    "                                          include_bck=False)\n",
    "    else:\n",
    "        cnm.estimates.play_movie(images, q_max=99.9, gain_res=2,\n",
    "                                      magnification=2,\n",
    "                                      bpx=border_to_0,\n",
    "                                      include_bck=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028f7eb",
   "metadata": {},
   "source": [
    "The denoised movie can also be explicitly constructed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99359cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie\n",
    "if \"cnm2\" in locals():\n",
    "    denoised = cm.movie(cnm2.estimates.A.dot(cnm2.estimates.C) + \\\n",
    "                        cnm2.estimates.b.dot(cnm2.estimates.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])\n",
    "else:\n",
    "    denoised = cm.movie(cnm.estimates.A.dot(cnm.estimates.C) + \\\n",
    "                        cnm.estimates.b.dot(cnm.estimates.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_denoised = False\n",
    "if save_denoised:\n",
    "    denoised.save(denoised_optional_fpath)\n",
    "    print(f\"Denoised movie saved to\\n\\t{denoised_optional_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d43410",
   "metadata": {},
   "source": [
    "# Save moco parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion_correction.py (from caiman) 503-, 524 is the relevant case\n",
    "Y = cm.load(moco_fnames[0]).astype(np.float32)\n",
    "ymin = Y.min()\n",
    "if ymin < 0:\n",
    "    Y -= Y.min()\n",
    "\n",
    "xy_grid = [(it[0], it[1]) for it in sliding_window(Y[0], mc.overlaps, mc.strides)]\n",
    "dims_grid = tuple(np.max(np.stack(xy_grid, axis=1), axis=1) - np.min(\n",
    "                    np.stack(xy_grid, axis=1), axis=1) + 1)\n",
    "shifts_x = np.stack([np.reshape(_sh_, dims_grid, order='C').astype(\n",
    "                    np.float32) for _sh_ in mc.x_shifts_els], axis=0)\n",
    "shifts_y = np.stack([np.reshape(_sh_, dims_grid, order='C').astype(\n",
    "                    np.float32) for _sh_ in mc.y_shifts_els], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_params_lis = [\n",
    "\"max_shifts\",\n",
    "\"niter_rig\",\n",
    "\"splits_rig\",\n",
    "\"num_splits_to_process_rig\",\n",
    "\"num_splits_to_process_els\",\n",
    "\"strides\",\n",
    "\"overlaps\",\n",
    "\"splits_els\",\n",
    "\"upsample_factor_grid\",\n",
    "\"max_deviation_rigid\",\n",
    "\"shifts_opencv\",\n",
    "\"min_mov\",\n",
    "\"nonneg_movie\",\n",
    "\"gSig_filt\",\n",
    "\"use_cuda\",\n",
    "\"border_nan\",\n",
    "\"pw_rigid\",\n",
    "\"var_name_hdf5\",\n",
    "\"is3D\",\n",
    "\"indices\",\n",
    "\"total_template_rig\",\n",
    "\"templates_rig\",\n",
    "\"fname_tot_rig\",\n",
    "\"shifts_rig\",\n",
    "\"total_template_els\",\n",
    "\"fname_tot_els\",\n",
    "\"templates_els\",\n",
    "\"x_shifts_els\",\n",
    "\"y_shifts_els\",\n",
    "\"coord_shifts_els\",\n",
    "\"border_to_0\",\n",
    "\"mmap_file\",  # also fname_mmap_f\n",
    "]\n",
    "\n",
    "# min_mov, total_template_rig, total_template_els, border_to_0 have shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ae224",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_types = False\n",
    "if list_types:\n",
    "    for dset in moco_params_lis:\n",
    "        data = getattr(mc, dset)\n",
    "        print(f\"{dset}: {type(data)}\")\n",
    "        try:\n",
    "            print(f\"\\t{data.shape}\")\n",
    "        except:\n",
    "            print(f\"\\tno shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2acf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for compatibility with Pure Python Pipeline Splitting, add \n",
    "# moco_intervals, moco_flags, cnmf_flags. As there is no splitting, these are:\n",
    "# moco_intervals = [(1, len(rnr.nd2_data))]\n",
    "# moco_flags = [True]\n",
    "# cnmf_flags = [True]\n",
    "utf8_type = h5py.string_dtype('utf-8', 30)\n",
    "def append_dataset(h5_file, name, data):\n",
    "    if (type(data) is tuple and type(data[0]) is slice) \\\n",
    "    or \\\n",
    "    data is None \\\n",
    "    or \\\n",
    "    type(data) is str \\\n",
    "    or \\\n",
    "    (type(data) is list and (data[0] is None or type(data[0]) is str)):  \n",
    "        # some entries (e.g. indices) are a tuple of slices\n",
    "        # some entries are of type string, are None, [None, None, ...] or [\"...\"]\n",
    "        # convert these types to string (easiest way to preserve information about format)\n",
    "        #data_arr = np.array(, dtype=utf8_type)\n",
    "        hf.attrs[name] = data.__str__().encode(\"utf-8\")\n",
    "    else:\n",
    "        data_arr = np.array(data)\n",
    "        dataset = h5_file.create_dataset(name, data_arr.shape, data_arr.dtype)\n",
    "        if len(data_arr.shape) == 0:\n",
    "            dataset = data_arr\n",
    "        else:\n",
    "            for i in range(data_arr.shape[0]):\n",
    "                dataset[i] = data_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf7247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(moco_pars_fpath, 'w') as hf:\n",
    "    print(\"Adding uuid\")\n",
    "    hf.attrs[\"uuid\"] = session_uuid\n",
    "    print(\"Adding moco_intervals\")\n",
    "    append_dataset(hf, \"moco_intervals\", moco_intervals)\n",
    "    print(\"Adding moco_flags\")\n",
    "    append_dataset(hf, \"moco_flags\", moco_flags)\n",
    "    print(\"Adding cnmf_intervals\")\n",
    "    append_dataset(hf, \"cnmf_intervals\", cnmf_intervals)\n",
    "    print(\"Adding cnmf_flags\")\n",
    "    append_dataset(hf, \"cnmf_flags\", cnmf_flags)\n",
    "    print(\"Adding begin_end_frames\")\n",
    "    append_dataset(hf, \"begin_end_frames\", begin_end_frames)\n",
    "    print(\"Saving moco params...\")\n",
    "    for dset_name in moco_params_lis:\n",
    "        print(\"\\t\" + dset_name)\n",
    "        data = getattr(mc, dset_name)\n",
    "        append_dataset(hf, dset_name, data)\n",
    "print(f\"Saved listed parameters in\\n\\t{moco_pars_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf68b8",
   "metadata": {},
   "source": [
    "# (Optional) Match to LabView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b96e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_to_lv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"MATLAB_2P_FOLDER\" in env_dict:\n",
    "    matlab_2p_path = env_dict[\"MATLAB_2P_FOLDER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if match_to_lv:\n",
    "    import labrotation.two_photon_session as tps\n",
    "    nd2_meta_path = fh.open_file(\"Choose Nikon metadata file (.txt)!\")\n",
    "    labview_path = fh.open_file(\"Choose LabView file (xy.txt, NOT xytime.txt)! Press cancel if not available.\")\n",
    "    lfp_path = fh.open_file(\"Choose LFP file (.abf)! Press cancel if none available.\")\n",
    "    if lfp_path == \".\":\n",
    "        lfp_path = None\n",
    "    if labview_path == \".\":\n",
    "        labview_path = None\n",
    "        labview_timestamps_path = None\n",
    "    else:\n",
    "        labview_timestamps_path = labview_path[:-4] + \"time.txt\"\n",
    "    export_fpath = os.path.join(export_folder, os.path.splitext(nd2_fname)[0] + \"_session.h5\")\n",
    "    session = tps.TwoPhotonSession.init_and_process(nd2_fpath, nd2_meta_path, labview_path, labview_timestamps_path, lfp_path, matlab_2p_path)\n",
    "    session.export_hdf5(export_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff045a",
   "metadata": {},
   "source": [
    "# Opening results (data fields and attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc894613",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(moco_pars_fpath, \"r\") as hf:\n",
    "    for key in hf.attrs.keys():\n",
    "        print(f\"{key}:\\n\\t{hf.attrs[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(moco_pars_fpath, \"r\") as hf:\n",
    "    for key in hf.keys():\n",
    "        print(f\"{key}:\\n\\t{hf[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14b641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734d18a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnr.rnr_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78342a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.discarded_components.idx_components_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ca122",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.idx_components_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48041885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

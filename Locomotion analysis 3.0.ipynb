{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e013d97",
   "metadata": {},
   "source": [
    "# Locomotion analysis v3.0\n",
    "This script works with the pre-assembled dataset, cutting out most of the acquiring data part, resulting in cleaner and more reliable analysis (the dataset is manually checked separately from this script)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0239a8",
   "metadata": {},
   "source": [
    "Output naming convention: `loco_(opt. waterfall/sanitycheck/stattest)_{dataset type (tmev/chr2) OR experiment type (tmev, chr2_szsd, ...) if waterfall or sanity check}_(opt. aggregate)_(opt. delta)_(opt. window_type)_{datetime}.{file format}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daccd5dd",
   "metadata": {},
   "source": [
    "### About the data\n",
    "* `speed`: the speed as measured by the sensor attached to one wheel of the treadmill\n",
    "* `totdist`: the total distance directly calculated in LabView. Whenever `speed` is negative, `totdist` is reduced! This is why we need...\n",
    "* `totdist_abs`: the i-th value is calculated as `totdist_abs[i-1] + abs(speed[i]*(t[i] - t[i-1]))`, i.e. integrated absolute distance covered.\n",
    "* `running`: a binary value, 0 if the mouse is not running (the `speed`is below a threshold, `40` by default), 1 otherwise. The original 100 Hz data, from which the downsampling happens, already includes an algorithm to connect two data points/intervals when the time not spent moving between them is small. The threshold for two `running` periods to still be counted as one is 250 bins@100 Hz\n",
    "* `running%`: the sum of `running` (i.e. number of frames where `running` is 1) divided by the length of the segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT_METRICS = [\"totdist_abs_norm\", \"running%\", \"running_episodes\", \"avg_speed\", \"running_episodes_mean_length\", \"max_speed\"]  # metrics to test for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c4451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metric_label = OrderedDict([(\"totdist_abs\", \"Total (absolute) distance, a.u.\"),\n",
    "                                (\"running%\", \"% of time spent with locomotion\"), \n",
    "                                (\"running_episodes\", \"Number of running episodes\"),\n",
    "                                (\"avg_speed\", \"Average of locomotion velocity\"),\n",
    "                                (\"running_episodes_mean_length\", \"Mean length of running episodes, a.u.\"),\n",
    "                                (\"max_speed\", \"Max velocity of locomotion, a.u.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMPL_THRESHOLD = 0.2  # threshold that one element within the running episode candidate has to be reached for the episode to not be discarded.\n",
    "TEMP_THRESHOLD = 15  # in number of frames. In 15 Hz, this amounts to 1 s threshold that a candidate episode has to reach to not be discarded. \n",
    "EPISODE_MERGE_THRESHOLD_FRAMES = 8  # merge running episodes if temporal distance distance smaller than this many frames or equal (15 Hz!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117cd92",
   "metadata": {},
   "source": [
    "# Set version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27d936",
   "metadata": {},
   "source": [
    "### Set up export figure parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = False  # export results of this script?\n",
    "save_sanity_check = False  # make sure to set save_figs to True as well\n",
    "save_waterfall = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02de199",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = False  # set to True to save the figures created\n",
    "save_as_eps = False\n",
    "save_as_pdf = True\n",
    "if save_as_pdf:\n",
    "    file_format = \".pdf\"\n",
    "elif save_as_eps:\n",
    "    file_format = \".eps\"\n",
    "else:\n",
    "    file_format = \".jpg\"\n",
    "if save_figs:\n",
    "    print(f\"Going to save figures as {file_format} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51054967",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aef127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80753c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labrotation.file_handling as fh\n",
    "import h5py\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps\n",
    "import seaborn as sns\n",
    "import uuid  # for unique labeling of sessions and coupling arrays (mouse velocity, distance, ...) to sessions in dataframe \n",
    "from matplotlib import cm  # colormap\n",
    "import datadoc_util\n",
    "from labrotation import two_photon_session as tps\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from math import floor\n",
    "import matlab.engine  # for saving data to workspace\n",
    "from scipy.stats import ttest_rel\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cf136",
   "metadata": {},
   "source": [
    "# Set seaborn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7310fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=3)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec68054",
   "metadata": {},
   "source": [
    "# If exists, load environmental variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee7f17",
   "metadata": {},
   "source": [
    "# Set up data documentation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89537f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: inside the documentation folder, the subfolders carry the id of each mouse (not exact necessarily, but they \n",
    "# can be identified by the name of the subfolder). \n",
    "# Inside the subfolder xy (for mouse xy), xy_grouping.xlsx and xy_segmentation.xlsx can be found.\n",
    "# xy_grouping.xlsx serves the purpose of finding the recordings belonging together, and has columns:\n",
    "# folder, nd2, labview, lfp, face_cam_last, nikon_meta, experiment_type, day\n",
    "# xy_segmentation.xlsx contains frame-by-frame (given by a set of disjoint intervals forming a cover for the whole recording) \n",
    "# classification of the events in the recording (\"normal\", seizure (\"sz\"), sd wave (\"sd_wave\") etc.). The columns:\n",
    "# folder, interval_type, frame_begin, frame_end.\n",
    "\n",
    "# TODO: write documentation on contents of xlsx files (what the columns are etc.)\n",
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    docu_folder = fh.open_dir(\"Choose folder containing folders for each mouse!\")\n",
    "print(f\"Selected folder:\\n\\t{docu_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652dd010",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"documentation\" in os.listdir(docu_folder):\n",
    "    mouse_folder = os.path.join(docu_folder, \"documentation\")\n",
    "else:\n",
    "    mouse_folder = docu_folder\n",
    "mouse_names = os.listdir(mouse_folder)\n",
    "print(f\"Mice detected:\")\n",
    "for mouse in mouse_names:\n",
    "    print(f\"\\t{mouse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4476f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_for_fname():\n",
    "    now = datetime.now()\n",
    "    return f\"{now.year:04d}{now.month:02d}{now.day:02d}-{now.hour:02d}{now.minute:02d}{now.second:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad91b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = env_dict[\"DOWNLOADS_FOLDER\"]\n",
    "print(f\"Output files will be saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cdc0d4",
   "metadata": {},
   "source": [
    "## Set a uniform datetime string for output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dtime = get_datetime_for_fname()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe63c765",
   "metadata": {},
   "source": [
    "### Load matlab-2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882258c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"MATLAB_2P_FOLDER\" in env_dict.keys():\n",
    "    matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]\n",
    "else:\n",
    "    matlab_2p_folder = fh.open_dir(\"Choose matlab-2p folder\")\n",
    "print(f\"matlab-2p folder set to:\\n\\t{matlab_2p_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8efd1b",
   "metadata": {},
   "source": [
    "### Load data documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = datadoc_util.DataDocumentation(docu_folder)\n",
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32afd1",
   "metadata": {},
   "source": [
    "### Set up color coding\n",
    "for now, only possible to assign a color to each mouse. Later, when event uuids available, need to map event uuid to color code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f609aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_colors = ddoc.getColorings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_colors_mouse = df_colors[[\"mouse_id\", \"color\"]].to_dict(orient=\"list\")\n",
    "dict_colors_mouse = dict(zip(dict_colors_mouse[\"mouse_id\"], dict_colors_mouse[\"color\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07153a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_colors_mouse[\"T413\"] = \"#000000\"  # set one to black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847f99c",
   "metadata": {},
   "source": [
    "### Load events_list dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list_fpath = os.path.join(docu_folder, \"events_list.xlsx\")\n",
    "assert os.path.exists(events_list_fpath)\n",
    "\n",
    "df_events_list = pd.read_excel(events_list_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13444932",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_traces_fpath = fh.open_file(\"Open assembled_traces h5 file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecee90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_chr2 = False\n",
    "is_bilat = False\n",
    "if \"chr2\" in assembled_traces_fpath.lower():\n",
    "    is_chr2 = True\n",
    "    print(\"ChR2 dataset detected\")\n",
    "elif \"bilat\" in assembled_traces_fpath.lower():\n",
    "    is_bilat = True\n",
    "    print(\"Bilat stim dataset detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d14289",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chr2:\n",
    "    used_mouse_ids = [\"OPI-2239\", \"WEZ-8917\", \"WEZ-8924\", \"WEZ-8922\"]\n",
    "elif is_bilat:\n",
    "    used_mouse_ids = [\"WEZ-8946\", \"WEZ-8960\", \"WEZ-8961\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"chr2\" if is_chr2 else \"bilat\" if is_bilat else \"tmev\" \n",
    "if not is_chr2:  # for TMEV, also save pooled CA1+NC statistics\n",
    "    pool_tmev = True\n",
    "else:\n",
    "    pool_tmev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_dict = dict()  \n",
    "traces_meta_dict = dict()\n",
    "# first keys are event uuids, inside the following dataset names:\n",
    "# 'lfp_mov_t', 'lfp_mov_y', 'lfp_t', 'lfp_y', 'lv_dist', 'lv_rounds', \n",
    "# 'lv_running', 'lv_speed', 'lv_t_s', 'lv_totdist', 'mean_fluo'\n",
    "with h5py.File(assembled_traces_fpath, \"r\") as hf:\n",
    "    for uuid in hf.keys():\n",
    "        if (not is_chr2) or (hf[uuid].attrs[\"mouse_id\"] in used_mouse_ids):\n",
    "            session_dataset_dict = dict() \n",
    "            session_meta_dict = dict()\n",
    "            for dataset_name in hf[uuid].keys():\n",
    "                session_dataset_dict[dataset_name] = np.array(hf[uuid][dataset_name])\n",
    "            for attr_name in hf[uuid].attrs:\n",
    "                session_meta_dict[attr_name] = hf[uuid].attrs[attr_name]\n",
    "            traces_dict[uuid] = session_dataset_dict.copy()\n",
    "            traces_meta_dict[uuid] = session_meta_dict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27f767",
   "metadata": {},
   "source": [
    "### Get locomotion amplitude by finding min and max LabView speed entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_speed = np.inf\n",
    "max_speed = -np.inf\n",
    "for event_uuid in traces_dict.keys():\n",
    "    speed = traces_dict[event_uuid][\"lv_speed\"]\n",
    "    min_candidate = np.min(speed)\n",
    "    max_candidate = np.max(speed)\n",
    "    if min_candidate < min_speed:\n",
    "        min_speed = min_candidate\n",
    "    if max_candidate > max_speed:\n",
    "        max_speed = max_candidate\n",
    "print(f\"Speed range: {min_speed} to {max_speed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "LV_SPEED_AMPL = max_speed - min_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc21302",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_bilat:\n",
    "    min_fluo = np.inf\n",
    "    max_fluo = -np.inf\n",
    "    for event_uuid in traces_dict.keys():\n",
    "        mean_fluo = traces_dict[event_uuid][\"mean_fluo\"]\n",
    "        if is_chr2:\n",
    "            if traces_meta_dict[event_uuid][\"mouse_id\"] in used_mouse_ids:\n",
    "                if \"i_stim_begin_frame\" in traces_meta_dict[event_uuid].keys():\n",
    "                    # get 0-indexing, inclusive first and last frames of stim\n",
    "                    i_begin_stim = traces_meta_dict[event_uuid][\"i_stim_begin_frame\"]\n",
    "                    i_end_stim = traces_meta_dict[event_uuid][\"i_stim_end_frame\"]\n",
    "                    mean_fluo_except_stim = np.concatenate([mean_fluo[:i_begin_stim], mean_fluo[i_end_stim+1:]])\n",
    "                    min_candidate = np.min(mean_fluo_except_stim)\n",
    "                    max_candidate = np.max(mean_fluo_except_stim)\n",
    "                else:\n",
    "                    print(f\"{event_uuid} missing i_stim_begin_frame!\")\n",
    "        else:\n",
    "            min_candidate = np.min(mean_fluo)\n",
    "            max_candidate = np.max(mean_fluo)\n",
    "        if min_candidate < min_fluo:\n",
    "            min_fluo = min_candidate\n",
    "        if max_candidate > max_fluo:\n",
    "            max_fluo = max_candidate\n",
    "    print(f\"{min_fluo} to {max_fluo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ade1f7",
   "metadata": {},
   "source": [
    "# Calculate locomotion statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d049406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episodes(segment, merge_episodes=False, merge_threshold_frames=EPISODE_MERGE_THRESHOLD_FRAMES, return_begin_end_frames = False):\n",
    "    # if returns indices, then (i_begin, i_end) are both inclusive in 0-indexing!\n",
    "    \n",
    "    \n",
    "    n_eps = 0\n",
    "    episode_lengths = []  # in frame units\n",
    "    episodes = []\n",
    "    n_episodes = 0\n",
    "    current_episode_len = 0\n",
    "    \n",
    "    episode_begin = 0\n",
    "    episode_end = 0\n",
    "    \n",
    "    # algorithm: detect episode begin and episode end. record it in list\n",
    "    \n",
    "    for i_frame in range(len(segment)-1):  # check current and next element for end of a episode: ...100...\n",
    "        if segment[i_frame] == 1:  # current frame is part of an episode\n",
    "            # increase current episode length\n",
    "            if i_frame == 0 or segment[i_frame - 1] == 0:  # check if beginning of an episode or segment starts with an episode\n",
    "                episode_begin = i_frame\n",
    "            current_episode_len += 1\n",
    "            if segment[i_frame+1] == 0: # episode ends with next frame\n",
    "                n_episodes += 1\n",
    "                episode_lengths.append(current_episode_len)\n",
    "                episodes.append((episode_begin, i_frame))\n",
    "                current_episode_len = 0\n",
    "    if segment[-1] == 1: # check if there is one episode that does not end\n",
    "        n_episodes += 1\n",
    "        # add last segment to segments list\n",
    "        current_episode_len += 1\n",
    "        episode_lengths.append(current_episode_len)\n",
    "        episodes.append((episode_begin, len(segment)-1))\n",
    "        current_episode_len = 0\n",
    "        \n",
    "    assert current_episode_len == 0\n",
    "    if merge_episodes:\n",
    "        if len(episodes) < 2:  # single (or zero) episode cannot be merged\n",
    "            if return_begin_end_frames:\n",
    "                return episodes\n",
    "            else:\n",
    "                return [ep[1]-ep[0] + 1 for ep in episodes]\n",
    "        \n",
    "        # merge episodes that are close to each other\n",
    "        episodes_merged = []\n",
    "\n",
    "        episode_begin = episodes[0][0]\n",
    "        episode_end = episodes[0][1]\n",
    "        # starting with second episode, check if current episode can be merged with previous. If yes, update episode_end.\n",
    "        # If not, add previous episode to list, update episode_begin and episode_end to current episode values\n",
    "        \n",
    "        \n",
    "        for i_episode in range(1, len(episodes)):\n",
    "            current_episode_begin = episodes[i_episode][0]\n",
    "            current_episode_end = episodes[i_episode][1]\n",
    "\n",
    "            delta = current_episode_begin - episode_end\n",
    "            \n",
    "            if delta <= merge_threshold_frames:  # merge current episode to previous one\n",
    "                episode_end = current_episode_end\n",
    "            else:  # add previous episode to list, start with current episode\n",
    "                episodes_merged.append((episode_begin, episode_end))\n",
    "                episode_begin = current_episode_begin\n",
    "                episode_end = current_episode_end\n",
    "        # add last segment to list\n",
    "        episodes_merged.append((episode_begin, episode_end))\n",
    "        if return_begin_end_frames:\n",
    "            return episodes_merged\n",
    "        else:\n",
    "            episode_lengths_merged = [ep[1]-ep[0] + 1 for ep in episodes_merged]\n",
    "            return episode_lengths_merged\n",
    "    if return_begin_end_frames:\n",
    "        return episodes\n",
    "    else:\n",
    "        return episode_lengths  # len() shows n_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(speed_trace, episodes, temporal_threshold, amplitude_threshold):\n",
    "    \"\"\"\n",
    "    Given a trace and a list of tuples (i_begin_frame, i_end_frame), this function discards those that\n",
    "    a.) are shorter than the defined temporal threshold (in units of frames),\n",
    "    OR\n",
    "    b.) the amplitude of the absolute trace does not reach the amplitude threshold during the episode.\n",
    "    Returns the filtered episodes.\n",
    "    \"\"\"\n",
    "    \n",
    "    discard_list = []\n",
    "    for i_episode, episode in enumerate(episodes):  # tuple of (i_begin, i_end). Assume [i_begin:i_end+1] is correct, see get_episodes()\n",
    "        episode_trace = speed_trace[episode[0]:episode[1]+1]\n",
    "        # filter by temporal threshold\n",
    "        if len(episode_trace) < temporal_threshold:\n",
    "            # print(f\"{len(episode_trace)}\")\n",
    "            if i_episode not in discard_list:\n",
    "                discard_list.append(i_episode)\n",
    "        # filter by amplitude threshold\n",
    "        if max(np.abs(episode_trace)) < amplitude_threshold:\n",
    "            if i_episode not in discard_list:\n",
    "                discard_list.append(i_episode)\n",
    "    discard_list = sorted(discard_list)\n",
    "    \n",
    "    # discard components\n",
    "    episodes_filtered = [episodes[i] for i in range(len(episodes)) if i not in discard_list]\n",
    "    return episodes_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44924566",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_manual_bl_am_length = True\n",
    "bl_manual_length = 4425#4500\n",
    "am_manual_length = 4425 #4500\n",
    "\n",
    "\n",
    "# each entry (row) should have columns: \n",
    "# uuid of event, mouse id, window type, segment type (bl/sz/am), segment length in frames, totdist, running, speed\n",
    "list_statistics = []  \n",
    "dict_episodes = {}\n",
    "loco_binary_traces = {}  # contains the post-filtering \"running\" trace, of which the running% is calculated (divided by segment length)\n",
    "loco_episodes = {}  # contains the first and last indices of the locomotion episodes\n",
    "begin_end_frames_dict = {}\n",
    "\n",
    "for event_uuid in traces_dict.keys():\n",
    "    mouse_id = traces_meta_dict[event_uuid][\"mouse_id\"]\n",
    "    win_type = traces_meta_dict[event_uuid][\"window_type\"]\n",
    "    # get segment lengths\n",
    "    n_bl_frames = traces_meta_dict[event_uuid][\"n_bl_frames\"]\n",
    "    n_am_frames = traces_meta_dict[event_uuid][\"n_am_frames\"]\n",
    "    n_frames = traces_meta_dict[event_uuid][\"n_frames\"]\n",
    "    n_sz_frames = n_frames - n_am_frames - n_bl_frames\n",
    "    \n",
    "    if use_manual_bl_am_length:\n",
    "        if (bl_manual_length > n_bl_frames) or (am_manual_length > n_am_frames):\n",
    "            print(f\"{mouse_id} {event_uuid}:\\n\\tNot enough bl ({n_bl_frames}, {bl_manual_length} required) or am ({n_am_frames}, {am_manual_length} required) frames available. Skipping...\")\n",
    "            continue\n",
    "        # todo: set first and last frames for bl and am (as well as sz). If not use_manual_bl_am_length, also set it!\n",
    "        # then modify code below to first and last frames\n",
    "        else:\n",
    "            # define baseline as last frame before sz segment, and starting bl_manual_length frames before\n",
    "            last_frame_bl = n_bl_frames - 1  # 0 indexing: last bl frame, inclusive\n",
    "            first_frame_bl = last_frame_bl - bl_manual_length + 1  # inclusive\n",
    "            print(first_frame_bl)\n",
    "            assert first_frame_bl >= 0\n",
    "            # define aftermath as first frame after sz segment, and ending am_manual_length frames after\n",
    "            first_frame_am = n_bl_frames+n_sz_frames  # inclusive\n",
    "            assert first_frame_am == n_frames - n_am_frames\n",
    "            \n",
    "            last_frame_am = first_frame_am + am_manual_length - 1  # inclusive\n",
    "            \n",
    "            #convert to [begin, end), i.e. left inclusive, right exclusive, for numpy indexing\n",
    "            last_frame_bl += 1\n",
    "            last_frame_am += 1\n",
    "            \n",
    "    else:\n",
    "        first_frame_bl = 0  # inclusive\n",
    "        last_frame_bl = n_bl_frames  # exclusive\n",
    "        \n",
    "        first_frame_am = n_bl_frames+n_sz_frames  # inclusive\n",
    "        last_frame_am = n_frames  # exclusive\n",
    "    \n",
    "    begin_end_frames_dict[event_uuid] = [first_frame_bl, last_frame_bl, first_frame_am, last_frame_am]\n",
    "    \n",
    "    # print(f\"{ddoc.getNikonFileNameForUuid(event_uuid)}:\\n\\t{n_bl_frames} bl, {n_sz_frames} mid, {n_am_frames} am\")\n",
    "    # get movement data\n",
    "    lv_totdist = traces_dict[event_uuid][\"lv_totdist\"]\n",
    "    lv_totdist_abs = traces_dict[event_uuid][\"lv_totdist_abs\"]\n",
    "    lv_running = traces_dict[event_uuid][\"lv_running\"]\n",
    "    lv_speed = traces_dict[event_uuid][\"lv_speed\"]\n",
    "    \n",
    "    # apply post-processing threshold to \"running\"\n",
    "    \n",
    "    # cut up data into segments\n",
    "    lv_totdist_bl = lv_totdist[first_frame_bl:last_frame_bl]\n",
    "    lv_totdist_sz = lv_totdist[last_frame_bl:first_frame_am]\n",
    "    lv_totdist_am = lv_totdist[first_frame_am:last_frame_am]\n",
    "    if not use_manual_bl_am_length:\n",
    "        assert len(lv_totdist_bl) + len(lv_totdist_sz) + len(lv_totdist_am) == len(lv_totdist)\n",
    "    else:\n",
    "        assert len(lv_totdist_bl) == bl_manual_length\n",
    "        assert len(lv_totdist_am) == am_manual_length \n",
    "    \n",
    "    lv_totdist_abs_bl = lv_totdist_abs[first_frame_bl:last_frame_bl]\n",
    "    lv_totdist_abs_sz = lv_totdist_abs[last_frame_bl:first_frame_am]\n",
    "    lv_totdist_abs_am = lv_totdist_abs[first_frame_am:last_frame_am]\n",
    "    \n",
    "    lv_running_bl = lv_running[first_frame_bl:last_frame_bl]\n",
    "    lv_running_sz = lv_running[last_frame_bl:first_frame_am]\n",
    "    lv_running_am = lv_running[first_frame_am:last_frame_am]\n",
    "    \n",
    "    lv_speed_bl = lv_speed[first_frame_bl:last_frame_bl]\n",
    "    lv_speed_sz = lv_speed[last_frame_bl:first_frame_am]\n",
    "    lv_speed_am = lv_speed[first_frame_am:last_frame_am]\n",
    "    \n",
    "    \n",
    "    # calculate statistics\n",
    "    totdist_bl = lv_totdist_bl[-1] - lv_totdist_bl[0]\n",
    "    totdist_sz = lv_totdist_sz[-1] - lv_totdist_sz[0]\n",
    "    totdist_am = lv_totdist_am[-1] - lv_totdist_am[0]\n",
    "    totdist_abs_bl = lv_totdist_abs_bl[-1] - lv_totdist_abs_bl[0]\n",
    "    totdist_abs_sz = lv_totdist_abs_sz[-1] - lv_totdist_abs_sz[0]\n",
    "    totdist_abs_am = lv_totdist_abs_am[-1] - lv_totdist_abs_am[0]\n",
    "\n",
    "    speed_bl = sum(lv_speed_bl)\n",
    "    speed_sz = sum(lv_speed_sz)\n",
    "    speed_am = sum(lv_speed_am)\n",
    "    # calculate average speed\n",
    "    lv_speed_bl = np.array(lv_speed_bl)\n",
    "    lv_speed_sz = np.array(lv_speed_sz)\n",
    "    lv_speed_am = np.array(lv_speed_am)\n",
    "    lv_running_bl = np.array(lv_running_bl)\n",
    "    lv_running_sz = np.array(lv_running_sz)\n",
    "    lv_running_am = np.array(lv_running_am)\n",
    "    # take absolute values!\n",
    "    avg_speed_bl = np.mean(np.abs(lv_speed_bl[lv_running_bl > 0]))\n",
    "    avg_speed_sz = np.mean(np.abs(lv_speed_sz[lv_running_sz > 0]))\n",
    "    avg_speed_am = np.mean(np.abs(lv_speed_am[lv_running_am > 0]))\n",
    "    # take absolute max speed!\n",
    "    max_speed_bl = np.max(np.abs(lv_speed_bl)) #np.median(np.sort(lv_speed_bl)[floor(0.95*len(lv_speed_bl)):])\n",
    "    max_speed_sz = np.max(np.abs(lv_speed_sz)) #np.median(np.sort(lv_speed_sz)[floor(0.95*len(lv_speed_sz)):])\n",
    "    max_speed_am = np.max(np.abs(lv_speed_am)) #np.median(np.sort(lv_speed_am)[floor(0.95*len(lv_speed_am)):])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # number of running episodes, length\n",
    "    list_episodes_bl = get_episodes(lv_running_bl, True, EPISODE_MERGE_THRESHOLD_FRAMES, return_begin_end_frames=True )  # 15 frames in 15 Hz is 1 s.\n",
    "    list_episodes_sz = get_episodes(lv_running_sz, True, EPISODE_MERGE_THRESHOLD_FRAMES, return_begin_end_frames=True)\n",
    "    list_episodes_am = get_episodes(lv_running_am, True, EPISODE_MERGE_THRESHOLD_FRAMES,  return_begin_end_frames=True)\n",
    "    \n",
    "    # apply a filter to episodes, discard those that do not fulfill the criteria\n",
    "    list_episodes_bl = apply_threshold(lv_speed_bl, list_episodes_bl, TEMP_THRESHOLD, AMPL_THRESHOLD, )\n",
    "    list_episodes_sz = apply_threshold(lv_speed_sz, list_episodes_sz, TEMP_THRESHOLD, AMPL_THRESHOLD, )\n",
    "    list_episodes_am = apply_threshold(lv_speed_am, list_episodes_am, TEMP_THRESHOLD, AMPL_THRESHOLD, )\n",
    "    \n",
    "    # get the episode lengths and number of episodes\n",
    "    list_episode_lengths_bl = [ep[1]-ep[0] + 1 for ep in list_episodes_bl]\n",
    "    n_episodes_bl = len(list_episodes_bl)\n",
    "    \n",
    "    list_episode_lengths_sz = [ep[1]-ep[0] + 1 for ep in list_episodes_sz]\n",
    "    n_episodes_sz = len(list_episode_lengths_sz)\n",
    "    \n",
    "    list_episode_lengths_am = [ep[1]-ep[0] + 1 for ep in list_episodes_am]\n",
    "    n_episodes_am = len(list_episode_lengths_am)\n",
    "    \n",
    "    # apply filtering to \"running\" signal\n",
    "    \n",
    "    filtered_running_bl = np.zeros(len(lv_running_bl), dtype=lv_running_bl.dtype)\n",
    "    filtered_running_sz = np.zeros(len(lv_running_sz), dtype=lv_running_sz.dtype)\n",
    "    filtered_running_am = np.zeros(len(lv_running_am), dtype=lv_running_am.dtype)\n",
    "    # add zeros before and after segments to match original recording length\n",
    "    filtered_running_prebl = np.zeros(first_frame_bl, dtype=lv_running_bl.dtype)\n",
    "    filtered_running_postam = np.zeros(len(lv_totdist) - last_frame_am, dtype=lv_running_am.dtype)\n",
    "    \n",
    "    for episode in list_episodes_bl:\n",
    "        filtered_running_bl[episode[0]:episode[1]+1] = 1\n",
    "    for episode in list_episodes_sz:\n",
    "        filtered_running_sz[episode[0]:episode[1]+1] = 1\n",
    "    for episode in list_episodes_am:\n",
    "        filtered_running_am[episode[0]:episode[1]+1] = 1\n",
    "    \n",
    "    \n",
    "    # create \"running\" statistic, using filtered data\n",
    "    running_bl = np.sum(filtered_running_bl)  # np.sum(lv_running_bl)\n",
    "    running_sz = np.sum(filtered_running_sz)  # np.sum(lv_running_sz)\n",
    "    running_am = np.sum(filtered_running_am)  # np.sum(lv_running_am)\n",
    "    \n",
    "    loco_binary_traces[event_uuid] = np.concatenate([filtered_running_prebl, filtered_running_bl, filtered_running_sz, filtered_running_am, filtered_running_postam])\n",
    "    assert len(loco_binary_traces[event_uuid]) == len(lv_totdist)\n",
    "    \n",
    "    # as running already has a built-in merging (see Matlab beltAddRunningProperties.m), we can count the leading edges in that data\n",
    "    #n_episodes_bl2 = sum((lv_running_bl[1:] - lv_running_bl[:-1]) > 0)\n",
    "    #n_episodes_sz2 = sum((lv_running_sz[1:] - lv_running_sz[:-1]) > 0)\n",
    "    #n_episodes_am2 = sum((lv_running_am[1:] - lv_running_am[:-1]) > 0)\n",
    "    \n",
    "    #print(f\"bl: {n_episodes_bl} vs {n_episodes_bl2}, sz: {n_episodes_sz} vs {n_episodes_sz2}, am: {n_episodes_am} vs {n_episodes_am2}\")\n",
    "    \n",
    "    \n",
    "    # add to episodes dict\n",
    "    if mouse_id not in dict_episodes.keys():\n",
    "        dict_episodes[mouse_id] = dict()\n",
    "    dict_episodes[mouse_id][event_uuid] = dict()\n",
    "\n",
    "    list_episode_lengths_bl = np.array(list_episode_lengths_bl)\n",
    "    list_episode_lengths_sz = np.array(list_episode_lengths_sz)\n",
    "    list_episode_lengths_am = np.array(list_episode_lengths_am)\n",
    "    \n",
    "    dict_episodes[mouse_id][event_uuid][\"bl\"] = list_episode_lengths_bl\n",
    "    dict_episodes[mouse_id][event_uuid][\"sz\"] = list_episode_lengths_sz\n",
    "    dict_episodes[mouse_id][event_uuid][\"am\"] = list_episode_lengths_am\n",
    "    \n",
    "    # calculate mean episode length, std\n",
    "    bl_episode_mean_len = list_episode_lengths_bl.mean() if len(list_episode_lengths_bl) > 0 else 0\n",
    "    sz_episode_mean_len = list_episode_lengths_sz.mean() if len(list_episode_lengths_sz) > 0 else 0\n",
    "    am_episode_mean_len = list_episode_lengths_am.mean() if len(list_episode_lengths_am) > 0 else 0\n",
    "    \n",
    "    bl_episode_std = list_episode_lengths_bl.std()\n",
    "    sz_episode_std = list_episode_lengths_sz.std()\n",
    "    am_episode_std = list_episode_lengths_am.std()\n",
    "    \n",
    "    \n",
    "    if \"exp_type\" in traces_meta_dict[event_uuid].keys():\n",
    "        exp_type = traces_meta_dict[event_uuid][\"exp_type\"]\n",
    "    else:\n",
    "        exp_type = \"tmev\"\n",
    "        \n",
    "    segment_length_bl = last_frame_bl - first_frame_bl\n",
    "    segment_length_sz = first_frame_am - last_frame_bl\n",
    "    segment_length_am = last_frame_am - first_frame_am\n",
    "        \n",
    "    # add to data list\n",
    "    list_statistics.append([event_uuid, mouse_id, win_type, exp_type, \"bl\", segment_length_bl, totdist_bl, totdist_abs_bl, running_bl, speed_bl, avg_speed_bl, n_episodes_bl, bl_episode_mean_len, bl_episode_std, max_speed_bl, ])\n",
    "    list_statistics.append([event_uuid, mouse_id, win_type, exp_type, \"sz\", segment_length_sz, totdist_sz, totdist_abs_sz, running_sz, speed_sz, avg_speed_sz, n_episodes_sz, sz_episode_mean_len, sz_episode_std, max_speed_sz, ])\n",
    "    list_statistics.append([event_uuid, mouse_id, win_type, exp_type, \"am\", segment_length_am, totdist_am, totdist_abs_am, running_am, speed_am, avg_speed_am, n_episodes_am, am_episode_mean_len, am_episode_std, max_speed_am, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535694c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(data=list_statistics, columns=[\"event_uuid\", \"mouse_id\", \"window_type\", \"exp_type\", \"segment_type\",  \"segment_length\", \"totdist\", \"totdist_abs\", \"running\", \"speed\", \"avg_speed\", \"running_episodes\", \"running_episodes_mean_length\", \"running_episodes_length_std\", \"max_speed\", ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeb03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set NaN to 0 (running_episodes_mean_length: if no episodes, then mean segment length is 0)\n",
    "df_stats[\"running_episodes_mean_length\"] = df_stats[\"running_episodes_mean_length\"].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af82b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a scale factor for better readability: 0.000513 -> 51.3, for example\n",
    "if \"n_bl_frames\" in locals():\n",
    "    scale_factor = n_bl_frames  # scale up to bl segment length \n",
    "else:\n",
    "    scale_factor = 10000\n",
    "\n",
    "df_stats[\"totdist_norm\"] = scale_factor*df_stats[\"totdist\"]/df_stats[\"segment_length\"]\n",
    "df_stats[\"totdist_abs_norm\"] = scale_factor*df_stats[\"totdist_abs\"]/df_stats[\"segment_length\"]\n",
    "df_stats[\"running_norm\"] = scale_factor*df_stats[\"running\"]/df_stats[\"segment_length\"]\n",
    "df_stats[\"speed_norm\"] = scale_factor*df_stats[\"speed\"]/df_stats[\"segment_length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec3363d",
   "metadata": {},
   "source": [
    "### Add % of time spent running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d9f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of time spent running\n",
    "df_stats[\"running%\"] = 100.*df_stats[\"running\"]/df_stats[\"segment_length\"]  # get value as true % instead of [0, 1] float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da4f70",
   "metadata": {},
   "source": [
    "### Replace NaN by 0 in average speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[\"avg_speed\"] = df_stats[\"avg_speed\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f89db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_stats[\"avg_speed\"].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8350fa",
   "metadata": {},
   "source": [
    "### Add  color codes to entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706fa48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[\"color\"] = df_stats.apply(lambda row: dict_colors_mouse[row[\"mouse_id\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_colors_event = df_stats[[\"event_uuid\", \"color\"]].to_dict(orient=\"list\")\n",
    "dict_colors_event = dict(zip(dict_colors_event[\"event_uuid\"], dict_colors_event[\"color\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d57df",
   "metadata": {},
   "source": [
    "## Standardize window type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aaba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[\"window_type\"] = df_stats[\"window_type\"].replace({\"Cx\" : \"NC\", \"ca1\": \"CA1\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732725dc",
   "metadata": {},
   "source": [
    "## Create per-mouse means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0650038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_mouse_mean = df_stats.drop(columns=[\"event_uuid\", \"window_type\", \"color\"], axis=0).groupby([\"mouse_id\", \"exp_type\", \"segment_type\"]).agg(func=\"mean\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d913c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_mouse_mean[\"window_type\"] = df_stats_per_mouse_mean.apply(lambda row: ddoc.getMouseWinInjInfo(row[\"mouse_id\"]).iloc[0].window_type, axis=1)\n",
    "df_stats_per_mouse_mean[\"color\"] = df_stats_per_mouse_mean.apply(lambda row: df_colors[df_colors[\"mouse_id\"] == row[\"mouse_id\"]].iloc[0].color, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeade0d6",
   "metadata": {},
   "source": [
    "### For the mouse aggregate data, create an identifier unique for the mouse ID + experiment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_mouse_mean[\"mouse_id_exp_type\"] = df_stats_per_mouse_mean[\"mouse_id\"] + \" \" + df_stats_per_mouse_mean[\"exp_type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56ecd7",
   "metadata": {},
   "source": [
    "### Experiment type-related quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8944d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_exp_types = len(df_stats.exp_type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_types = df_stats.exp_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08056e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[df_stats[\"segment_type\"]== \"bl\"].groupby(\"exp_type\").event_uuid.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628af860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[df_stats[\"segment_type\"]== \"bl\"].groupby(\"mouse_id\").event_uuid.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a083849b",
   "metadata": {},
   "source": [
    "# 1. TMEV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba4f81",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe3b4ec",
   "metadata": {},
   "source": [
    "## Introduce mapping shorthand notation to proper names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_chr2 and not is_bilat:\n",
    "    value_mapping = {\"bl\":\"baseline\", \"sz\": \"seizure\", \"am\":\"post-seizure\"}\n",
    "    df_stats[\"segment_type\"] = df_stats[\"segment_type\"].apply(lambda x: value_mapping[x])\n",
    "    df_stats_ca1 = df_stats[df_stats[\"window_type\"] == \"CA1\"]\n",
    "    df_stats_nc = df_stats[df_stats[\"window_type\"] == \"NC\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e11b8",
   "metadata": {},
   "source": [
    "## Plot individual recordings, color-coded by mouse ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66560d",
   "metadata": {},
   "source": [
    "### Plot all possible metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf62480",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_chr2 and not is_bilat:\n",
    "    df_stats_only_bl_am = df_stats[df_stats[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_chr2 and not is_bilat:\n",
    "    df_stats_only_bl_am[df_stats_only_bl_am[\"segment_type\"].isin([value_mapping[\"am\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_chr2 and not is_bilat:\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(32,20))\n",
    "    sns.lineplot(data=df_stats_only_bl_am, x=\"segment_type\", y=\"totdist_abs\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[0][0],  linestyle=\"-\", marker=\"o\", markersize=13, linewidth=1, legend=False)\n",
    "    sns.despine(left=True, bottom=True, top=True, right=True)\n",
    "    axs[0][0].set(xlabel='Segment', ylabel='Total (absolute) distance, a.u.')\n",
    "\n",
    "    sns.lineplot(data=df_stats_only_bl_am, x=\"segment_type\", y=\"running%\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[0][1],  linestyle=\"-\", marker=\"o\", markersize=13, linewidth=1,  legend=False)\n",
    "    axs[0][1].set(xlabel='Segment', ylabel='% of time spent with locomotion')\n",
    "\n",
    "    sns.lineplot(data=df_stats_only_bl_am, x=\"segment_type\", y=\"running_episodes\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[0][2],  linestyle=\"-\", marker=\"o\", markersize=13, linewidth=1,  legend=False)\n",
    "    axs[0][2].set(xlabel='Segment', ylabel='Number of running episodes')\n",
    "\n",
    "    sns.lineplot(data=df_stats_only_bl_am, x=\"segment_type\", y=\"avg_speed\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[1][0],  linestyle=\"-\", marker=\"o\", markersize=13, linewidth=1,  legend=False)\n",
    "    axs[1][0].set(xlabel='Segment', ylabel='Average of locomotion velocity')\n",
    "\n",
    "    sns.lineplot(data=df_stats_only_bl_am, x=\"segment_type\", y=\"running_episodes_mean_length\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[1][1],  linestyle=\"-\", marker=\"o\", markersize=13, linewidth=1,  legend=False)\n",
    "    axs[1][1].set(xlabel='Segment', ylabel='Mean length of running episodes, a.u.')\n",
    "\n",
    "    sns.lineplot(data=df_stats_only_bl_am, x=\"segment_type\", y=\"max_speed\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[1][2],  linestyle=\"-\", marker=\"o\", markersize=13, linewidth=1,  legend=False)\n",
    "    axs[1][2].set(xlabel='Segment', ylabel='Max velocity of locomotion, a.u.')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs:\n",
    "        fig_fpath = os.path.join(output_folder, f'loco_tmev_{output_dtime}{file_format}')\n",
    "        plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "        print(f\"Saved to {fig_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1e2b06",
   "metadata": {},
   "source": [
    "### Plot 3 metrics along with individual points, violin plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef55809",
   "metadata": {},
   "source": [
    "## Aggregate by mouse\n",
    "estimator='mean', errorbar=('ci', 95) are the default statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_chr2 and not is_bilat:\n",
    "    df_stats_per_mouse_mean[\"segment_type\"] = df_stats_per_mouse_mean[\"segment_type\"].apply(lambda x: value_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1354c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_chr2 and not is_bilat:\n",
    "    df_stats_per_mouse_mean_only_bl_am = df_stats_per_mouse_mean[df_stats_per_mouse_mean[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_chr2 and not is_bilat:\n",
    "    df_stats_per_mouse_mean_only_bl_am = df_stats_per_mouse_mean_only_bl_am.sort_values(by=[\"mouse_id\", \"exp_type\", \"segment_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6740f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_chr2 and not is_bilat:\n",
    "    if n_exp_types > 1:\n",
    "        n_exp_types = len( df_stats_per_mouse_mean.exp_type.unique())\n",
    "        fig, axs = plt.subplots(n_exp_types, 6, figsize=(32,10*n_exp_types))\n",
    "    else:\n",
    "        n_exp_types = 1\n",
    "        n_cols = 3\n",
    "        n_rows = 2\n",
    "        fig, axs = plt.subplots(n_rows, n_cols, figsize=(32,20))\n",
    "    for i_exp_type, exp_type in enumerate(df_stats_per_mouse_mean_only_bl_am.exp_type.unique()):\n",
    "        df_exp_type = df_stats_per_mouse_mean_only_bl_am[(df_stats_per_mouse_mean_only_bl_am[\"exp_type\"] == exp_type)]\n",
    "        #print(len(df_exp_type.mouse_id.unique()))\n",
    "        if n_exp_types > 1:\n",
    "            for i in range(len(dict_metric_label.keys())):\n",
    "                axs[i_exp_type][i].set_title(f\"{exp_type}\")\n",
    "            \n",
    "            for i, (metric, label) in enumerate(dict_metric_label.items()):\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=metric, hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][i], marker=\"o\", markersize=20, legend=False)\n",
    "                axs[i_exp_type][i].set(xlabel='Segment', ylabel=label)\n",
    "        else:\n",
    "            for i in range(len(axs)):\n",
    "                for j in range(len(axs[i])):\n",
    "                    axs[i][j].set_title(f\"{exp_type}\")\n",
    "\n",
    "            for i, (metric, label) in enumerate(dict_metric_label.items()):\n",
    "                i_row = i//n_cols\n",
    "                i_col = i%n_cols\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=metric, hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_row][i_col], marker=\"o\", markersize=20, legend=False)\n",
    "                axs[i_row][i_col].set(xlabel='Segment', ylabel=label)        \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs:\n",
    "        fig_fpath = os.path.join(output_folder, f'loco_tmev_aggregate_{output_dtime}{file_format}')\n",
    "        plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "        print(f\"Saved to {fig_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc650ae",
   "metadata": {},
   "source": [
    "# 2. ChR2 (bl - stim - (Sz) - am protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355b092",
   "metadata": {},
   "source": [
    "### Rename bl -> baseline, am -> post-stimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chr2 or is_bilat:\n",
    "    value_mapping = {\"bl\":\"baseline\", \"sz\": \"stimulation\", \"am\":\"post-stimulation\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chr2 or is_bilat:\n",
    "    df_stats[\"segment_type\"] = df_stats[\"segment_type\"].apply(lambda x: value_mapping[x])\n",
    "    df_stats_per_mouse_mean[\"segment_type\"] = df_stats_per_mouse_mean[\"segment_type\"].apply(lambda x: value_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chr2 or is_bilat:\n",
    "    df_stats_only_bl_am = df_stats[df_stats[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d96c0a",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d7c67",
   "metadata": {},
   "source": [
    "### Plot each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401fac80",
   "metadata": {},
   "source": [
    "### Plot for CA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aaa02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_ca1 = df_stats[df_stats[\"window_type\"] == \"CA1\"]\n",
    "if len(df_stats_ca1) > 0:\n",
    "    n_exp_types = len( df_stats_ca1.exp_type.unique())\n",
    "    window_type = \"CA1\"\n",
    "    if n_exp_types > 1 :\n",
    "        fig, axs = plt.subplots(n_exp_types, 6, figsize=(42,8*n_exp_types))\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#i_exp_type, exp_type in enumerate(df_stats_ca1.exp_type.unique()):\n",
    "            df_exp_type = df_stats_only_bl_am[(df_stats_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_only_bl_am[\"window_type\"] == \"CA1\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            for i in range(len(axs[i_exp_type])):\n",
    "                axs[i_exp_type][i].set_title(f\"{exp_type}\")\n",
    "            for metric, label in dict_metric_label.items():\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"totdist_abs_norm\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][0], marker=\"o\", markersize=20, legend=False)\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running%\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][1], marker=\"o\", markersize=20, legend=False)\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][2], marker=\"o\", markersize=20, legend=False)\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"avg_speed\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][3], marker=\"o\", markersize=20, legend=False)\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes_mean_length\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][4], marker=\"o\", markersize=20, legend=False)\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"max_speed\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][5], marker=\"o\", markersize=20, legend=False)\n",
    "    else:  # 1 type\n",
    "        fig, axs = plt.subplots(1, 6, figsize=(42,8*n_exp_types))\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#i_exp_type, exp_type in enumerate(df_stats_ca1.exp_type.unique()):\n",
    "            df_exp_type = df_stats_only_bl_am[(df_stats_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_only_bl_am[\"window_type\"] == \"CA1\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            for i in range(len(axs)):\n",
    "                axs[i].set_title(f\"{exp_type}\")\n",
    "            for i, (metric, label) in enumerate(dict_metric_label.items()):\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=metric, hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i], marker=\"o\", markersize=20, legend=False)\n",
    "                axs[i].set(xlabel='Segment', ylabel=label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs:\n",
    "        fig_fpath = os.path.join(output_folder, f'loco_{dataset_type}_{window_type.lower()}_{output_dtime}{file_format}')\n",
    "        plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "        print(f\"Saved to {fig_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38f3fe",
   "metadata": {},
   "source": [
    "### Plot for NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03708c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_nc = df_stats[df_stats[\"window_type\"] == \"NC\"]\n",
    "if len(df_stats_nc) > 0:\n",
    "    n_cols = len(dict_metric_label.keys())\n",
    "    n_exp_types = len(df_stats_nc.exp_type.unique())\n",
    "    if n_exp_types > 1:\n",
    "        fig, axs = plt.subplots(n_exp_types, n_cols, figsize=(42,8*n_exp_types))\n",
    "\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_nc.exp_type.unique()):\n",
    "            df_exp_type = df_stats_only_bl_am[(df_stats_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_only_bl_am[\"window_type\"] == \"NC\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            for i in range(n_cols):\n",
    "                axs[i_exp_type][i].set_title(f\"{exp_type}\")\n",
    "\n",
    "            for i, (metric, label) in enumerate(dict_metric_label.items()):\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=metric, hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][i], marker=\"o\", markersize=20, legend=False)\n",
    "                axs[i_exp_type][i].set(xlabel='Segment', ylabel=label)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 6, figsize=(42,8*n_exp_types))\n",
    "\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_nc.exp_type.unique()):\n",
    "            df_exp_type = df_stats_only_bl_am[(df_stats_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_only_bl_am[\"window_type\"] == \"NC\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            for i in range(n_cols):\n",
    "                axs[i].set_title(f\"{exp_type}\")\n",
    "\n",
    "            for i, (metric, label) in enumerate(dict_metric_label.items()):\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=metric, hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[0], marker=\"o\", markersize=20, legend=False)\n",
    "                axs[0].set(xlabel='Segment', ylabel=label)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs:\n",
    "        fig_fpath = os.path.join(output_folder, f'loco_{dataset_type}_nc_{output_dtime}{file_format}')\n",
    "        plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "        print(f\"Saved to {fig_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ba30b",
   "metadata": {},
   "source": [
    "## No window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50abe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_nowin = df_stats[df_stats[\"window_type\"] == \"None\"]\n",
    "if len(df_stats_nowin) > 0:\n",
    "    n_exp_types = len(df_stats_nowin.exp_type.unique())\n",
    "    if n_exp_types > 1:\n",
    "        fig, axs = plt.subplots(n_exp_types, 6, figsize=(42,8*n_exp_types))\n",
    "\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_nc.exp_type.unique()):\n",
    "            df_exp_type = df_stats_only_bl_am[(df_stats_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_only_bl_am[\"window_type\"] == \"None\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            axs[i_exp_type][0].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][1].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][2].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][3].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][4].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][5].set_title(f\"{exp_type}\")\n",
    "\n",
    "\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"totdist_abs_norm\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][0], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running%\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][1], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][2], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"avg_speed\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][3], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes_mean_length\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][4], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"max_speed\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[i_exp_type][5], marker=\"o\", markersize=20, legend=False)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 6, figsize=(42,8*n_exp_types))\n",
    "\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_nc.exp_type.unique()):\n",
    "            df_exp_type = df_stats_only_bl_am[(df_stats_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_only_bl_am[\"window_type\"] == \"None\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            axs[0].set_title(f\"{exp_type}\")\n",
    "            axs[1].set_title(f\"{exp_type}\")\n",
    "            axs[2].set_title(f\"{exp_type}\")\n",
    "            axs[3].set_title(f\"{exp_type}\")\n",
    "            axs[4].set_title(f\"{exp_type}\")\n",
    "            axs[5].set_title(f\"{exp_type}\")\n",
    "\n",
    "\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"totdist_abs_norm\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[0], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running%\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[1], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[2], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"avg_speed\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[3], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes_mean_length\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[4], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"max_speed\", hue=\"event_uuid\", palette=dict_colors_event, estimator=None, ax=axs[5], marker=\"o\", markersize=20, legend=False)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs:\n",
    "        fig_fpath = os.path.join(output_folder, f'loco_{dataset_type}_nowin_{output_dtime}{file_format}')\n",
    "        plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "        print(f\"Saved to {fig_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5902ca0",
   "metadata": {},
   "source": [
    "# Mouse-aggregate\n",
    "i.e. mean per mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2766818d",
   "metadata": {},
   "source": [
    "## CA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_mouse_mean_ca1 = df_stats_per_mouse_mean[df_stats_per_mouse_mean[\"window_type\"] == \"CA1\"]\n",
    "#df_stats_per_mouse_mean_ca1[\"segment_type\"] = df_stats_per_mouse_mean_ca1[\"segment_type\"].apply(lambda x: value_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_mouse_mean_ca1_only_bl_am = df_stats_per_mouse_mean_ca1[df_stats_per_mouse_mean_ca1[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00135d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_mouse_mean_ca1_only_bl_am = df_stats_per_mouse_mean_ca1_only_bl_am.sort_values(by=[\"mouse_id\", \"exp_type\", \"segment_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_exp_types = len( df_stats_per_mouse_mean_ca1.exp_type.unique())\n",
    "if len(df_stats_per_mouse_mean_ca1) > 0:\n",
    "    n_cols = len(dict_metric_label.keys())\n",
    "    if n_exp_types > 1:\n",
    "        fig, axs = plt.subplots(n_exp_types, n_cols, figsize=(42,8*n_exp_types))\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_per_mouse_mean_ca1_only_bl_am.exp_type.unique()):\n",
    "            df_exp_type = df_stats_per_mouse_mean_ca1_only_bl_am[(df_stats_per_mouse_mean_ca1_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_per_mouse_mean_ca1_only_bl_am[\"window_type\"] == \"CA1\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            for i in range(n_cols):\n",
    "                axs[i_exp_type][i].set_title(f\"{exp_type}\", fontsize=30)\n",
    "            for i, (metric, label) in enumerate(dict_metric_label.items()):\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=metric, hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][i], marker=\"o\", markersize=20, legend=False)\n",
    "                axs[i_exp_type][0].set(xlabel='Segment', ylabel=label)\n",
    "    else:  # 1 experiment type (assumed n_exp_types > 0)\n",
    "        fig, axs = plt.subplots(1, 6, figsize=(42,8*n_exp_types))\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_per_mouse_mean_ca1_only_bl_am.exp_type.unique()):\n",
    "            df_exp_type = df_stats_per_mouse_mean_ca1_only_bl_am[(df_stats_per_mouse_mean_ca1_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_per_mouse_mean_ca1_only_bl_am[\"window_type\"] == \"CA1\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            axs[0].set_title(f\"{exp_type}\", fontsize=30)\n",
    "            axs[1].set_title(f\"{exp_type}\")\n",
    "            axs[2].set_title(f\"{exp_type}\")\n",
    "            axs[3].set_title(f\"{exp_type}\")\n",
    "            axs[4].set_title(f\"{exp_type}\")\n",
    "            axs[5].set_title(f\"{exp_type}\")\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"totdist_abs_norm\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[0], marker=\"o\", markersize=20, legend=False)\n",
    "            axs[0].set(xlabel='Segment', ylabel='Total (absolute) distance, a.u.')\n",
    "            \n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running%\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[1], marker=\"o\", markersize=20, legend=False)\n",
    "            axs[1].set(xlabel='Segment', ylabel='% of time spent with locomotion')\n",
    "            \n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[2], marker=\"o\", markersize=20, legend=False)\n",
    "            axs[2].set(xlabel='Segment', ylabel='Number of running episodes')\n",
    "            \n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"avg_speed\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[3], marker=\"o\", markersize=20, legend=False)\n",
    "            axs[3].set(xlabel='Segment', ylabel='Average of locomotion velocity')\n",
    "            \n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes_mean_length\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[4], marker=\"o\", markersize=20, legend=False)\n",
    "            axs[4].set(xlabel='Segment', ylabel='Mean length of running episodes, a.u.')\n",
    "            \n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"max_speed\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[5], marker=\"o\", markersize=20, legend=False)\n",
    "            axs[5].set(xlabel='Segment', ylabel='Max velocity of locomotion, a.u.')\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_figs:\n",
    "            fig_fpath = os.path.join(output_folder, f'loco_{dataset_type}_aggregate_ca1_{output_dtime}{file_format}')\n",
    "            plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "            print(f\"Saved to {fig_fpath}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3b303",
   "metadata": {},
   "source": [
    "## NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_stats_nc) > 0:\n",
    "    df_stats_per_mouse_mean_nc = df_stats_per_mouse_mean[df_stats_per_mouse_mean[\"window_type\"] == \"NC\"]\n",
    "    # df_stats_per_mouse_mean_nc[\"segment_type\"] = df_stats_per_mouse_mean_nc[\"segment_type\"].apply(lambda x: value_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f022540",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_stats_nc) > 0:\n",
    "    df_stats_per_mouse_mean_nc_only_bl_am = df_stats_per_mouse_mean_nc[df_stats_per_mouse_mean_nc[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e74b0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_stats_nc) > 0:\n",
    "    df_stats_per_mouse_mean_nc_only_bl_am = df_stats_per_mouse_mean_nc_only_bl_am.sort_values(by=[\"mouse_id\", \"exp_type\", \"segment_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_stats_nc) > 0:\n",
    "    n_exp_types = len( df_stats_per_mouse_mean_nc.exp_type.unique())\n",
    "    n_cols = len(dict_metric_label.keys())\n",
    "    if n_exp_types > 1:\n",
    "        \n",
    "        fig, axs = plt.subplots(n_exp_types, n_cols, figsize=(42,8*n_exp_types))\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_per_mouse_mean_nc.exp_type.unique()):\n",
    "            df_exp_type = df_stats_per_mouse_mean_nc_only_bl_am[(df_stats_per_mouse_mean_nc_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_per_mouse_mean_nc_only_bl_am[\"window_type\"] == \"NC\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            for i in range(n_cols):\n",
    "                axs[i_exp_type][i].set_title(f\"{exp_type}\")\n",
    "            for i, (metric, label) in enumerate(dict_metric_label.items()):\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=metric, hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][i], marker=\"o\", markersize=20, legend=False)\n",
    "                axs[i_exp_type][i].set(xlabel='Segment', ylabel=label)\n",
    "    else:  # n_exp_types = 1 ( > 0 assumed)\n",
    "        fig, axs = plt.subplots(n_exp_types, n_cols, figsize=(42,8))\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_per_mouse_mean_nc.exp_type.unique()):\n",
    "            df_exp_type = df_stats_per_mouse_mean_nc_only_bl_am[(df_stats_per_mouse_mean_nc_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_per_mouse_mean_nc_only_bl_am[\"window_type\"] == \"NC\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            for i in range(n_cols):\n",
    "                axs[i].set_title(f\"{exp_type}\")\n",
    "\n",
    "            for i, (metric, label) in enumerate(dict_metric_label.items()):\n",
    "                sns.lineplot(data=df_exp_type, x=\"segment_type\", y=metric, hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i], marker=\"o\", markersize=20, legend=False)\n",
    "                axs[i].set(xlabel='Segment', ylabel=label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs:\n",
    "        fig_fpath = os.path.join(output_folder, f'loco_{dataset_type}_aggregate_nc_{output_dtime}{file_format}')\n",
    "        plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "        print(f\"Saved to {fig_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5dca4",
   "metadata": {},
   "source": [
    "### No window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf5e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_stats_nowin)>0:\n",
    "    df_stats_per_mouse_mean_nowin = df_stats_per_mouse_mean[df_stats_per_mouse_mean[\"window_type\"] == \"None\"]\n",
    "    df_stats_per_mouse_mean_nowin_only_bl_am = df_stats_per_mouse_mean_nowin[df_stats_per_mouse_mean_nowin[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])]\n",
    "    df_stats_per_mouse_mean_nowin_only_bl_am = df_stats_per_mouse_mean_nowin_only_bl_am.sort_values(by=[\"mouse_id\", \"exp_type\", \"segment_type\"])\n",
    "\n",
    "if len(df_stats_nowin) > 0:\n",
    "    n_exp_types = len( df_stats_per_mouse_mean_nowin.exp_type.unique())\n",
    "    if n_exp_types > 1:\n",
    "        fig, axs = plt.subplots(n_exp_types, 6, figsize=(42,8*n_exp_types))\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_per_mouse_mean_nc.exp_type.unique()):\n",
    "            df_exp_type = df_stats_per_mouse_mean_nowin_only_bl_am[(df_stats_per_mouse_mean_nowin_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_per_mouse_mean_nowin_only_bl_am[\"window_type\"] == \"None\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            axs[i_exp_type][0].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][1].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][2].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][3].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][4].set_title(f\"{exp_type}\")\n",
    "            axs[i_exp_type][5].set_title(f\"{exp_type}\")\n",
    "\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"totdist_abs_norm\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][0], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running%\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][1], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][2], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"avg_speed\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][3], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes_mean_length\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][4], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"max_speed\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[i_exp_type][5], marker=\"o\", markersize=20, legend=False)\n",
    "    else:  # n_exp_types = 1 ( > 0 assumed)\n",
    "        fig, axs = plt.subplots(n_exp_types, 6, figsize=(42,8))\n",
    "        for i_exp_type, exp_type in enumerate(exp_types):#enumerate(df_stats_per_mouse_mean_nc.exp_type.unique()):\n",
    "            df_exp_type = df_stats_per_mouse_mean_nowin_only_bl_am[(df_stats_per_mouse_mean_nowin_only_bl_am[\"exp_type\"] == exp_type) & (df_stats_per_mouse_mean_nc_only_bl_am[\"window_type\"] == \"None\")]\n",
    "            #print(len(df_exp_type.mouse_id.unique()))\n",
    "            axs[0].set_title(f\"{exp_type}\")\n",
    "            axs[1].set_title(f\"{exp_type}\")\n",
    "            axs[2].set_title(f\"{exp_type}\")\n",
    "            axs[3].set_title(f\"{exp_type}\")\n",
    "            axs[4].set_title(f\"{exp_type}\")\n",
    "            axs[5].set_title(f\"{exp_type}\")\n",
    "\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"totdist_abs_norm\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[0], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running%\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[1], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[2], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"avg_speed\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[3], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"running_episodes_mean_length\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[4], marker=\"o\", markersize=20, legend=False)\n",
    "            sns.lineplot(data=df_exp_type, x=\"segment_type\", y=\"max_speed\", hue=\"mouse_id\", palette=dict_colors_mouse, estimator=None, ax=axs[5], marker=\"o\", markersize=20, legend=False)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_figs:\n",
    "        fig_fpath = os.path.join(output_folder, f'loco_{dataset_type}_aggregate_nowin_{output_dtime}{file_format}')\n",
    "        plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "        print(f\"Saved to {fig_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42602fd7",
   "metadata": {},
   "source": [
    "# Plot pre-post differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6320d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_props = {\n",
    "    'boxprops':{'edgecolor':'black'},\n",
    "    'medianprops':{'color':'black'},\n",
    "    'whiskerprops':{'color':'black'},\n",
    "    'capprops':{'color':'black'}\n",
    "}\n",
    "l_dfs = []\n",
    "def plot_differences(df_stat_data):\n",
    "    # in each row, plot for each exp_type the given metric. Plot different metric each row.\n",
    "    # pre/post values might be paired by event_uuid (individual sessions) or mouse_id (aggregate).\n",
    "    group_by_colname = \"event_uuid\"\n",
    "    if group_by_colname not in df_stat_data.columns:\n",
    "        group_by_colname = \"mouse_id\"\n",
    "    df_plot_dset = None\n",
    "    if len(df_stat_data) > 0:\n",
    "        n_window_types = len(df_stat_data.window_type.unique())\n",
    "        n_exp_types = len(df_stat_data.exp_type.unique())\n",
    "        fig, axs = plt.subplots(len(STAT_METRICS), 1, figsize=(4*(n_window_types + n_exp_types - 1), 10*len(STAT_METRICS)))\n",
    "        for i, metric in enumerate(STAT_METRICS):  # fill each row\n",
    "            if group_by_colname == \"event_uuid\":\n",
    "                df_metric_pivot = df_stat_data.pivot(columns=\"segment_type\", index=group_by_colname, values=metric).reset_index()\n",
    "            else:  # mouse_id may not be unique (multiple experiment types, like chr2_ctl, chr2_sd, for one mouse)\n",
    "                df_metric_pivot = df_stat_data.pivot(columns=\"segment_type\", index=[group_by_colname, \"exp_type\"], values=metric).reset_index()\n",
    "            # 1 window per mouse\n",
    "            df_metric_pivot[\"window_type\"] = df_metric_pivot.apply(lambda row: df_stat_data[df_stat_data[group_by_colname] == row[group_by_colname]].window_type.iloc[0], axis=1)   \n",
    "            if \"exp_type\" not in df_metric_pivot.columns:\n",
    "                df_metric_pivot[\"exp_type\"] = df_metric_pivot.apply(lambda row: df_stat_data[df_stat_data[group_by_colname] == row[group_by_colname]].exp_type.iloc[0], axis=1)   \n",
    "            metric_diff_name = f\"delta_{metric}\"\n",
    "            df_metric_pivot[metric_diff_name] = df_metric_pivot[value_mapping[\"am\"]] - df_metric_pivot[value_mapping[\"bl\"]]\n",
    "            # only keep the change (delta), drop the quantities themselves\n",
    "            df_metric_pivot = df_metric_pivot.drop([value_mapping[\"bl\"], value_mapping[\"sz\"], value_mapping[\"am\"]], axis=1)\n",
    "            l_dfs.append(df_metric_pivot)\n",
    "            if df_plot_dset is None:\n",
    "                df_plot_dset = df_metric_pivot\n",
    "            else:\n",
    "                df_plot_dset = df_plot_dset.merge(df_metric_pivot, on=[group_by_colname, \"window_type\", \"exp_type\"])\n",
    "            sns.boxplot(data=df_metric_pivot, x=\"exp_type\", y=metric_diff_name, hue=\"window_type\", ax=axs[i], saturation=0.6, **plot_props)\n",
    "        plt.tight_layout()\n",
    "        if save_data:\n",
    "            if group_by_colname == \"event_uuid\":\n",
    "                data_output_fpath = os.path.join(output_folder, f\"loco_{dataset_type}_delta_{output_dtime}.xlsx\")\n",
    "            else:  # aggregate data used\n",
    "                data_output_fpath = os.path.join(output_folder, f\"loco_{dataset_type}_aggregate_delta_{output_dtime}.xlsx\")\n",
    "            df_plot_dset.to_excel(data_output_fpath, index=False)\n",
    "            print(f\"Saved data to {data_output_fpath}\")\n",
    "        if save_figs:\n",
    "            if group_by_colname == \"event_uuid\":\n",
    "                fig_fpath = os.path.join(output_folder, f'loco_{dataset_type}_delta_{output_dtime}{file_format}')\n",
    "            else:\n",
    "                fig_fpath = os.path.join(output_folder, f'loco_{dataset_type}_aggregate_delta_{output_dtime}{file_format}')\n",
    "            plt.savefig(fig_fpath, format=file_format.split(\".\")[-1])\n",
    "            print(f\"Saved to {fig_fpath}\")\n",
    "        plt.show()\n",
    "        return df_plot_dset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f62c92",
   "metadata": {},
   "source": [
    "## Plot for each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_differences(df_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c633bcc",
   "metadata": {},
   "source": [
    "## Plot mouse aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e29c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_differences(df_stats_per_mouse_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c0448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpiv = df_stats_per_mouse_mean.pivot(columns=\"segment_type\", index=[\"mouse_id\", \"exp_type\"], values=\"running%\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a9534",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpiv[\"window_type\"] = dfpiv.apply(lambda row: df_stats_per_mouse_mean[df_stats_per_mouse_mean[\"mouse_id\"] == row[\"mouse_id\"]].window_type.iloc[0], axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_dfs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f7ee88",
   "metadata": {},
   "source": [
    "# Statistical testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_t_test(df, column_name=\"totdist_abs\", one_sided=False, greater_expected=value_mapping[\"am\"], pair_by=\"event_uuid\"):\n",
    "    am_vals = []\n",
    "    bl_vals = []\n",
    "    for i_g, g in df.groupby(pair_by):\n",
    "        assert (len(g[g[\"segment_type\"] == value_mapping[\"bl\"]]) == 1) and (len(g[g[\"segment_type\"] == value_mapping[\"am\"]] ) == 1)\n",
    "        bl_val = g[g[\"segment_type\"] == value_mapping[\"bl\"]][column_name].values\n",
    "        am_val = g[g[\"segment_type\"] == value_mapping[\"am\"]][column_name].values\n",
    "        am_vals.append(am_val[0])\n",
    "        bl_vals.append(bl_val[0])\n",
    "    am_vals = np.array(am_vals)\n",
    "    bl_vals = np.array(bl_vals)\n",
    "\n",
    "    if one_sided:\n",
    "        ttest_result = ttest_rel(am_vals, bl_vals)\n",
    "    else:\n",
    "        if greater_expected==value_mapping[\"am\"]:\n",
    "            ttest_result = ttest_rel(am_vals, bl_vals, alternative=\"greater\")  # first dataset (am) expected to be greater\n",
    "        elif greater_expected==value_mapping[\"bl\"]:\n",
    "            ttest_result = ttest_rel(am_vals, bl_vals, alternative=\"less\")  # second dataset (bl) expected to be greater\n",
    "        else:\n",
    "            raise Exception(f\"paired_t_test(): invalid greater_expected value {greater_expected}\")\n",
    "    #print(ttest_result)\n",
    "    return ttest_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b895e3",
   "metadata": {},
   "source": [
    "## CA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data_ca1 = df_stats[(df_stats[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])) & (df_stats[\"window_type\"] == \"CA1\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CA1\")\n",
    "for statistic in STAT_METRICS:\n",
    "    print(statistic)\n",
    "    for exp_type, exp_g in stat_data_ca1.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "        ttest_result = paired_t_test(exp_g, statistic)\n",
    "        print(f'\\t{exp_type}: {len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]])} pairs;\\n\\tstatistic={ttest_result.statistic}, p={ttest_result.pvalue}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724987c",
   "metadata": {},
   "source": [
    "## NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_nc = df_stats[df_stats[\"window_type\"] == \"NC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ede03",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data_nc = df_stats[(df_stats[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])) & (df_stats[\"window_type\"] == \"NC\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b47c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_stats_nc) > 0:\n",
    "    print(\"NC\")\n",
    "    for statistic in STAT_METRICS:\n",
    "        print(statistic)\n",
    "        for exp_type, exp_g in stat_data_nc.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "            ttest_result = paired_t_test(exp_g, statistic)\n",
    "            print(f'\\t{exp_type}: {len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]])} pairs;\\n\\tstatistic={ttest_result.statistic}, p={ttest_result.pvalue}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448a50e",
   "metadata": {},
   "source": [
    "## Optional: pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ec6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pool_tmev:\n",
    "    stat_data_pooled = df_stats[df_stats[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pool_tmev:\n",
    "    print(\"Pooled CA1+NC\")\n",
    "    for statistic in STAT_METRICS:\n",
    "        print(statistic)\n",
    "        for exp_type, exp_g in stat_data_pooled.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "            ttest_result = paired_t_test(exp_g, statistic)\n",
    "            print(f'\\t{exp_type}: {len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]])} pairs;\\n\\tstatistic={ttest_result.statistic}, p={ttest_result.pvalue}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e964c",
   "metadata": {},
   "source": [
    "## Mouse-aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f43e69",
   "metadata": {},
   "source": [
    "### CA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d923b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data_mouse_means_ca1 = df_stats_per_mouse_mean_ca1[(df_stats_per_mouse_mean_ca1[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])) & (df_stats_per_mouse_mean_ca1[\"window_type\"] == \"CA1\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c6d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CA1\")\n",
    "for statistic in STAT_METRICS:\n",
    "    print(statistic)\n",
    "    for exp_type, exp_g in stat_data_mouse_means_ca1.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "        ttest_result = paired_t_test(exp_g, statistic, pair_by=\"mouse_id\")\n",
    "        print(f'\\t{exp_type}: {len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]])} pairs;\\n\\tstatistic={ttest_result.statistic}, p={ttest_result.pvalue}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3352aca2",
   "metadata": {},
   "source": [
    "### NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6d6bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_stats_nc) > 0:\n",
    "    stat_data_mouse_means_nc = df_stats_per_mouse_mean_nc[(df_stats_per_mouse_mean_nc[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])) & (df_stats_per_mouse_mean_nc[\"window_type\"] == \"NC\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6271055",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_stats_nc) > 0:\n",
    "    print(\"NC\")\n",
    "    for statistic in STAT_METRICS:\n",
    "        print(statistic)\n",
    "        for exp_type, exp_g in stat_data_mouse_means_nc.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "            ttest_result = paired_t_test(exp_g, statistic, pair_by=\"mouse_id\")\n",
    "            print(f'\\t{exp_type}: {len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]])} pairs;\\n\\tstatistic={ttest_result.statistic}, p={ttest_result.pvalue}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a36516",
   "metadata": {},
   "source": [
    "## Optional: pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pool_tmev:\n",
    "    stat_data_aggregate_pooled = df_stats_per_mouse_mean[df_stats_per_mouse_mean[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5bb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pool_tmev:\n",
    "    print(\"Pooled\")\n",
    "    for statistic in STAT_METRICS:\n",
    "        print(statistic)\n",
    "        for exp_type, exp_g in stat_data_aggregate_pooled.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "            ttest_result = paired_t_test(exp_g, statistic, pair_by=\"mouse_id\")\n",
    "            print(f'\\t{exp_type}: {len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]])} pairs;\\n\\tstatistic={ttest_result.statistic}, p={ttest_result.pvalue}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff6e4fd",
   "metadata": {},
   "source": [
    "# Waterfall plot & sanity check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbe53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exptype_wintype_id_dict = {}   # keys: experiment_type, window_type, mouse_id, value: [uuid1, uuid2, ...]\n",
    "for uuid in traces_meta_dict.keys():\n",
    "    if is_chr2 or is_bilat:\n",
    "        exp_type = traces_meta_dict[uuid][\"exp_type\"]\n",
    "    else:\n",
    "        exp_type = \"tmev\"\n",
    "    win_type = traces_meta_dict[uuid][\"window_type\"]\n",
    "    mouse_id = traces_meta_dict[uuid][\"mouse_id\"]\n",
    "    if exp_type not in exptype_wintype_id_dict.keys():\n",
    "        exptype_wintype_id_dict[exp_type] = dict()\n",
    "    if win_type not in exptype_wintype_id_dict[exp_type].keys():\n",
    "        exptype_wintype_id_dict[exp_type][win_type] = dict()\n",
    "    if mouse_id not in exptype_wintype_id_dict[exp_type][win_type].keys():\n",
    "        exptype_wintype_id_dict[exp_type][win_type][mouse_id] = []  # list of uuids\n",
    "    exptype_wintype_id_dict[exp_type][win_type][mouse_id].append(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5712541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_only_bl_am['avg_speed'] = df_stats_only_bl_am['avg_speed'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba75161",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df_stats_only_bl_am[\"avg_speed\"].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNikLoco(exp_type, cut_to_segments=True, bl_equal_post = True,  show_debug=False, show_fig=True, n_bl_frames=bl_manual_length, ):\n",
    "    AMPLITUDE = LV_SPEED_AMPL\n",
    "    offset = 0\n",
    "    # set plotting limits in case we want to cut to the segments\n",
    "    t_min = np.inf\n",
    "    t_max = -1\n",
    "    \n",
    "    n_recordings_with_type =  0\n",
    "    for win_type in exptype_wintype_id_dict[exp_type].keys():\n",
    "        for mouse_id in exptype_wintype_id_dict[exp_type][win_type].keys():\n",
    "            for event_uuid in exptype_wintype_id_dict[exp_type][win_type][mouse_id]:\n",
    "                n_recordings_with_type += 1\n",
    "    fig = plt.figure(figsize=(18,n_recordings_with_type*3))\n",
    "    mouse_ids = traces_dict.keys()\n",
    "    prev_range = 0.0\n",
    "    for win_type in exptype_wintype_id_dict[exp_type].keys():\n",
    "        for mouse_id in exptype_wintype_id_dict[exp_type][win_type].keys(): \n",
    "            for event_uuid in exptype_wintype_id_dict[exp_type][win_type][mouse_id]:\n",
    "                df_quantities = df_stats_only_bl_am[df_stats_only_bl_am[\"event_uuid\"] == event_uuid]\n",
    "                print(event_uuid)\n",
    "                bl_totdist_abs_norm = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]].totdist_abs_norm.iloc[0]\n",
    "                am_totdist_abs_norm = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]].totdist_abs_norm.iloc[0]\n",
    "                bl_running_episodes = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]].running_episodes.iloc[0]\n",
    "                am_running_episodes = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]].running_episodes.iloc[0]\n",
    "                bl_running_percent = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]][\"running%\"].iloc[0]\n",
    "                am_running_percent = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]][\"running%\"].iloc[0]\n",
    "                bl_avg_speed = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]].avg_speed.iloc[0]\n",
    "                am_avg_speed = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]].avg_speed.iloc[0]\n",
    "                bl_running_episodes_mean_length = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]].running_episodes_mean_length.iloc[0]\n",
    "                am_running_episodes_mean_length = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]].running_episodes_mean_length.iloc[0]\n",
    "\n",
    "                if is_chr2:  # chr2 experiments contain the whole session in one file\n",
    "                    df_segments = ddoc.getSegmentsForUUID(event_uuid)\n",
    "                    i_frame_stim_begin = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_begin.iloc[0] - 1\n",
    "                    i_frame_stim_end = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_end.iloc[0] - 1  # in 1 indexing, inclusive\n",
    "                else:  # in tmev recordings, there is no stim, but it is the seizure segment (see value_mapping)\n",
    "                    metadata_dict = traces_meta_dict[event_uuid]\n",
    "                    i_frame_stim_begin = metadata_dict[\"n_bl_frames\"]\n",
    "                    i_frame_stim_end = metadata_dict[\"n_frames\"] - metadata_dict[\"n_am_frames\"]\n",
    "\n",
    "\n",
    "                nik_trace = traces_dict[event_uuid][\"mean_fluo\"]\n",
    "                \n",
    "                if is_chr2:\n",
    "                    nik_trace[i_frame_stim_begin:i_frame_stim_end] = 1.2*max(nik_trace[i_frame_stim_end+1:])  # reduce stim amplitude\n",
    "\n",
    "                min_nik = min(nik_trace)\n",
    "                max_nik = max(nik_trace)\n",
    "\n",
    "                t = traces_dict[event_uuid][\"lv_t_s\"]\n",
    "                \n",
    "                # get begin and end time points of baseline and post-stim segments \n",
    "                i_frame_bl_end = i_frame_stim_begin\n",
    "                i_frame_post_begin = i_frame_stim_end\n",
    "                if n_bl_frames < i_frame_stim_begin:\n",
    "                    i_frame_bl_begin = i_frame_bl_end - n_bl_frames \n",
    "                else:\n",
    "                    i_frame_bl_begin = 0 \n",
    "                if bl_equal_post:\n",
    "                    i_frame_post_end = i_frame_post_begin + n_bl_frames\n",
    "                if not bl_equal_post or i_frame_post_end > len(nik_trace):\n",
    "                    i_frame_post_end = len(nik_trace) - 1\n",
    "                    \n",
    "                # mark segment borders\n",
    "                #plt.vlines(x=[t[i_frame_bl_begin], t[i_frame_bl_end], t[i_frame_post_begin], t[i_frame_post_end]], ymin = offset, ymax = offset+2.2*AMPLITUDE, color=\"orange\")\n",
    "                plt.vlines(x=t[begin_end_frames_dict[event_uuid]], ymin = offset, ymax = offset+2.2*AMPLITUDE, color=\"orange\")\n",
    "                \n",
    "                \n",
    "                if cut_to_segments: \n",
    "                    if t[i_frame_bl_begin] < t_min:\n",
    "                        t_min = t[i_frame_bl_begin]\n",
    "                    if t[i_frame_post_end] > t_max:\n",
    "                        t_max = t[i_frame_post_end]\n",
    "                \n",
    "                labview_trace = traces_dict[event_uuid][\"lv_speed\"]\n",
    "                \n",
    "                if show_debug:\n",
    "                    \n",
    "                    # add totdist_abs_norm values for bl and post-stim\n",
    "                    plt.text(t[i_frame_bl_begin] + (t[i_frame_bl_end] - t[i_frame_bl_begin])*0.1, offset+1.5*AMPLITUDE, f\"d={bl_totdist_abs_norm:.3f}, {bl_running_percent:.2f}%, eps={bl_running_episodes} mean {bl_running_episodes_mean_length:.2f},\\nv={bl_avg_speed:.3f}\", fontsize=20, color=\"red\")\n",
    "                    plt.text(t[i_frame_post_begin] + (t[i_frame_post_end] - t[i_frame_post_begin])*0.1, offset+1.5*AMPLITUDE, f\"d={am_totdist_abs_norm:.3f}, {am_running_percent:.2f}%, eps={am_running_episodes} mean {am_running_episodes_mean_length:.2f},\\nv={am_avg_speed:.3f}, uuid: {event_uuid}\", fontsize=20, color=\"red\")\n",
    "                    # plot running binary data\n",
    "                    \n",
    "                    #labview_running = traces_dict[event_uuid][\"lv_running\"]\n",
    "                    #running_episodes = get_episodes(traces_dict[event_uuid][\"lv_running\"], True, EPISODE_MERGE_THRESHOLD_FRAMES, True)\n",
    "\n",
    "                    # apply a filter to episodes, discard those that do not fulfill the criteria\n",
    "                    #running_episodes = apply_threshold(traces_dict[event_uuid][\"lv_speed\"], running_episodes, AMPL_THRESHOLD, TEMP_THRESHOLD)\n",
    "                    \n",
    "                    #labview_running_merged = np.zeros(labview_running.shape)\n",
    "                    \n",
    "                    #for episode in running_episodes:\n",
    "                    #    labview_running_merged[episode[0]:episode[1]+1] = 1\n",
    "                    \n",
    "                    labview_running_merged = loco_binary_traces[event_uuid]\n",
    "                    \n",
    "                    # for checking if running% is correct: gather all running episodes to end of each segment to visualize the %\n",
    "                    #running_pre = np.sort(labview_running_merged[:i_frame_bl_begin].copy())\n",
    "                    #running_bl = np.sort(labview_running_merged[i_frame_bl_begin:i_frame_bl_end].copy())\n",
    "                    #running_stim = np.sort(labview_running_merged[i_frame_bl_end:i_frame_stim_end].copy())\n",
    "                    #running_post = np.sort(labview_running_merged[i_frame_post_begin:i_frame_post_end].copy())\n",
    "                    #running_rest = np.sort(labview_running_merged[i_frame_post_end:].copy())\n",
    "                    #running_list = [running_pre, running_bl, running_stim, running_post, running_rest]                   \n",
    "                    #sorted_episodes = np.concatenate(running_list)\n",
    "                    #plt.plot(t, 0.5*AMPLITUDE*sorted_episodes+offset+ 0.5*AMPLITUDE, color=\"red\")\n",
    "                    \n",
    "                    # plot the binary locomotion trace (filtered)\n",
    "                    #plt.plot(t, 0.5*AMPLITUDE*labview_running_merged+offset+ 0.5*AMPLITUDE, color=\"red\")\n",
    "                    # plot only horizontal lines where fitlered binary locomotion trace shows locomotion\n",
    "                    episodes = get_episodes(labview_running_merged, merge_episodes=False, merge_threshold_frames=0, return_begin_end_frames = True)\n",
    "                    # convert [(i_begin, i_end), ...] to [i_begin1, i_begin2, ...], [i_end1, i_end2, ...]\n",
    "                    episode_begin_frames = np.array([episode[0] for episode in episodes])\n",
    "                    episode_end_frames = np.array([episode[1] for episode in episodes])\n",
    "                    if len(episode_begin_frames) > 0 :\n",
    "                        plt.hlines(xmin = t[episode_begin_frames], xmax = t[episode_end_frames], y=[offset-0.1*AMPLITUDE for i in range(len(episode_begin_frames))], linewidth=6, color=\"red\")\n",
    "\n",
    "                \n",
    "                \n",
    "                min_lv = min(labview_trace)\n",
    "                max_lv = max(labview_trace)\n",
    "                # plt.plot(t, AMPLITUDE*(labview_trace - min_lv)/(max_lv - min_lv)+offset, color=\"black\")\n",
    "                # amplitude is matched to labview speed raw values, so no scaling here\n",
    "                plt.plot(t, labview_trace - min_lv + offset, color=\"black\")\n",
    "                \n",
    "                \n",
    "                offset +=1.1*AMPLITUDE\n",
    "\n",
    "\n",
    "\n",
    "                color = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "                plt.plot(t, AMPLITUDE*(nik_trace- min_nik)/(max_nik - min_nik)+offset, color=color)\n",
    "                offset+=1.1*AMPLITUDE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if (len(traces_dict[event_uuid][\"mean_fluo\"]) != 13483):\n",
    "                    print(f'{event_uuid}: {len(traces_dict[event_uuid][\"mean_fluo\"])}, {mouse_id}, {exp_type}')\n",
    "\n",
    "\n",
    "\n",
    "    if cut_to_segments:\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim((t_min, t_max))\n",
    "    print(f\"Total: {n_recordings_with_type} traces\")\n",
    "    plt.suptitle(exp_type, fontsize=22)\n",
    "    #plt.axis(\"off\")\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Time (s)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    #plt.xlim((300, 460))  # 250, 500\n",
    "    if save_figs:\n",
    "        if not show_debug:\n",
    "            out_fpath = f\"D:\\\\Downloads\\\\loco_waterfall_{exp_type}_{output_dtime}{file_format}\"        \n",
    "        else:\n",
    "            out_fpath = f\"D:\\\\Downloads\\\\loco_sanitycheck_{exp_type}_{output_dtime}{file_format}\"\n",
    "        plt.savefig(out_fpath,bbox_inches='tight', dpi=300)\n",
    "        print(f\"Saved as {out_fpath}\")\n",
    "    if show_fig:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareLoco(exp_type):\n",
    "    AMPLITUDE = LV_SPEED_AMPL\n",
    "    offset = 0\n",
    "    n_recordings_with_type =  0\n",
    "    for win_type in exptype_wintype_id_dict[exp_type].keys():\n",
    "        for mouse_id in exptype_wintype_id_dict[exp_type][win_type].keys():\n",
    "            for event_uuid in exptype_wintype_id_dict[exp_type][win_type][mouse_id]:\n",
    "                n_recordings_with_type += 1\n",
    "    fig = plt.figure(figsize=(18,n_recordings_with_type*3))\n",
    "    mouse_ids = traces_dict.keys()\n",
    "    prev_range = 0.0\n",
    "    for win_type in exptype_wintype_id_dict[exp_type].keys():\n",
    "        for mouse_id in exptype_wintype_id_dict[exp_type][win_type].keys():\n",
    "            for event_uuid in exptype_wintype_id_dict[exp_type][win_type][mouse_id]:\n",
    "                print(event_uuid)\n",
    "                if is_chr2:\n",
    "                    df_segments = ddoc.getSegmentsForUUID(event_uuid)\n",
    "                    i_frame_stim_begin = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_begin.iloc[0] - 1\n",
    "                    i_frame_stim_end = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_end.iloc[0] - 1  # in 1 indexing, inclusive\n",
    "                else:\n",
    "                    metadata_dict = traces_meta_dict[event_uuid]\n",
    "                    i_frame_stim_begin = metadata_dict[\"n_bl_frames\"]\n",
    "                    i_frame_stim_end = metadata_dict[\"n_frames\"] - metadata_dict[\"n_am_frames\"]\n",
    "                \n",
    "                lfp_mov_trace = traces_dict[event_uuid][\"lfp_mov_y\"]\n",
    "                t_lfp = traces_dict[event_uuid][\"lfp_mov_t\"]\n",
    "                lfp_min = min(lfp_mov_trace)\n",
    "                lfp_max = max(lfp_mov_trace)\n",
    "\n",
    "\n",
    "                t = traces_dict[event_uuid][\"lv_t_s\"]\n",
    "\n",
    "                labview_trace = traces_dict[event_uuid][\"lv_speed\"]\n",
    "                min_lv = min(labview_trace[10:])\n",
    "                max_lv = max(labview_trace[10:])\n",
    "                # scale LFP to match LabView in amplitude, at least roughly\n",
    "                plt.plot(t_lfp, AMPLITUDE*(lfp_mov_trace - lfp_min)/(lfp_max - lfp_min)+offset, color=\"black\")\n",
    "                offset +=1.1*AMPLITUDE\n",
    "\n",
    "                if t[0] +1000 < t_lfp[0]:\n",
    "                    print(f\"{event_uuid} {mouse_id}\")\n",
    "\n",
    "\n",
    "                color = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "                # do not scale, keep original amplitude\n",
    "                plt.plot(t, labview_trace- min_lv+offset, color=color)\n",
    "                offset+=1.1*AMPLITUDE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if (len(traces_dict[event_uuid][\"mean_fluo\"]) != 13483):\n",
    "                    print(f'{event_uuid}: {len(traces_dict[event_uuid][\"mean_fluo\"])}, {mouse_id}, {exp_type}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #plt.axis(\"off\")\n",
    "    plt.suptitle(exp_type, fontsize=22)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Time (s)\", fontsize=14)\n",
    "    #plt.xlim((300, 460))  # 250, 500\n",
    "    plt.tight_layout()\n",
    "    if save_figs:\n",
    "        out_fpath = f\"D:\\\\Downloads\\\\loco_traces_{exp_type}_{output_dtime}{file_format}\"\n",
    "        plt.savefig(out_fpath,bbox_inches='tight', dpi=300)\n",
    "        print(f\"Saved as {out_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waterfallLoco(exp_type, show_segments=False, bl_equal_post=True, n_bl_frames=bl_manual_length):\n",
    "    AMPLITUDE = LV_SPEED_AMPL\n",
    "    offset = 0\n",
    "\n",
    "    n_recordings_with_type =  0\n",
    "    for win_type in exptype_wintype_id_dict[exp_type].keys():\n",
    "        for mouse_id in exptype_wintype_id_dict[exp_type][win_type].keys():\n",
    "            for event_uuid in exptype_wintype_id_dict[exp_type][win_type][mouse_id]:\n",
    "                n_recordings_with_type += 1\n",
    "    fig = plt.figure(figsize=(18,n_recordings_with_type*3))\n",
    "    mouse_ids = traces_dict.keys()\n",
    "    prev_range = 0.0\n",
    "    for win_type in exptype_wintype_id_dict[exp_type].keys():\n",
    "        for mouse_id in exptype_wintype_id_dict[exp_type][win_type].keys(): \n",
    "            for event_uuid in exptype_wintype_id_dict[exp_type][win_type][mouse_id]:\n",
    "                if is_chr2:  # chr2 experiments contain the whole session in one file\n",
    "                    df_segments = ddoc.getSegmentsForUUID(event_uuid)\n",
    "                    i_frame_stim_begin = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_begin.iloc[0] - 1\n",
    "                    i_frame_stim_end = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_end.iloc[0] - 1  # in 1 indexing, inclusive\n",
    "                else:  # in tmev recordings, there is no stim, but it is the seizure segment (see value_mapping)\n",
    "                    metadata_dict = traces_meta_dict[event_uuid]\n",
    "                    i_frame_stim_begin = metadata_dict[\"n_bl_frames\"]\n",
    "                    i_frame_stim_end = metadata_dict[\"n_frames\"] - metadata_dict[\"n_am_frames\"]\n",
    "                    \n",
    "\n",
    "                t = traces_dict[event_uuid][\"lv_t_s\"]\n",
    "                \n",
    "                if show_segments:\n",
    "                    # get begin and end time points of baseline and post-stim segments \n",
    "                    i_frame_bl_end = i_frame_stim_begin\n",
    "                    i_frame_post_begin = i_frame_stim_end\n",
    "                    if n_bl_frames < i_frame_stim_begin:\n",
    "                        i_frame_bl_begin = i_frame_bl_end - n_bl_frames \n",
    "                    else:\n",
    "                        i_frame_bl_begin = 0\n",
    "                    if bl_equal_post:\n",
    "                        i_frame_post_end = i_frame_post_begin + n_bl_frames\n",
    "                    if not bl_equal_post or i_frame_post_end >= len(t):\n",
    "                        i_frame_post_end = len(t) - 1\n",
    "                    # plot them\n",
    "                    print(i_frame_post_end)\n",
    "                    plt.vlines(x=t[begin_end_frames_dict[event_uuid]], ymin = offset, ymax = offset+AMPLITUDE, color=\"orange\")\n",
    "                \n",
    "\n",
    "                \n",
    "                labview_trace = traces_dict[event_uuid][\"lv_speed\"]\n",
    "                min_lv = min(labview_trace)\n",
    "                max_lv = max(labview_trace)\n",
    "                color = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "                plt.plot(t, labview_trace - min_lv+offset, color=color)\n",
    "                \n",
    "                offset +=1.3*AMPLITUDE\n",
    "                \n",
    "                if (len(traces_dict[event_uuid][\"mean_fluo\"]) != 13483):\n",
    "                    print(f'{event_uuid}: {len(traces_dict[event_uuid][\"mean_fluo\"])}, {mouse_id}, {exp_type}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Total: {n_recordings_with_type} traces\")\n",
    "    plt.suptitle(exp_type, fontsize=22)\n",
    "    #plt.axis(\"off\")\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Time (s)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    #plt.xlim((300, 460))  # 250, 500\n",
    "    if save_figs:\n",
    "        out_fpath = f\"D:\\\\Downloads\\\\loco_waterfall_{exp_type}_{output_dtime}{file_format}\"\n",
    "        plt.savefig(out_fpath,bbox_inches='tight', dpi=300)\n",
    "        print(f\"Saved as {out_fpath}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNikLocoLFP(exp_type, cut_to_segments=True, bl_equal_post = True,  show_debug=False, show_fig=True, n_bl_frames=bl_manual_length, ):\n",
    "    AMPLITUDE = LV_SPEED_AMPL\n",
    "    offset = 0\n",
    "    # set plotting limits in case we want to cut to the segments\n",
    "    t_min = np.inf\n",
    "    t_max = -1\n",
    "    \n",
    "    n_recordings_with_type =  0\n",
    "    for win_type in exptype_wintype_id_dict[exp_type].keys():\n",
    "        for mouse_id in exptype_wintype_id_dict[exp_type][win_type].keys():\n",
    "            for event_uuid in exptype_wintype_id_dict[exp_type][win_type][mouse_id]:\n",
    "                n_recordings_with_type += 1\n",
    "    fig = plt.figure(figsize=(18,n_recordings_with_type*3))\n",
    "    mouse_ids = traces_dict.keys()\n",
    "    prev_range = 0.0\n",
    "    i_lfpoffs = 0\n",
    "    for win_type in exptype_wintype_id_dict[exp_type].keys():\n",
    "        for mouse_id in exptype_wintype_id_dict[exp_type][win_type].keys(): \n",
    "            for event_uuid in exptype_wintype_id_dict[exp_type][win_type][mouse_id]:\n",
    "                df_quantities = df_stats_only_bl_am[df_stats_only_bl_am[\"event_uuid\"] == event_uuid]\n",
    "                print(event_uuid)\n",
    "                bl_totdist_abs_norm = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]].totdist_abs_norm.iloc[0]\n",
    "                am_totdist_abs_norm = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]].totdist_abs_norm.iloc[0]\n",
    "                bl_running_episodes = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]].running_episodes.iloc[0]\n",
    "                am_running_episodes = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]].running_episodes.iloc[0]\n",
    "                bl_running_percent = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]][\"running%\"].iloc[0]\n",
    "                am_running_percent = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]][\"running%\"].iloc[0]\n",
    "                bl_avg_speed = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]].avg_speed.iloc[0]\n",
    "                am_avg_speed = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]].avg_speed.iloc[0]\n",
    "                bl_running_episodes_mean_length = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"bl\"]].running_episodes_mean_length.iloc[0]\n",
    "                am_running_episodes_mean_length = df_quantities[df_quantities[\"segment_type\"] == value_mapping[\"am\"]].running_episodes_mean_length.iloc[0]\n",
    "\n",
    "                if is_chr2:  # chr2 experiments contain the whole session in one file\n",
    "                    df_segments = ddoc.getSegmentsForUUID(event_uuid)\n",
    "                    i_frame_stim_begin = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_begin.iloc[0] - 1\n",
    "                    i_frame_stim_end = df_segments[df_segments[\"interval_type\"] == \"stimulation\"].frame_end.iloc[0] - 1  # in 1 indexing, inclusive\n",
    "                else:  # in tmev recordings, there is no stim, but it is the seizure segment (see value_mapping)\n",
    "                    metadata_dict = traces_meta_dict[event_uuid]\n",
    "                    i_frame_stim_begin = metadata_dict[\"n_bl_frames\"]\n",
    "                    i_frame_stim_end = metadata_dict[\"n_frames\"] - metadata_dict[\"n_am_frames\"]\n",
    "\n",
    "                has_nik = \"mean_fluo\" in traces_dict[event_uuid]\n",
    "                if has_nik:\n",
    "                    nik_trace = traces_dict[event_uuid][\"mean_fluo\"]\n",
    "                \n",
    "                if is_chr2 and has_nik:\n",
    "                    nik_trace[i_frame_stim_begin:i_frame_stim_end] = 1.2*max(nik_trace[i_frame_stim_end+1:])  # reduce stim amplitude\n",
    "                if has_nik:\n",
    "                    min_nik = min(nik_trace)\n",
    "                    max_nik = max(nik_trace)\n",
    "                \n",
    "                t = traces_dict[event_uuid][\"lv_t_s\"]\n",
    "                \n",
    "                if \"lfp_y\" in traces_dict[event_uuid].keys():\n",
    "                    lfp_y = traces_dict[event_uuid][\"lfp_y\"]\n",
    "                    lfp_mov_y = traces_dict[event_uuid][\"lfp_mov_y\"]\n",
    "                    lfp_t = traces_dict[event_uuid][\"lfp_t\"]\n",
    "                    # normalize traces\n",
    "                    min_lfp = np.min(lfp_y)\n",
    "                    max_lfp = np.max(lfp_y)\n",
    "                    lfp_y = AMPLITUDE*(lfp_y - min_lfp)/(max_lfp - min_lfp)\n",
    "                    \n",
    "                    min_lfp_mov = np.min(lfp_mov_y)\n",
    "                    max_lfp_mov = np.max(lfp_mov_y)\n",
    "                    lfp_mov_y = AMPLITUDE*(lfp_mov_y - min_lfp_mov)/(max_lfp_mov - min_lfp_mov)\n",
    "                else:\n",
    "                    lfp_y = None\n",
    "                    lfp_t = None\n",
    "                    lfp_mov_y = None\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                # get begin and end time points of baseline and post-stim segments \n",
    "                i_frame_bl_end = i_frame_stim_begin\n",
    "                i_frame_post_begin = i_frame_stim_end\n",
    "                if n_bl_frames < i_frame_stim_begin:\n",
    "                    i_frame_bl_begin = i_frame_bl_end - n_bl_frames \n",
    "                else:\n",
    "                    i_frame_bl_begin = 0 \n",
    "                if bl_equal_post:\n",
    "                    i_frame_post_end = i_frame_post_begin + n_bl_frames\n",
    "                    if i_frame_post_end == len(t):\n",
    "                        i_frame_post_end = len(t) - 1\n",
    "                if has_nik and (not bl_equal_post or i_frame_post_end > len(nik_trace)):\n",
    "                    i_frame_post_end = len(nik_trace) - 1\n",
    "                    \n",
    "                # mark segment borders\n",
    "                #plt.vlines(x=[t[i_frame_bl_begin], t[i_frame_bl_end], t[i_frame_post_begin], t[i_frame_post_end]], ymin = offset, ymax = offset+2.2*AMPLITUDE, color=\"orange\")\n",
    "                vline_height = 1.2*AMPLITUDE\n",
    "                if has_nik:  # nik trace\n",
    "                    vline_height += AMPLITUDE\n",
    "                if lfp_y is not None:  # lfp + lfp loco traces\n",
    "                    vline_height += 2*AMPLITUDE\n",
    "                if max(begin_end_frames_dict[event_uuid]) >= len(t):\n",
    "                    print(f\"last vline has to be modified: {begin_end_frames_dict[event_uuid][-1]}, last frame {len(t)}\")\n",
    "                    begin_end_frames_dict[event_uuid][-1] -= 1\n",
    "                plt.vlines(x=t[begin_end_frames_dict[event_uuid]], ymin = offset, ymax = offset+vline_height, color=\"orange\")\n",
    "\n",
    "                \n",
    "                if cut_to_segments: \n",
    "                    if t[i_frame_bl_begin] < t_min:\n",
    "                        t_min = t[i_frame_bl_begin]\n",
    "                    if t[i_frame_post_end] > t_max:\n",
    "                        t_max = t[i_frame_post_end]\n",
    "                \n",
    "                labview_trace = traces_dict[event_uuid][\"lv_speed\"]\n",
    "                \n",
    "                if show_debug:\n",
    "                    \n",
    "                    # add totdist_abs_norm values for bl and post-stim\n",
    "                    plt.text(t[i_frame_bl_begin] + (t[i_frame_bl_end] - t[i_frame_bl_begin])*0.1, offset+1.5*AMPLITUDE, f\"d={bl_totdist_abs_norm:.3f}, {bl_running_percent:.2f}%, eps={bl_running_episodes} mean {bl_running_episodes_mean_length:.2f},\\nv={bl_avg_speed:.3f}\", fontsize=20, color=\"red\")\n",
    "                    plt.text(t[i_frame_post_begin] + (t[i_frame_post_end] - t[i_frame_post_begin])*0.1, offset+1.5*AMPLITUDE, f\"d={am_totdist_abs_norm:.3f}, {am_running_percent:.2f}%, eps={am_running_episodes} mean {am_running_episodes_mean_length:.2f},\\nv={am_avg_speed:.3f}, uuid: {event_uuid}\", fontsize=20, color=\"red\")\n",
    "                    # plot running binary data\n",
    "                    \n",
    "                    #labview_running = traces_dict[event_uuid][\"lv_running\"]\n",
    "                    #running_episodes = get_episodes(traces_dict[event_uuid][\"lv_running\"], True, EPISODE_MERGE_THRESHOLD_FRAMES, True)\n",
    "\n",
    "                    # apply a filter to episodes, discard those that do not fulfill the criteria\n",
    "                    #running_episodes = apply_threshold(traces_dict[event_uuid][\"lv_speed\"], running_episodes, AMPL_THRESHOLD, TEMP_THRESHOLD)\n",
    "                    \n",
    "                    #labview_running_merged = np.zeros(labview_running.shape)\n",
    "                    \n",
    "                    #for episode in running_episodes:\n",
    "                    #    labview_running_merged[episode[0]:episode[1]+1] = 1\n",
    "                    \n",
    "                    labview_running_merged = loco_binary_traces[event_uuid]\n",
    "                    \n",
    "                    # for checking if running% is correct: gather all running episodes to end of each segment to visualize the %\n",
    "                    #running_pre = np.sort(labview_running_merged[:i_frame_bl_begin].copy())\n",
    "                    #running_bl = np.sort(labview_running_merged[i_frame_bl_begin:i_frame_bl_end].copy())\n",
    "                    #running_stim = np.sort(labview_running_merged[i_frame_bl_end:i_frame_stim_end].copy())\n",
    "                    #running_post = np.sort(labview_running_merged[i_frame_post_begin:i_frame_post_end].copy())\n",
    "                    #running_rest = np.sort(labview_running_merged[i_frame_post_end:].copy())\n",
    "                    #running_list = [running_pre, running_bl, running_stim, running_post, running_rest]                   \n",
    "                    #sorted_episodes = np.concatenate(running_list)\n",
    "                    #plt.plot(t, 0.5*AMPLITUDE*sorted_episodes+offset+ 0.5*AMPLITUDE, color=\"red\")\n",
    "                    \n",
    "                    # plot the binary locomotion trace (filtered)\n",
    "                    #plt.plot(t, 0.5*AMPLITUDE*labview_running_merged+offset+ 0.5*AMPLITUDE, color=\"red\")\n",
    "                    # plot only horizontal lines where fitlered binary locomotion trace shows locomotion\n",
    "                    episodes = get_episodes(labview_running_merged, merge_episodes=False, merge_threshold_frames=0, return_begin_end_frames = True)\n",
    "                    # convert [(i_begin, i_end), ...] to [i_begin1, i_begin2, ...], [i_end1, i_end2, ...]\n",
    "                    episode_begin_frames = np.array([episode[0] for episode in episodes])\n",
    "                    episode_end_frames = np.array([episode[1] for episode in episodes])\n",
    "                    if len(episode_begin_frames) > 0 :\n",
    "                        plt.hlines(xmin = t[episode_begin_frames], xmax = t[episode_end_frames], y=[offset-0.1*AMPLITUDE for i in range(len(episode_begin_frames))], linewidth=6, color=\"red\")\n",
    "\n",
    "                \n",
    "                \n",
    "                min_lv = min(labview_trace)\n",
    "                max_lv = max(labview_trace)\n",
    "                # plt.plot(t, AMPLITUDE*(labview_trace - min_lv)/(max_lv - min_lv)+offset, color=\"black\")\n",
    "                # amplitude is matched to labview speed raw values, so no scaling here\n",
    "                \n",
    "\n",
    "                \n",
    "                plt.plot(t, labview_trace - min_lv + offset, color=\"black\")\n",
    "                offset +=1.1*AMPLITUDE\n",
    "\n",
    "                if lfp_y is not None:\n",
    "                    #lfp_t = lfp_t + szsd_lfp_offset_list[i_lfpoffs]\n",
    "                    #print(szsd_lfp_offset_list[i_lfpoffs])\n",
    "                    plt.plot(lfp_t, lfp_mov_y + offset, color=\"lightgrey\")\n",
    "                    offset += 1.1*AMPLITUDE\n",
    "                    \n",
    "                    plt.plot(lfp_t, lfp_y + offset, color=\"grey\")\n",
    "                    offset += 1.1*AMPLITUDE\n",
    "                    i_lfpoffs += 1\n",
    "\n",
    "                color = df_colors[df_colors[\"mouse_id\"] == mouse_id].color.iloc[0]\n",
    "                if has_nik:\n",
    "                    plt.plot(t, AMPLITUDE*(nik_trace- min_nik)/(max_nik - min_nik)+offset, color=color)\n",
    "                    offset+=1.1*AMPLITUDE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if has_nik and (len(traces_dict[event_uuid][\"mean_fluo\"]) != 13483):\n",
    "                    print(f'{event_uuid}: {len(traces_dict[event_uuid][\"mean_fluo\"])}, {mouse_id}, {exp_type}')\n",
    "\n",
    "\n",
    "\n",
    "    if cut_to_segments:\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlim((t_min, t_max))\n",
    "    #ax.set_xlim((270, 350))  # for checking matching of LFP, Nikon and Labview channels\n",
    "    #ax.set_xlim((300, 400))\n",
    "    print(f\"Total: {n_recordings_with_type} traces\")\n",
    "    plt.suptitle(exp_type, fontsize=22)\n",
    "    #plt.axis(\"off\")\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Time (s)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    if save_figs:\n",
    "        if not show_debug:\n",
    "            out_fpath = os.path.join(output_folder, f\"D:\\\\Downloads\\\\loco_NikLocoLFP_{exp_type}_{output_dtime}{file_format}\" )       \n",
    "        else:\n",
    "            out_fpath = os.path.join(output_folder, f\"loco_NikLocoLFP_sanitycheck_{exp_type}_{output_dtime}{file_format}\")\n",
    "        plt.savefig(out_fpath,bbox_inches='tight', dpi=300)\n",
    "        print(f\"Saved as {out_fpath}\")\n",
    "    if show_fig:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff52fa",
   "metadata": {},
   "source": [
    "### Plot one of the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100dbdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_type in df_stats.exp_type.unique():\n",
    "    print(exp_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_sanity_check:\n",
    "    for exp_type in df_stats.exp_type.unique(): \n",
    "        plotNikLocoLFP(exp_type, cut_to_segments=False, bl_equal_post=True, show_debug=True, show_fig=False)  # include all information useful for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_waterfall:\n",
    "    for exp_type in df_stats.exp_type.unique():\n",
    "        plotNikLoco(exp_type, cut_to_segments=True, bl_equal_post=True, show_debug=False, show_fig=False)  # include all information useful for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d02e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chr2:\n",
    "    plotNikLocoLFP(\"chr2_ctl\", cut_to_segments=True, bl_equal_post=True, show_debug=False, show_fig=False)  # include all information useful for debugging\n",
    "elif not is_bilat:\n",
    "    plotNikLocoLFP(\"tmev\", cut_to_segments=True, bl_equal_post=True, show_debug=False, show_fig=False)  # include all information useful for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173aef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "szsd_lfp_offset_list = [8.8, 0, 8.6, 0., 0, 8.6, 8.6, 8.6, 9.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e696cb",
   "metadata": {},
   "source": [
    "# Export results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827a96be",
   "metadata": {},
   "source": [
    "## Export all metrics (individual session data) to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcaa861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save = df_stats[(df_stats[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    if is_chr2:\n",
    "        output_fpath = os.path.join(output_folder, f\"loco_chr2_{output_dtime}.xlsx\")\n",
    "    elif is_bilat:\n",
    "        output_fpath = os.path.join(output_folder, f\"loco_bilat_{output_dtime}.xlsx\")\n",
    "    else:\n",
    "        output_fpath = os.path.join(output_folder, f\"loco_tmev_{output_dtime}.xlsx\")\n",
    "    df_to_save.to_excel(output_fpath, index=False)\n",
    "    print(f\"Results exported to {output_fpath}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f607a",
   "metadata": {},
   "source": [
    "## Export mouse aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2501cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_save_aggregate = df_stats_per_mouse_mean[df_stats_per_mouse_mean[\"segment_type\"].isin([value_mapping[\"bl\"], value_mapping[\"am\"]])].sort_values(by=[\"mouse_id\", \"exp_type\", \"segment_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    if is_chr2:\n",
    "        output_fpath = os.path.join(output_folder, f\"loco_chr2_aggregate_{output_dtime}.xlsx\")\n",
    "    elif is_bilat:\n",
    "        output_fpath = os.path.join(output_folder, f\"loco_bilat_aggregate_{output_dtime}.xlsx\")\n",
    "    else:\n",
    "        output_fpath = os.path.join(output_folder, f\"loco_tmev_aggregate_{output_dtime}.xlsx\")\n",
    "    df_to_save_aggregate.to_excel(output_fpath, index=False)\n",
    "    print(f\"Results exported to {output_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a4623",
   "metadata": {},
   "source": [
    "# Export to Matlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33193c",
   "metadata": {},
   "source": [
    "## Individual session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chr2:\n",
    "    output_fpath = os.path.join(output_folder, f\"loco_chr2_{output_dtime}.mat\")\n",
    "else:\n",
    "    output_fpath = os.path.join(output_folder, f\"loco_tmev_{output_dtime}.mat\")\n",
    "print(f\"Saving session-level data to workspace\\n\\t{output_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e451a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    eng = matlab.engine.start_matlab()\n",
    "\n",
    "    for colname in df_to_save.columns:\n",
    "        dtype = df_to_save[colname].dtype\n",
    "        if \"%\" in colname:\n",
    "            colname_matlab = colname.replace(\"%\", \"percent\")\n",
    "        else:\n",
    "            colname_matlab = colname\n",
    "        if dtype == np.object_:  # strings are represented as object_ in np array\n",
    "            eng.workspace[colname_matlab] = list(np.array(df_to_save[colname]))\n",
    "        elif dtype == np.int64:\n",
    "            eng.workspace[colname_matlab] = matlab.int64(list(df_to_save[colname]))\n",
    "        elif dtype == np.int32:\n",
    "            eng.workspace[colname_matlab] = matlab.int32(list(df_to_save[colname]))\n",
    "        elif dtype == np.float64:\n",
    "            eng.workspace[colname_matlab] = matlab.double(list(df_to_save[colname]))\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{dtype} not implemented yet!\")\n",
    "\n",
    "    eng.eval(f\"save('{output_fpath}')\", nargout=0)\n",
    "    print(\"Saved successfully.\")\n",
    "    eng.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c0e991",
   "metadata": {},
   "source": [
    "## Save aggregate data to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chr2:\n",
    "    output_fpath = os.path.join(output_folder, f\"loco_chr2_aggregate_{output_dtime}.mat\")\n",
    "else:\n",
    "    output_fpath = os.path.join(output_folder, f\"loco_tmev_aggregate_{output_dtime}.mat\")\n",
    "print(f\"Saving mouse aggregate data to workspace\\n\\t{output_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    eng = matlab.engine.start_matlab()\n",
    "\n",
    "    for colname in df_to_save_aggregate.columns:\n",
    "        dtype = df_to_save_aggregate[colname].dtype\n",
    "        if \"%\" in colname:\n",
    "            colname_matlab = colname.replace(\"%\", \"percent\")\n",
    "        else:\n",
    "            colname_matlab = colname\n",
    "        if dtype == np.object_:  # strings are represented as object_ in np array\n",
    "            eng.workspace[colname_matlab] = list(np.array(df_to_save_aggregate[colname]))\n",
    "        elif dtype == np.int64:\n",
    "            eng.workspace[colname_matlab] = matlab.int64(list(df_to_save_aggregate[colname]))\n",
    "        elif dtype == np.float64:\n",
    "            eng.workspace[colname_matlab] = matlab.double(list(df_to_save_aggregate[colname]))\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{dtype} not implemented yet!\")\n",
    "\n",
    "    eng.eval(f\"save('{output_fpath}')\", nargout=0)\n",
    "    print(\"Saved successfully.\")\n",
    "    eng.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d51940",
   "metadata": {},
   "source": [
    "# Save statistical test results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9776f89",
   "metadata": {},
   "source": [
    "## Individual sessions as samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3f1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form: [[window_type, metric, experiment_type, n_samples, t_statistic, p],  [...], ]\n",
    "stat_colnames = [\"window_type\", \"metric\", \"experiment_type\", \"n_samples\", \"t_statistic\", \"p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    stat_data = []\n",
    "    # start with CA1\n",
    "    if len(df_stats[df_stats[\"window_type\"] == \"CA1\"]) > 0:\n",
    "        for statistic in STAT_METRICS:\n",
    "            for exp_type, exp_g in stat_data_ca1.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "                ttest_result = paired_t_test(exp_g, statistic)\n",
    "                t_stat = ttest_result.statistic\n",
    "                p = ttest_result.pvalue\n",
    "                row = []\n",
    "                row.append(\"CA1\")\n",
    "                row.append(statistic)\n",
    "                row.append(exp_type)\n",
    "                row.append(len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]]))\n",
    "                row.append(t_stat)\n",
    "                row.append(p)\n",
    "                stat_data.append(row)\n",
    "    else:\n",
    "        print(\"Skipping CA1, no samples found...\")\n",
    "    if len(df_stats[df_stats[\"window_type\"] == \"NC\"]) > 0:\n",
    "        for statistic in STAT_METRICS:\n",
    "            for exp_type, exp_g in stat_data_nc.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "                ttest_result = paired_t_test(exp_g, statistic)\n",
    "                t_stat = ttest_result.statistic\n",
    "                p = ttest_result.pvalue\n",
    "                row = []\n",
    "                row.append(\"NC\")\n",
    "                row.append(statistic)\n",
    "                row.append(exp_type)\n",
    "                row.append(len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]]))\n",
    "                row.append(t_stat)\n",
    "                row.append(p)\n",
    "                stat_data.append(row)\n",
    "    else:\n",
    "        print(\"Skipping NC, no samples found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f356159",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    if is_chr2:\n",
    "        output_fpath = os.path.join(output_folder,  f\"loco_stattest_chr2_{output_dtime}.xlsx\")\n",
    "    else:\n",
    "        output_fpath = os.path.join(output_folder,  f\"loco_stattest_tmev_{output_dtime}.xlsx\")\n",
    "    df_exp_stat = pd.DataFrame(data=stat_data, columns=stat_colnames)\n",
    "    df_exp_stat.to_excel(output_fpath, index=False)\n",
    "    #with open(output_fpath, 'w', newline='\\n') as csvfile:\n",
    "    #    writer = csv.writer(csvfile, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    #    writer.writerow(stat_colnames)\n",
    "    #    for row in stat_data:\n",
    "    #        writer.writerow(row)\n",
    "    print(f\"Saved to\\n\\t{output_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a1cc3",
   "metadata": {},
   "source": [
    "### Save pooled stat results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data and pool_tmev:\n",
    "    stat_data = []\n",
    "    for statistic in STAT_METRICS:\n",
    "        for exp_type, exp_g in stat_data_pooled.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "            ttest_result = paired_t_test(exp_g, statistic)\n",
    "            t_stat = ttest_result.statistic\n",
    "            p = ttest_result.pvalue\n",
    "            row = []\n",
    "            row.append(\"Pooled\")\n",
    "            row.append(statistic)\n",
    "            row.append(exp_type)\n",
    "            row.append(len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]]))\n",
    "            row.append(t_stat)\n",
    "            row.append(p)\n",
    "            stat_data.append(row)\n",
    "    output_fpath = os.path.join(output_folder,  f\"loco_stattest_{dataset_type}_pooled_{output_dtime}.xlsx\")\n",
    "    df_exp_stat = pd.DataFrame(data=stat_data, columns=stat_colnames)\n",
    "    df_exp_stat.to_excel(output_fpath, index=False)\n",
    "    #with open(output_fpath, 'w', newline='\\n') as csvfile:\n",
    "    #    writer = csv.writer(csvfile, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    #    writer.writerow(stat_colnames)\n",
    "    #    for row in stat_data:\n",
    "    #        writer.writerow(row)\n",
    "    print(f\"Saved to\\n\\t{output_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9e9bc",
   "metadata": {},
   "source": [
    "## Mouse aggregate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eabb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_data_aggregate = []\n",
    "if save_data:\n",
    "    # start with CA1\n",
    "    if len(df_stats[df_stats[\"window_type\"] == \"CA1\"]) > 0:\n",
    "        for statistic in STAT_METRICS:\n",
    "            for exp_type, exp_g in stat_data_mouse_means_ca1.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "                ttest_result = paired_t_test(exp_g, statistic, pair_by=\"mouse_id\")\n",
    "                t_stat = ttest_result.statistic\n",
    "                p = ttest_result.pvalue\n",
    "                row = []\n",
    "                row.append(\"CA1\")\n",
    "                row.append(statistic)\n",
    "                row.append(exp_type)\n",
    "                row.append(len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]]))\n",
    "                row.append(t_stat)\n",
    "                row.append(p)\n",
    "                stat_data_aggregate.append(row)\n",
    "    else:\n",
    "        print(\"Skipping CA1, no samples found...\")\n",
    "    if len(df_stats[df_stats[\"window_type\"] == \"NC\"]) > 0:\n",
    "        for statistic in STAT_METRICS:\n",
    "            for exp_type, exp_g in stat_data_mouse_means_nc.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "                ttest_result = paired_t_test(exp_g, statistic, pair_by=\"mouse_id\")\n",
    "                t_stat = ttest_result.statistic\n",
    "                p = ttest_result.pvalue\n",
    "                row = []\n",
    "                row.append(\"NC\")\n",
    "                row.append(statistic)\n",
    "                row.append(exp_type)\n",
    "                row.append(len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]]))\n",
    "                row.append(t_stat)\n",
    "                row.append(p)\n",
    "                stat_data_aggregate.append(row)\n",
    "    else:\n",
    "        print(\"Skipping NC, no samples found...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf09bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    output_fpath = os.path.join(output_folder,  f\"loco_stattest_{dataset_type}_aggregate_{output_dtime}.xlsx\")\n",
    "    df_exp_stat_aggregate = pd.DataFrame(data=stat_data_aggregate, columns=stat_colnames)\n",
    "    df_exp_stat_aggregate.to_excel(output_fpath, index=False)\n",
    "    #with open(output_fpath, 'w', newline='\\n') as csvfile:\n",
    "    #    writer = csv.writer(csvfile, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    #    writer.writerow(stat_colnames)\n",
    "    #    for row in stat_data_aggregate:\n",
    "    #        writer.writerow(row)\n",
    "    print(f\"Saved to\\n\\t{output_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d722d95",
   "metadata": {},
   "source": [
    "### Save pooled aggregate stat results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data and pool_tmev:\n",
    "    stat_data_aggregate = []\n",
    "    for statistic in STAT_METRICS:\n",
    "        for exp_type, exp_g in stat_data_aggregate_pooled.sort_values(by=\"exp_type\").groupby(\"exp_type\"):\n",
    "            ttest_result = paired_t_test(exp_g, statistic, pair_by=\"mouse_id\")\n",
    "            t_stat = ttest_result.statistic\n",
    "            p = ttest_result.pvalue\n",
    "            row = []\n",
    "            row.append(\"CA1\")\n",
    "            row.append(statistic)\n",
    "            row.append(exp_type)\n",
    "            row.append(len(exp_g[exp_g[\"segment_type\"] == value_mapping[\"bl\"]]))\n",
    "            row.append(t_stat)\n",
    "            row.append(p)\n",
    "            stat_data_aggregate.append(row)\n",
    "    output_fpath = os.path.join(output_folder,  f\"loco_stattest_{dataset_type}_aggregate_pooled_{output_dtime}.xlsx\")\n",
    "    df_exp_stat_aggregate = pd.DataFrame(data=stat_data_aggregate, columns=stat_colnames)\n",
    "    df_exp_stat_aggregate.to_excel(output_fpath, index=False)\n",
    "    #with open(output_fpath, 'w', newline='\\n') as csvfile:\n",
    "    #    writer = csv.writer(csvfile, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    #    writer.writerow(stat_colnames)\n",
    "    #    for row in stat_data_aggregate:\n",
    "    #        writer.writerow(row)\n",
    "    print(f\"Saved to\\n\\t{output_fpath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a2c11",
   "metadata": {},
   "source": [
    "# Export analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82427918",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    \"stat_metrics\": STAT_METRICS,  # the metrics that were statistically tested\n",
    "    \"amplitude_threshold\": AMPL_THRESHOLD,  # the minimum amplitude to be reached to classify as running episode\n",
    "    \"temporal_threshold\": TEMP_THRESHOLD, # the minimum duration to be reached to classify as running episode\n",
    "    \"episode_merging_threshold_frames\" : EPISODE_MERGE_THRESHOLD_FRAMES,  # maximum allowed the duration (in frames) between two episodes to be merged into one\n",
    "    \"manually_cut_segments\" : use_manual_bl_am_length,  # bool, whether the baseline and aftermath were cut to predefined length\n",
    "    \"bl_manual_length\" : bl_manual_length,  # the manually set bl length in frames (if manually_cut_segments is True)\n",
    "    \"am_manual_length\" : am_manual_length,\n",
    "    \"segment_name_mapping\" : value_mapping,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ed97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data:\n",
    "    json_output_fpath = os.path.join(output_folder, f\"analysis_params_{dataset_type}_{output_dtime}.json\")\n",
    "    with open(json_output_fpath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(params_dict, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Parameters saved to {json_output_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927dcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26d2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d70db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caiman as cm\n",
    "import labrotation.file_handling as fh\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os.path\n",
    "import json\n",
    "from nd2_to_caiman import np_arr_from_nd2\n",
    "import scipy\n",
    "from RippleNoiseRemoval import RNR\n",
    "from time import time\n",
    "from movie_splitting import numpy_to_hdf5\n",
    "from numba import njit, prange\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d5f244",
   "metadata": {},
   "source": [
    "## Open CNMF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7226daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_fpath = fh.open_file(\"Open hdf5 caiman file\")\n",
    "print(cnmf_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf = cm.source_extraction.cnmf.cnmf.load_CNMF(cnmf_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e410d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_uuid = None\n",
    "with h5py.File(cnmf_fpath, 'r') as hf:\n",
    "    session_uuid = hf.attrs[\"uuid\"]\n",
    "print(f\"UUID of session was {session_uuid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329c1e3",
   "metadata": {},
   "source": [
    "## Open MoCo parameters and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cf807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumed naming conventions:\n",
    "# CNMF results: xy_cnmf.hdf5\n",
    "# moco parameters: xy_moco_pars.h5\n",
    "# CNMF parameters: xy_pars.json\n",
    "\n",
    "# get root file name (and path)\n",
    "# get rid of extension and \"_cnmf\" at the end\n",
    "root_fpath = \"_\".join(os.path.splitext(cnmf_fpath)[0].split(\"_\")[:-1])\n",
    "\n",
    "\n",
    "pars_fpath = root_fpath + \"_pars.json\"\n",
    "moco_pars_fpath = root_fpath + \"_moco_pars.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pars_fpath, \"r\") as json_file:\n",
    "    js = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0125eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nd2_fpath = js[\"original_fnames\"]\n",
    "print(nd2_fpath)\n",
    "print(f\"nd2 file available: {os.path.exists(nd2_fpath)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_pars = dict()\n",
    "moco_data_dict = dict()\n",
    "def bytesListToList(blist):\n",
    "    return list(map(lambda x: None if x == 'None' else x, blist.decode(\"utf-8\") .rstrip()[1:-1].split(\", \")))\n",
    "def bytesToVal(bs):\n",
    "    return None if bs == b'None' else bs.decode('utf-8') # TODO: convert to double?\n",
    "\n",
    "with h5py.File(moco_pars_fpath, \"r\") as hf:\n",
    "    for key in hf.keys():\n",
    "        moco_data_dict[key] = hf[key][()]\n",
    "\n",
    "    moco_pars[\"border_nan\"] = hf.attrs[\"border_nan\"]\n",
    "    moco_pars['uuid'] = hf.attrs[\"uuid\"]\n",
    "    moco_pars[\"var_name_hdf5\"] = hf.attrs[\"var_name_hdf5\"].decode(\"utf-8\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9a8cd",
   "metadata": {},
   "source": [
    "## Set output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64605acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set export folder for temporary files\n",
    "export_folder = fh.open_dir(\"Select folder to save results\", True)\n",
    "# export_fname: get rid of .nd2 extension, append date and .h5 extension\n",
    "export_fname = fh.get_filename_with_date(os.path.splitext(os.path.split(nd2_fpath)[1])[0] + \"_rnr_\", \".hdf5\")\n",
    "export_hd5_fpath = os.path.join(export_folder, export_fname) # nd2_fpath.split(\"/\")[-1][:-4] + \"_exp.h5\"\n",
    "print(f\"Export file selected: {export_hd5_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not(\"export_hd5_fpath\" in locals()):\n",
    "    export_hd5_fpath = fh.open_file(\"Choose hd5 file to open\")\n",
    "if export_hd5_fpath.split(\".\")[-1] != \"hdf5\":\n",
    "    print(f\"Invalid hd5 file:\\n{export_hd5_fpath}\\nChoose a valid hd5 file!\")\n",
    "    export_hd5_fpath = fh.open_file(\"Choose hd5 file to open\")\n",
    "fnames = [export_hd5_fpath]\n",
    "print(f\"Going to perform MoCo on {fnames}\")\n",
    "assert export_hd5_fpath.split(\".\")[-1] == \"hdf5\", f\"Invalid file extension: .{export_hd5_fpath.split('.')[-1]}, expected .hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f04325",
   "metadata": {},
   "source": [
    "# Extract spatial and temporal components from CNMF object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00619807",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal = cnmf.estimates.C  # FIXME: this is not the raw signal!\n",
    "spatial = cnmf.estimates.A.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1505ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"spatial: {spatial.shape}\\ntemporal: {temporal.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535accc",
   "metadata": {},
   "source": [
    "### Get segmentation values\n",
    "First, needed for checking segmentation consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35479948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version of saving intervals for MoCo and CNMF:\n",
    "if \"moco_intervals\" in js.keys():\n",
    "    moco_intervals = js[\"moco_intervals\"]\n",
    "    moco_flags = js[\"moco_flags\"]\n",
    "    cnmf_intervals = js[\"cnmf_intervals\"]\n",
    "    cnmf_flags = js[\"cnmf_flags\"]\n",
    "elif \"moco_intervals\" in moco_data_dict.keys():\n",
    "    moco_intervals = moco_data_dict[\"moco_intervals\"]\n",
    "    moco_flags = moco_data_dict[\"moco_flags\"]\n",
    "    cnmf_intervals = moco_data_dict[\"cnmf_intervals\"]\n",
    "    cnmf_flags = moco_data_dict[\"cnmf_flags\"]\n",
    "else:\n",
    "    raise Exception(\"No segmentation info found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36168007",
   "metadata": {},
   "source": [
    "# Perform RNR\n",
    "* TODO: it is not necessary to perform, as the difference is tiny to non-existent in the traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b60325",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = js[\"rnr_win\"]\n",
    "amplitude_threshold = js[\"amplitude_threshold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e50f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnr = RNR(win, amplitude_threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_open = time()\n",
    "if \"begin_end_frames\" in locals():\n",
    "    rnr.open_recording(nd2_fpath, begin_end_frames)  # opens usual recording size (8.8-9 GB) in about 830 s\n",
    "else:\n",
    "    rnr.open_recording(nd2_fpath)\n",
    "print(f\"File opened in {time() - t0_open} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c31eeb",
   "metadata": {},
   "source": [
    "### Test consistency of segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a48734",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(cnmf_intervals)):\n",
    "    gap = cnmf_intervals[i][0] - cnmf_intervals[i-1][1]\n",
    "    if gap != 1:\n",
    "        raise Exception(f\"Error in segmentation: Intervals {i} and {i+1}: {cnmf_intervals[i-1]} {cnmf_intervals[i]} are not continuous! Difference of {gap}\")\n",
    "if cnmf_intervals[0][0] != 1:\n",
    "    raise Exception(f\"Error in segmentation: does not start with frame 1: {cnmf_intervals[0]}\")\n",
    "if cnmf_intervals[-1][1] != rnr.nd2_data.shape[0]:\n",
    "    raise Exception(f\"Error in segmentation: does not seem to cover whole recording! Last segment: {cnmf_intervals[-1]}, length of movie: { rnr.nd2_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9312518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(cnmf_intervals)):\n",
    "    gap = cnmf_intervals[i][0] - cnmf_intervals[i-1][1]\n",
    "    print(f\"{cnmf_intervals[i]}\\t{gap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00eb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_core = True\n",
    "if multi_core:\n",
    "    import multiprocessing as mp\n",
    "    n_processes = mp.cpu_count() - 2  # leave some capacity for possible other notebooks etc.\n",
    "    t0_multi = time()\n",
    "    rnr_data = rnr.rnr_multithread(n_processes)  # a bit faster than opening file, around 500s for 8.8-9 GB\n",
    "    t1_multi = time()\n",
    "    print(f\"RNR multi-thread with {n_processes} processes finished in {t1_multi - t0_multi} s\")\n",
    "else:\n",
    "    t0_single = time()\n",
    "    rnr_data = rnr.rnr_singlethread()  # a bit faster than opening file, around 500s for 8.8-9 GB\n",
    "    t1_single = time()\n",
    "    print(f\"RNR single thread finished in {t1_single - t0_single} s\")\n",
    "print(f\"Result is a {type(rnr_data)} with datatype {rnr_data.dtype}\")\n",
    "print(f\"Shape: {rnr_data.shape[0]} frames of {rnr_data.shape[1]}x{rnr_data.shape[2]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa76832",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbdd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_to_hdf5(rnr_data, export_hd5_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85697e7a",
   "metadata": {},
   "source": [
    "## (Optional) Save no-rnr results to same type of hdf5 for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_nornr = False\n",
    "if compare_nornr:\n",
    "    export_hd5_fpath_nornr = os.path.splitext(export_hd5_fpath)[0] + \"_nornr.hdf5\"\n",
    "    numpy_to_hdf5(rnr.nd2_data, export_hd5_fpath_nornr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447cfdcf",
   "metadata": {},
   "source": [
    "## Clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a6df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rnr\n",
    "del rnr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35a673",
   "metadata": {},
   "source": [
    "# MoCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7c09af",
   "metadata": {},
   "source": [
    "### Get other parameters (CNMF and moco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = js[\"fr\"]                             # imaging rate in frames per second\n",
    "decay_time = js[\"decay_time\"]                  # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "strides = tuple(js[\"strides\"])          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = tuple(js[\"overlaps\"])         # overlap between pathes (size of patch strides+overlaps)\n",
    "max_shifts = tuple(js[\"max_shifts\"])          # maximum allowed rigid shifts (in pixels)\n",
    "max_deviation_rigid = js[\"max_deviation_rigid\"]     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = js[\"pw_rigid\"]             # flag for performing non-rigid motion correction\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = js[\"p\"]                       # order of the autoregressive system\n",
    "gnb = js[\"nb\"]                     # number of global background components\n",
    "merge_thr = js[\"merge_thr\"]            # merging threshold, max correlation allowed\n",
    "rf = js[\"rf\"]                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = js[\"stride\"]             # amount of overlap between the patches in pixels\n",
    "K = js[\"K\"]                       # number of components per patch\n",
    "gSig = js[\"gSig\"]               # expected half size of neurons in pixels\n",
    "method_init = js[\"method_init\"]  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = js[\"ssub\"]                    # spatial subsampling during initialization\n",
    "tsub = js[\"tsub\"]                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = js[\"min_SNR\"]               # signal to noise ratio for accepting a component\n",
    "rval_thr = js[\"rval_thr\"]              # space correlation threshold for accepting a component\n",
    "cnn_thr = js[\"min_cnn_thr\"]              # threshold for CNN based classifier\n",
    "cnn_lowest = js[\"cnn_lowest\"] # neurons with cnn probability lower than this value are rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"fnames\" not in locals():\n",
    "    fnames = fh.open_file(\"No hd5 file selected. Choose corresponding hd5 file!\")\n",
    "opts_dict = {'fnames': fnames, \n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest,\n",
    "            'var_name_hdf5': 'data',\n",
    "            'gSig' :  gSig,}  # FIXME: does not work! Check where does this setting get lost?\n",
    "\n",
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70734776",
   "metadata": {},
   "source": [
    "### Set up cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7317e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6842238",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de1df7",
   "metadata": {},
   "source": [
    "### Apply shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29153d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.x_shifts_els = moco_data_dict[\"x_shifts_els\"]\n",
    "mc.y_shifts_els = moco_data_dict[\"y_shifts_els\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f40ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_folder = os.path.split(fnames[0])[0]\n",
    "print(f\"Changing work folder to {work_folder}, this is where moco result will be saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(work_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1469aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should save in C order because cm.load_memmap() takes C-memmap. However, as the opening and closing of memmap files is \n",
    "# so confusing, I decided to try to copy the original demo_pipeline jupyter notebook as closely as I can.\n",
    "exp_fname = mc.apply_shifts_movie(fnames, save_memmap=True,order=\"F\")\n",
    "print(exp_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_mmap = os.path.join(work_folder, exp_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8c922",
   "metadata": {},
   "source": [
    "# Extract trace\n",
    "`m_els` is the memmap that contains recording, RNR + MoCo (both optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d5c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_els = cm.load(mc_mmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_els.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097903a",
   "metadata": {},
   "source": [
    "### define dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cc955",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = temporal.shape[0]\n",
    "n_frames_cut = temporal.shape[1]\n",
    "n_frames_long = m_els.shape[0]\n",
    "n_bkgd = cnmf.estimates.b.shape[1]  # number of background components. Usually 2 (or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CNMF contains temporal and spatial components of {n_neurons} neurons.\\n\\tTotal:\\t{n_frames_long} frames\\n\\tCNMF:\\t{n_frames_cut} frames\\n\\tDiff:\\t{n_frames_long-n_frames_cut} frames\\n(Diff: the frames that were cut out before running the CNMF algorithm (seizure etc.))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203ffd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check intervals are consistent with temporal size\n",
    "n_frs = 0\n",
    "for i_tup, tup in enumerate(cnmf_intervals):\n",
    "    if cnmf_flags[i_tup]:\n",
    "        n_frs += tup[1] - tup[0] + 1\n",
    "print(n_frs)\n",
    "print(n_frs == n_frames_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801fc49c",
   "metadata": {},
   "source": [
    "### create np arrays for whole traces and traces of only segments given to CNMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_weight = np.zeros(n_neurons, dtype=m_els.dtype)\n",
    "for i_neuron in range(n_neurons):\n",
    "    weight = 0\n",
    "    neuron_mask = spatial[:,i_neuron].reshape((512,512)).transpose()  # do not confuse neuron mask with elon musk\n",
    "    pixels_x, pixels_y = scipy.sparse.csc_matrix(neuron_mask).nonzero()\n",
    "    for pix_x, pix_y in zip(pixels_x, pixels_y):\n",
    "        weight += neuron_mask[pix_x, pix_y]\n",
    "    neuron_weight[i_neuron] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b266a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_data = np.asarray(m_els.data)  # TODO: apparently, this does not load memmap into file, so might even skip this step..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fefb7",
   "metadata": {},
   "source": [
    "### Reformat spatial matrix\n",
    "WARNING: currently, resolution (512x512) is hard-coded, even though other resolutions might be used. This can be resolved by reading out the CNMF parameters, or the nikon movie parameters... Must pay attention to x and y where they are not symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0041564",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = np.array(spatial)  # change type to allow np.reshape (?)\n",
    "spatial = np.reshape(spatial, (512, 512, n_neurons)) # (262144 -> 512x512, i.e. \"unflatten\")\n",
    "spatial = np.transpose(spatial, axes=[1,0,2])  # move neuron index to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9697ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Neuron components:\\nSpatial dim: {spatial.shape}\\nTemporal dim: {temporal.shape}\")\n",
    "assert spatial.shape[0] == 512\n",
    "assert spatial.shape[1] == 512\n",
    "assert spatial.shape[2] == n_neurons\n",
    "assert temporal.shape[0] == n_neurons\n",
    "assert temporal.shape[1] == n_frames_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def extract_neuron_trace():  # neuron_xy = np.array[x0, x1, ..., xn; y0, y1, ..., yn], 2 rows, n columns\n",
    "    traces_par = np.zeros((n_neurons, n_frames_long), dtype=moco_data.dtype)\n",
    "    for i_neuron in prange(n_neurons):\n",
    "        pixels_x, pixels_y = spatial[:,:,i_neuron].nonzero()\n",
    "        trace = np.zeros((n_frames_long,), dtype=moco_data.dtype)\n",
    "        for i_frame in range(n_frames_long):\n",
    "            trace_val = 0.\n",
    "            spatial_bkgd = 0.\n",
    "            i_pix = 0\n",
    "            while i_pix < pixels_x.shape[0]:\n",
    "                pix_neuron_value = spatial[pixels_x[i_pix], pixels_y[i_pix], i_neuron]*moco_data[i_frame, pixels_x[i_pix], pixels_y[i_pix]]\n",
    "                trace_val = trace_val + pix_neuron_value\n",
    "                i_pix = i_pix + 1\n",
    "            traces_par[i_neuron, i_frame] = trace_val\n",
    "        #np.sum(moco_data[:, pixels_x, pixels_y]*spatial[pixels_x, pixels_y, i_neuron], axis=1)\n",
    "    return traces_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_complete = extract_neuron_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_par = np.sum(spatial, axis=(0,1))  # calculate total weight (sum of spatial values) per neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create normalized traces. Logic behind normalization is that the higher the spatial values, the more stronger the neuron is.\n",
    "traces_complete_norm = np.divide(traces_complete, weights_par[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf92ffe5",
   "metadata": {},
   "source": [
    "# Copy CNMF traces, fill missing segment values with manually extracted trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13013522",
   "metadata": {},
   "source": [
    "## Extract CNMF \"raw\" trace (is it?) as seen in nb_view_components (blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54423a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnmf.estimates.nb_view_components(denoised_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c86e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.reshape(np.array(cnmf.estimates.A.mean(axis=1)), cnmf.estimates.dims, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafecd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yr = cm.utils.visualization.nb_view_patches(\n",
    "                None, cnmf.estimates.A, cnmf.estimates.C, cnmf.estimates.b, cnmf.estimates.f, cnmf.estimates.dims[0], cnmf.estimates.dims[1],\n",
    "                YrA=cnmf.estimates.R, image_neurons=img, thr=0.99, denoised_color=\"red\", cmap=\"jet\",\n",
    "                r_values=cnmf.estimates.r_values, SNR=cnmf.estimates.SNR_comp, cnn_preds=cnmf.estimates.cnn_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc126137",
   "metadata": {},
   "source": [
    "## Project CNMF \"raw\" trace onto whole movie, fill difference with manual trace\n",
    "The trace extracted by CNMF is shorter than the whole movie, and without the gaps (i.e. if CNMF was not performed on frames 10-20, then instead of 1-9, (10-20), 21-30, (31-40), 41-N as trace, we have 1-(N-21) consecutive frames. Using the cnmf intervals and corresponding flags, create a mapping between the original 1-N frames and the shortened version. I.e. to access the CNMF value for frame 21, using this mapping would give us the frame 10 (9 in 0-indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad37d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_traces = np.zeros(shape=(n_neurons, n_frames_long), dtype=cnmf.estimates.C.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941189e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_segment in range(2, len(cnmf_intervals)):\n",
    "    if not (cnmf_intervals[i_segment-1][1] == cnmf_intervals[i_segment][0] - 1):\n",
    "        print(i_segment)\n",
    "        print(cnmf_intervals[i_segment-1])\n",
    "        print(cnmf_intervals[i_segment])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create adjusted intervals with index = i_segment, and value (i_beginning_whole, i_end_whole).\n",
    "\n",
    "cnmf_intervals_adjusted = cnmf_intervals[cnmf_flags].copy()\n",
    "i_segment_adjusted = 0\n",
    "current_gap = 0\n",
    "\n",
    "for i_segment, segment in enumerate(cnmf_intervals):\n",
    "    if cnmf_flags[i_segment]:  # cnmf was performed on this segment\n",
    "        # only adjust for the current indexing gap in the beginning and end frames\n",
    "        cnmf_intervals_adjusted[i_segment_adjusted][0] -= current_gap\n",
    "        cnmf_intervals_adjusted[i_segment_adjusted][1] -= current_gap\n",
    "        print(f\"{segment}\\t{cnmf_intervals_adjusted[i_segment_adjusted]}\\t{current_gap}\\t{cnmf_flags[i_segment]}\")\n",
    "        i_segment_adjusted += 1\n",
    "    else:  # cnmf was not performed; add segment length to current_gap\n",
    "        seg_len = segment[1] - segment[0] + 1  # e.g. [1, 10] has length 10\n",
    "        current_gap += seg_len\n",
    "        print(f\"{segment}\\t\\t\\t{current_gap}\\t{cnmf_flags[i_segment]}\")\n",
    "    \n",
    "\n",
    "#if len(cnmf_intervals_adjusted) == 1:\n",
    "#    diff = cnmf_intervals_adjusted[0][0] - 1\n",
    "#    cnmf_intervals_adjusted[0][0] -= diff\n",
    "#    cnmf_intervals_adjusted[0][1] -= diff\n",
    "#else:\n",
    "#    for i in range(1, len(cnmf_intervals_adjusted)):\n",
    "#        segment_dist = cnmf_intervals_adjusted[i][1] - cnmf_intervals_adjusted[i][0]  # e.g. [1, 10] -> 1+9=10, so dist=10=10-1\n",
    "#        cnmf_intervals_adjusted[i][0] = cnmf_intervals_adjusted[i-1][1] + 1\n",
    "#        cnmf_intervals_adjusted[i][1] = cnmf_intervals_adjusted[i][0] + segment_dist\n",
    "\n",
    "assert cnmf_intervals_adjusted[0][0] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd932c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_index = 0 \n",
    "len_temporal = 0  # total length of cnmf=True segments; should match length of temporal\n",
    "for i_seg, seg in enumerate(cnmf_intervals):\n",
    "    if cnmf_flags[i_seg]:\n",
    "        # test all matching segments have same length\n",
    "        assert cnmf_intervals_adjusted[adjusted_index][1] - cnmf_intervals_adjusted[adjusted_index][0] == seg[1]-seg[0]\n",
    "        len_temporal += seg[1] - seg[0] + 1\n",
    "        adjusted_index += 1\n",
    "assert len_temporal == temporal.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(cnmf_intervals_adjusted)):\n",
    "    if not (cnmf_intervals_adjusted[i][0] - cnmf_intervals_adjusted[i-1][1]) == 1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_intervals[53:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a314fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_intervals_adjusted[53:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d76b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_cnmf_segment = 0\n",
    "# copy either cnmf trace or manually extracted trace to the segment.\n",
    "for i_interval, interval in enumerate(cnmf_intervals):\n",
    "    if cnmf_flags[i_interval]:  # cnmf was performed on this segment; just copy trace to right position\n",
    "        for i_neuron in range(n_neurons):\n",
    "            cnmf_traces[i_neuron, interval[0]-1 : interval[1]] = Yr[i_neuron, cnmf_intervals_adjusted[i_cnmf_segment][0]-1:cnmf_intervals_adjusted[i_cnmf_segment][1]]  # careful about 1-indexing\n",
    "        i_cnmf_segment += 1\n",
    "    else:  # need to fill segment with manual traces\n",
    "        for i_neuron in range(n_neurons):\n",
    "            cnmf_traces[i_neuron, interval[0]-1:interval[1]] = traces_complete[i_neuron, interval[0]-1:interval[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7daab4a",
   "metadata": {},
   "source": [
    "# Shift baseline to match manual trace to cnmf signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11964ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_neuron in range(n_neurons):\n",
    "    baseline_diff = np.median(traces_complete[i_neuron,:] - cnmf_traces[i_neuron,:])\n",
    "    for i_interval, interval in enumerate(cnmf_intervals):\n",
    "        if not cnmf_flags[i_interval]:\n",
    "            for i_frame in range(interval[0]-1, interval[1]):  #interval 1-indexed, e.g. [1, 10]; convert to 0, ..., 9 (inclusive)\n",
    "                cnmf_traces[i_neuron, i_frame] -= baseline_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61d14f",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e88f42",
   "metadata": {},
   "source": [
    "### Compare cnmf raw signal with signal extracted from spatial x nd2 fluorescence averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_NEU = 40\n",
    "fig = plt.figure(figsize=(18,10))\n",
    "plt.plot(traces_complete[I_NEU], linewidth=0.5, color=\"blue\")  # pure raw data\n",
    "plt.plot(cnmf_traces[I_NEU], linewidth=0.5, color=\"black\")  # cnmf intertwined with raw extracted segments\n",
    "plt.plot(traces_complete[I_NEU]-cnmf_traces[I_NEU], color=\"yellow\")\n",
    "#plt.plot(cnmf_traces[20] + np.median(traces_complete[20] - cnmf_traces[20]), linewidth=3)\n",
    "ax = plt.gca()\n",
    "#ax.set_xlim((2000,3000))\n",
    "plt.show()\n",
    "# TODO: watch MoCo video to see (1359 T352) if something goes wrong there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7cec0",
   "metadata": {},
   "source": [
    "# Optional: compare with no-rnr data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if compare_nornr:\n",
    "    nornr_data = np_arr_from_nd2(nd2_fpath)\n",
    "    numpy_to_hdf5(nornr_data, export_hd5_fpath_nornr)\n",
    "    work_folder_nornr = # TODO: compare with no RNR!\n",
    "    os.mkdir(work_folder_nornr)\n",
    "    print(f\"Changing to {work_folder_nornr}\")\n",
    "    os.chdir(work_folder_nornr)\n",
    "    fnames_nornr = [export_hd5_fpath_nornr]\n",
    "    mc_nornr = MotionCorrect(fnames_nornr, dview=dview, **opts.get_group('motion'))\n",
    "    mc_nornr.x_shifts_els = moco_data_dict[\"x_shifts_els\"]\n",
    "    mc_nornr.y_shifts_els = moco_data_dict[\"y_shifts_els\"]\n",
    "    # should save in C order because cm.load_memmap() takes C-memmap. However, as the opening and closing of memmap files is \n",
    "    # so confusing, I decided to try to copy the original demo_pipeline jupyter notebook as closely as I can.\n",
    "    exp_fname_nornr = mc.apply_shifts_movie(fnames_nornr, save_memmap=True,order=\"F\")\n",
    "    print(exp_fname_nornr)\n",
    "    mc_mmap_nornr = os.path.join(work_folder_nornr, exp_fname_nornr)\n",
    "    m_els_nornr = cm.load(mc_mmap_nornr)\n",
    "    moco_data = np.asarray(m_els_nornr)\n",
    "    traces_nornr = extract_neuron_trace()\n",
    "    moco_data = np.asarray(m_els)\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    plt.plot(traces_complete[20], linewidth=0.5, color=\"blue\")  # pure raw data\n",
    "    plt.plot(traces_nornr[20], linewidth=0.5, color=\"green\")\n",
    "    plt.plot(traces_complete[20]-traces_nornr[20], linewidth=0.5, color=\"yellow\")\n",
    "    #plt.plot(cnmf_traces[20] + np.median(traces_complete[20] - cnmf_traces[20]), linewidth=3)\n",
    "    plt.show()\n",
    "    rnr_diff = traces_complete - traces_nornr\n",
    "    print(rnr_diff.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0307a",
   "metadata": {},
   "source": [
    "# TODO: use Nikon metadata to export time stamps in hdf5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ac704",
   "metadata": {},
   "source": [
    "# Save traces and spatial masks to hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ce73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_fname = os.path.split(moco_pars_fpath)[-1][:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming the naming convention:\n",
    "# moco_pars_fname = root_fpath + \"_moco_pars.h5\":\n",
    "root_fname = os.path.split(moco_pars_fpath)[-1][:-13]\n",
    "whole_traces_h5_fname = root_fname + \"_traces.h5\"\n",
    "whole_traces_h5_fpath = os.path.join(export_folder, whole_traces_h5_fname)\n",
    "print(f\"Saving traces to\\n{whole_traces_h5_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from Pure Python Pipeline Splitting notebook\n",
    "utf8_type = h5py.string_dtype('utf-8', 30)\n",
    "def append_dataset(h5_file, name, data):\n",
    "    if (type(data) is tuple and type(data[0]) is slice) \\\n",
    "    or \\\n",
    "    data is None \\\n",
    "    or \\\n",
    "    type(data) is str \\\n",
    "    or \\\n",
    "    (type(data) is list and (data[0] is None or type(data[0]) is str)):  \n",
    "        # some entries (e.g. indices) are a tuple of slices\n",
    "        # some entries are of type string, are None, [None, None, ...] or [\"...\"]\n",
    "        # convert these types to string (easiest way to preserve information about format)\n",
    "        #data_arr = np.array(, dtype=utf8_type)\n",
    "        hf.attrs[name] = data.__str__().encode(\"utf-8\")\n",
    "    else:\n",
    "        data_arr = np.array(data)\n",
    "        dataset = h5_file.create_dataset(name, data_arr.shape, data_arr.dtype)\n",
    "        if len(data_arr.shape) == 0:\n",
    "            dataset = data_arr\n",
    "        else:\n",
    "            for i in range(data_arr.shape[0]):\n",
    "                dataset[i] = data_arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8438de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(cnmf_fpath, \"r\") as hf:\n",
    "    A_data = hf[\"estimates\"][\"A\"][\"data\"][()]\n",
    "    A_indptr = hf[\"estimates\"][\"A\"][\"indptr\"][()]\n",
    "    A_indices = hf[\"estimates\"][\"A\"][\"indices\"][()]\n",
    "    A_shape = hf[\"estimates\"][\"A\"][\"shape\"][()]\n",
    "# test that spatial to be exported is same as cnmf object's spatial components\n",
    "spatial2 = scipy.sparse.csc.csc_matrix((A_data, A_indices, A_indptr), shape=A_shape)\n",
    "assert (spatial2.todense() == cnmf.estimates.A.todense()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a0f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test moco intervals, flags, cnmf flags saved format\n",
    "with h5py.File(whole_traces_h5_fpath, 'w') as hf:\n",
    "    print(\"Adding uuid\")\n",
    "    hf.attrs[\"uuid\"] = session_uuid\n",
    "    print(\"Adding MoCo intervals\")\n",
    "    append_dataset(hf, \"moco_intervals\", moco_intervals)\n",
    "    print(\"Adding MoCo flags\")\n",
    "    append_dataset(hf, \"moco_flags\", moco_flags)\n",
    "    print(\"Adding cnmf_intervals\")\n",
    "    append_dataset(hf, \"cnmf_intervals\", cnmf_intervals)\n",
    "    print(\"Adding cnmf_flags\")\n",
    "    append_dataset(hf, \"cnmf_flags\", cnmf_flags)\n",
    "    print(\"Adding begin_end_frames\")\n",
    "    append_dataset(hf, \"begin_end_frames\", moco_data_dict[\"begin_end_frames\"])\n",
    "    print(\"Saving spatial...\")\n",
    "    spatial_group = hf.create_group(\"spatial\")  # save \"spatial\" as-is takes up more space but easier to access\n",
    "    spatial_group.create_dataset(\"data\", data=A_data)\n",
    "    spatial_group.create_dataset(\"indices\", data=A_indices)\n",
    "    spatial_group.create_dataset(\"indptr\", data=A_indptr)\n",
    "    spatial_group.create_dataset(\"shape\", data=A_shape)\n",
    "    print(\"Saving traces...\")\n",
    "    hf.create_dataset(\"traces\", data=traces_complete)\n",
    "print(f\"Saved listed parameters and data in\\n\\t{whole_traces_h5_fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d3d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1420ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b3758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create another dictionary with nd2 average fluorescence; extract it for each session.\n",
    "# TODO: save the extracted data in a h5 file or something similar. Do session extraction for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labrotation.file_handling as fh\n",
    "import h5py\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps\n",
    "import seaborn as sns\n",
    "import uuid  # for unique labeling of sessions and coupling arrays (mouse velocity, distance, ...) to sessions in dataframe \n",
    "from matplotlib import cm  # colormap\n",
    "import datadoc_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8f953",
   "metadata": {},
   "source": [
    "# If exists, load environmental variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00918713",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aaf40d",
   "metadata": {},
   "source": [
    "# Set up data documentation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: inside the documentation folder, the subfolders carry the id of each mouse (not exact necessarily, but they \n",
    "# can be identified by the name of the subfolder). \n",
    "# Inside the subfolder xy (for mouse xy), xy_grouping.xlsx and xy_segmentation.xlsx can be found.\n",
    "# xy_grouping.xlsx serves the purpose of finding the recordings belonging together, and has columns:\n",
    "# folder, nd2, labview, lfp, face_cam_last, nikon_meta, experiment_type, day\n",
    "# xy_segmentation.xlsx contains frame-by-frame (given by a set of disjoint intervals forming a cover for the whole recording) \n",
    "# classification of the events in the recording (\"normal\", seizure (\"sz\"), sd wave (\"sd_wave\") etc.). The columns:\n",
    "# folder, interval_type, frame_begin, frame_end.\n",
    "\n",
    "# TODO: write documentation on contents of xlsx files (what the columns are etc.)\n",
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    docu_folder = fh.open_dir(\"Choose folder containing folders for each mouse!\")\n",
    "print(f\"Selected folder:\\n\\t{docu_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3cedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"documentation\" in os.listdir(docu_folder):\n",
    "    mouse_folder = os.path.join(docu_folder, \"documentation\")\n",
    "else:\n",
    "    mouse_folder = docu_folder\n",
    "mouse_names = os.listdir(mouse_folder)\n",
    "print(f\"Mice detected:\")\n",
    "for mouse in mouse_names:\n",
    "    print(f\"\\t{mouse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8133420",
   "metadata": {},
   "source": [
    "### Load matlab-2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"MATLAB_2P_FOLDER\" in env_dict.keys():\n",
    "    matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]\n",
    "else:\n",
    "    matlab_2p_folder = fh.open_dir(\"Choose matlab-2p folder\")\n",
    "print(f\"matlab-2p folder set to:\\n\\t{matlab_2p_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg_complete = pd.DataFrame(columns = [\"nd2\", \"interval_type\", \"frame_begin\", \"frame_end\"])\n",
    "df_grouping_complete = pd.DataFrame(columns = [\"folder\", \"nd2\", \"labview\", \"lfp\", \"face_cam_last\", \"nikon_meta\", \"experiment_type\", \"mouse_id\", \"day\"])\n",
    "\n",
    "for mouse_id in mouse_names:\n",
    "    print(mouse_id)\n",
    "    seg_fpath = os.path.join(mouse_folder, mouse_id, mouse_id + '_segmentation.xlsx')\n",
    "    grouping_fpath = os.path.join(mouse_folder, mouse_id, mouse_id + '_grouping.xlsx')\n",
    "    if os.path.exists(seg_fpath) and os.path.exists(grouping_fpath):\n",
    "        df_seg = pd.read_excel(seg_fpath)\n",
    "        df_grouping = pd.read_excel(grouping_fpath)\n",
    "        df_grouping[\"mouse_id\"] = mouse_id\n",
    "        # select only tmev, chr2_szsd, chr2_sd, chr2_ctl experiment data first\n",
    "        df_grouping = df_grouping[df_grouping[\"experiment_type\"].isin([\"tmev\", \"tmev_ctl\", \"chr2_sd\", \"chr2_szsd\", \"chr2_ctl\"])]\n",
    "        # merge into large dataframes\n",
    "        # print(f\"\\tseg bef: {len(df_seg_complete['nd2'])}\")\n",
    "        df_seg_complete = pd.concat([df_seg_complete, df_seg])\n",
    "        # print(f\"\\tseg aft: {len(df_seg_complete['nd2'])}\")\n",
    "        # print(f\"\\tgro bef: {len(df_grouping_complete['nd2'])}\")\n",
    "        df_grouping_complete = pd.concat([df_grouping_complete, df_grouping])\n",
    "        # print(f\"\\tgro aft: {len(df_grouping_complete['nd2'])}\")\n",
    "    else:\n",
    "        print(f\"Check if you set the correct folder (folder containing all subfolders with mouse names):\")\n",
    "        if not os.path.exists(seg_fpath):\n",
    "            print(f\"\\t{seg_fpath} not found\")\n",
    "        if not os.path.exists(grouping_fpath):\n",
    "            print(f\"\\t{grouping_fpath} not found\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "docu_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1139760",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = datadoc_util.DataDocumentation(docu_folder)\n",
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only recordings that were classified as \"tmev\" (experiment type)\n",
    "df_seg_complete.where(df_seg_complete[\"nd2\"].isin(df_grouping_complete[\"nd2\"].unique()), inplace=True)\n",
    "# wrong recording types changed to NaN; drop them\n",
    "df_seg_complete.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b44926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create new dataframe. \n",
    "# x axis will be: baseline, seizure, sd_wave, sd_extinction, aftermath...\n",
    "# one plot: only with seizures \n",
    "#   (check categories: chr2_sz/chr2_szsd? tmev_sz? check interval types corresponding to seizure, sd etc.)\n",
    "# other plot: chr2 only?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80ccaf6",
   "metadata": {},
   "source": [
    "# Baseline - Seizure - SD - aftermath analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only videos with seizure\n",
    "df_sz = df_seg_complete.groupby(\"nd2\").filter(lambda group: \"sz\" in group[\"interval_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514caa5",
   "metadata": {},
   "source": [
    "## Add uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318fe799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz = pd.merge(df_sz, ddoc.getNikonFileNameUuid().dropna(), on=\"nd2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423aa4a",
   "metadata": {},
   "source": [
    "## Add seizure-uuid\n",
    "See 4 Directionality analysis for original context. This code should be the same as there! (If update needed, need to extract into third file!)\n",
    "In this analysis, the purpose is to make each seizure unique (to deal with seizures split-up in two videos, for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz[\"uuid_sz\"] = df_sz[\"uuid\"]\n",
    "# following two recordings contain 1 seizure-sd event\n",
    "df_sz[\"uuid_sz\"] = df_sz[\"uuid_sz\"].replace(\"65bff16a4cf04930a5cb14f489a8f99b\", \"30dc55d1a5dc4b0286d132e72f208ca6\")\n",
    "# following recordings do not have sz\n",
    "#qdf = qdf[qdf[\"uuid_matched\"] != \"171693d0988c458a96c8198c7b8cfc28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ba21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz[df_sz[\"uuid_sz\"] == \"30dc55d1a5dc4b0286d132e72f208ca6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7daee5",
   "metadata": {},
   "source": [
    "# Old analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9617a272",
   "metadata": {},
   "source": [
    "### TODO: some recordings start with non-\"normal\" event type! How to deal with these? E.g. fake-handling!\n",
    "### TODO: test if _nik.txt is read correctly for stimulations (where first column has weird format)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change labels of segments that start the video until seizure as \"baseline\"\n",
    "df_sz.loc[(df_sz[\"interval_type\"] == \"normal\") & (df_sz[\"frame_begin\"] == 1.0), \"interval_type\"] = \"baseline\"\n",
    "# assuming one seizure per video, and that there is no \"normal\" labeling between \"abnormal\" events like SZ and SD, \n",
    "#   change label to aftermath\n",
    "# TODO: change this to frame_end == len(recording)? i.e. last part in video?\n",
    "df_sz.loc[(df_sz[\"interval_type\"] == \"normal\") & (df_sz[\"frame_begin\"] != 1.0), \"interval_type\"] = \"aftermath\"  # second criterion is not even necessary anymore..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: some recordings have iis between \"normal\". Change them to normal to include them in movement statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_grouping_complete[\"nd2\"]) == len(df_grouping_complete[\"nd2\"].unique())  # grouping should be unique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_vids = df_sz[\"nd2\"].unique()\n",
    "df_sz_grouping = df_grouping_complete[df_grouping_complete[\"nd2\"].isin(sz_vids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sz_grouping[\"nd2\"]) == len(df_sz_grouping[\"nd2\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca1421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_grouping.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbedc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tps.from_hdf5()  # TODO: try opening sessions. If works properly, adjust script below to take hdf5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab7802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: rename row to row_grouping, row2 to row_segment\n",
    "\n",
    "sz_nd2s = list()  # should contain nd2 file names for backtracking\n",
    "sz_segments_speed_dict = dict()\n",
    "sz_segments_dist_dict = dict()\n",
    "sz_segments_totdist_dict = dict()\n",
    "sz_segments_rounds_dict = dict()\n",
    "sz_segments_tsscn_dict = dict()\n",
    "sz_segments_running_dict = dict()\n",
    "\n",
    "df_sz_res_cols = {\"mouse_id\": [], \"experiment_type\": [], \"interval_type\": [], \"distance\": [], \"d_frames\": [], \"dt\": []}\n",
    "\n",
    "# for each recording in category, create session, \n",
    "# perform labview cut to scanner timeframe, \n",
    "# then extract relevant frame movement data\n",
    "# results appended to segments_dict entries.\n",
    "# segments_dict should contain, for each key (type of interval) all the corresponding data from all videos\n",
    "for index, row in df_sz_grouping.iterrows():\n",
    "    labview_fpath = os.path.join(row[\"folder\"], row[\"labview\"])\n",
    "    nikmeta_fpath = os.path.join(row[\"folder\"], row[\"nikon_meta\"])\n",
    "    #TODO: instead of running the functions below, use init_and_process() constructor!\n",
    "    ses = tps.TwoPhotonSession(nd2_timestamps_path=nikmeta_fpath, labview_path=labview_fpath, matlab_2p_folder=matlab_2p_folder)\n",
    "    ses.infer_labview_timestamps()\n",
    "    ses._open_data()  # TODO: implement a better way than using \"private\" function.\n",
    "    ses_segments = df_sz[df_sz[\"nd2\"]==row[\"nd2\"]]  # get all segments from the same file\n",
    "    for index2, row2 in ses_segments.iterrows():\n",
    "        t0 = int(row2[\"frame_begin\"] - 1)  # correct 1-indexing to 0-indexing, convert to int\n",
    "        t1 = int(row2[\"frame_end\"])  # list[a:b] returns elements a to (b-1), so no need to subtract here\n",
    "        \n",
    "        # Check if dictionary entries exist\n",
    "        if row2[\"interval_type\"] not in sz_segments_speed_dict.keys():\n",
    "            sz_segments_speed_dict[row2[\"interval_type\"]] = []\n",
    "        if row2[\"interval_type\"] not in sz_segments_dist_dict.keys():   \n",
    "            sz_segments_dist_dict[row2[\"interval_type\"]] = []\n",
    "        if row2[\"interval_type\"] not in sz_segments_totdist_dict.keys():     \n",
    "            sz_segments_totdist_dict[row2[\"interval_type\"]] = []\n",
    "        if row2[\"interval_type\"] not in sz_segments_rounds_dict.keys():    \n",
    "            sz_segments_rounds_dict[row2[\"interval_type\"]] = []\n",
    "        if row2[\"interval_type\"] not in sz_segments_tsscn_dict.keys():    \n",
    "            sz_segments_tsscn_dict[row2[\"interval_type\"]] = []\n",
    "        if row2[\"interval_type\"] not in sz_segments_running_dict.keys():    \n",
    "            sz_segments_running_dict[row2[\"interval_type\"]] = []\n",
    "        \n",
    "        # append to dictionaries and nd2 list\n",
    "        sz_nd2s.append(row[\"nd2\"])\n",
    "        sz_segments_speed_dict[row2[\"interval_type\"]].append(deepcopy(ses.belt_scn_dict[\"speed\"][t0:t1]))\n",
    "        sz_segments_dist_dict[row2[\"interval_type\"]].append(deepcopy(ses.belt_scn_dict[\"distance\"][t0:t1]))\n",
    "        sz_segments_totdist_dict[row2[\"interval_type\"]].append(deepcopy(ses.belt_scn_dict[\"totdist\"][t0:t1]))\n",
    "        sz_segments_rounds_dict[row2[\"interval_type\"]].append(deepcopy(ses.belt_scn_dict[\"rounds\"][t0:t1]))\n",
    "        sz_segments_tsscn_dict[row2[\"interval_type\"]].append(deepcopy(ses.belt_scn_dict[\"tsscn\"][t0:t1]))\n",
    "        sz_segments_running_dict[row2[\"interval_type\"]].append(deepcopy(ses.belt_scn_dict[\"running\"][t0:t1]))\n",
    "        \n",
    "        # append to dataframe columns\n",
    "        df_sz_res_cols[\"mouse_id\"].append(row[\"mouse_id\"])\n",
    "        df_sz_res_cols[\"experiment_type\"].append(row[\"experiment_type\"])\n",
    "        df_sz_res_cols[\"interval_type\"].append(row2[\"interval_type\"])\n",
    "        df_sz_res_cols[\"distance\"].append(ses.belt_scn_dict[\"totdist\"][t1-1] - ses.belt_scn_dict[\"totdist\"][t0])  # t1 is 1-indexed, t0 0-indexed, see above\n",
    "        df_sz_res_cols[\"d_frames\"].append(t1 - 1 - t0)  # t1 is 1-indexed, t0 0-indexed, see above\n",
    "        # dt: in ms\n",
    "        df_sz_res_cols[\"dt\"].append(ses.belt_scn_dict[\"tsscn\"][t1-1] - ses.belt_scn_dict[\"tsscn\"][t0]) # t1 is 1-indexed, t0 0-indexed, see above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01cd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df from dict:\n",
    "df_sz_res = pd.DataFrame.from_dict(df_sz_res_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ba1a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize distance by the interval length \n",
    "# also take absolute value; especially during shorter intervals, mice might step backwards a few times and that's it \n",
    "df_sz_res[\"dist_norm\"] = abs(df_sz_res[\"distance\"]/df_sz_res[\"dt\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208be902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_res[\"mouse_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787af558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo work with dataframe, seaborn plot. if fine, use chr2 too (ctl stim vs szsd, vs sd only. need more sd only?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58085f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. open 2psession for each nd2, do matching. Need nd2? or only nd2 meta + labview. Latter would be much quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create df from results! With ID, exp type, interval type...\n",
    "# TODO: visualize data somehow. Take code from below (Unorganized)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ead889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result dataframe could be:\n",
    "# ID, interval_type, distance, dt, distance_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35283316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_res[\"interval_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_res[\"experiment_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: convert iis to normal for the sake of locomotion analysis?\n",
    "# TODO: add more recordings with seizures. Don't need complete tmev groupings for now... Only videos with seizures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5638737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_res[\"interval_type_renamed\"] = df_sz_res[\"interval_type\"].replace({\"sd_wave_cx\": \"sd_wave\"})\n",
    "df_sz_res[\"experiment_type_renamed\"] = df_sz_res[\"experiment_type\"].replace({\"tmev\": \"TMEV\", \"chr2_szsd\": \"ChR2\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e2313",
   "metadata": {},
   "source": [
    "# Save dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f6fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_dir = fh.open_dir(\"Choose folder for saving dataframe\")\n",
    "df_sz_res_fname = fh.get_filename_with_date(\"loco_analysis\", extension='.h5')\n",
    "df_out_fpath = os.path.join(df_output_dir, df_sz_res_fname)\n",
    "\n",
    "df_sz_res.to_hdf(df_out_fpath, key='df_sz_res', mode='a')\n",
    "df_seg.to_hdf(df_out_fpath, key='df_seg', mode='a')\n",
    "df_seg_complete.to_hdf(df_out_fpath, key='df_seg_complete', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164b48f",
   "metadata": {},
   "source": [
    "### Check for consistency after saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40256b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sz_res2 = pd.read_hdf(df_out_fpath, key='df_sz_res')\n",
    "# df_seg2= pd.read_hdf(df_out_fpath, key='df_seg')\n",
    "# df_seg_complete2 = pd.read_hdf(df_out_fpath, key='df_seg_complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "#sns.set(rc={'figure.figsize':(20.7,8.27)})\n",
    "\n",
    "# use standard error or standard deviation for uncertainty/spread, or confidence interval or percentile interval\n",
    "# se/sd/ci/pi\n",
    "# see https://seaborn.pydata.org/tutorial/error_bars.html\n",
    "g = sns.catplot(\n",
    "    data=df_sz_res, kind=\"bar\",\n",
    "    x=\"interval_type_renamed\", y=\"dist_norm\", hue=\"experiment_type_renamed\",\n",
    "    errorbar=(\"pi\", 50), alpha=.8, height=12, aspect=1.3\n",
    ");\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"(distance) / (interval length)\", fontsize=22)\n",
    "g.set_xticklabels([\"Baseline\", \"Seizure\", \"SD Wave\", \"SD Extinction\", \"Aftermath\", \"IIS\", \"Stimulation\"], fontsize=18)\n",
    "g.set_yticklabels(fontsize=18)\n",
    "g._legend.set_title(\"Experiment type\")\n",
    "plt.setp(g._legend.get_title(), fontsize=20);\n",
    "plt.setp(g._legend.get_texts(),  fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "#sns.set(rc={'figure.figsize':(20.7,8.27)})\n",
    "\n",
    "# use standard error or standard deviation for uncertainty/spread, or confidence interval or percentile interval\n",
    "# se/sd/ci/pi\n",
    "# see https://seaborn.pydata.org/tutorial/error_bars.html\n",
    "g = sns.catplot(\n",
    "    data=df_sz_res, kind=\"strip\",\n",
    "    x=\"interval_type_renamed\", y=\"dist_norm\", hue=\"experiment_type_renamed\",\n",
    "    errorbar=(\"pi\", 50), alpha=0.8, height=12, aspect=1.3, size=12\n",
    ");\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"(distance) / (interval length)\", fontsize=22)\n",
    "g.set_xticklabels([\"Baseline\", \"Seizure\", \"SD Wave\", \"SD Extinction\", \"Aftermath\", \"IIS\", \"Stimulation\"], fontsize=18)\n",
    "g.set_yticklabels(fontsize=18)\n",
    "g._legend.set_title(\"Experiment type\")\n",
    "plt.setp(g._legend.get_title(), fontsize=20);\n",
    "plt.setp(g._legend.get_texts(),  fontsize=18);\n",
    "g.set(ylim=(-0.003,0.06));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6906acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sz_res[(df_sz_res[\"interval_type_renamed\"] == \"baseline\") & (df_sz_res[\"experiment_type\"] == \"tmev\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4bbc2",
   "metadata": {},
   "source": [
    "# Compare ChR2 SD vs SZSD running statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only videos with seizure\n",
    "df_stim = df_seg_complete.groupby(\"nd2\").filter(lambda group: \"stimulation\" in group[\"interval_type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change labels of segments that start the video until seizure as \"baseline\"\n",
    "df_stim.loc[(df_stim[\"interval_type\"] == \"normal\") & (df_stim[\"frame_begin\"] == 1.0), \"interval_type\"] = \"baseline\"\n",
    "# assuming one seizure per video, and that there is no \"normal\" labeling between \"abnormal\" events like SZ and SD, \n",
    "#   change label to aftermath\n",
    "# TODO: change this to frame_end == len(recording)? i.e. last part in video?\n",
    "df_stim.loc[(df_stim[\"interval_type\"] == \"normal\") & (df_stim[\"frame_begin\"] != 1.0), \"interval_type\"] = \"aftermath\"  # second criterion is not even necessary anymore..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_vids = df_stim[\"nd2\"].unique()\n",
    "df_stim_grouping = df_grouping_complete[df_grouping_complete[\"nd2\"].isin(stim_vids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b3df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_stim_grouping[\"nd2\"]) == len(df_stim_grouping[\"nd2\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: integrate this in sz for loop for faster re-run of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75508f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7beac4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: rename row to row_grouping, row2 to row_segment\n",
    "\n",
    "stim_segments_speed_dict = dict()\n",
    "stim_segments_dist_dict = dict()\n",
    "stim_segments_totdist_dict = dict()\n",
    "stim_segments_rounds_dict = dict()\n",
    "stim_segments_tsscn_dict = dict()\n",
    "stim_segments_running_dict = dict()\n",
    "\n",
    "df_stim_res_cols = {\"mouse_id\": [], \"experiment_type\": [], \"interval_type\": [], \"distance\": [], \"d_frames\": [], \"dt\": [], \"uid\": []}\n",
    "\n",
    "# for each recording in category, create session, \n",
    "# perform labview cut to scanner timeframe, \n",
    "# then extract relevant frame movement data\n",
    "# results appended to segments_dict entries.\n",
    "# segments_dict should contain, for each key (type of interval) all the corresponding data from all videos\n",
    "for index, row in df_stim_grouping.iterrows():\n",
    "    labview_fpath = os.path.join(row[\"folder\"], row[\"labview\"])\n",
    "    nikmeta_fpath = os.path.join(row[\"folder\"], row[\"nikon_meta\"])\n",
    "    \n",
    "    ses = tps.TwoPhotonSession(nd2_timestamps_path=nikmeta_fpath, labview_path=labview_fpath, matlab_2p_folder=matlab_2p_folder)\n",
    "    ses.infer_labview_timestamps()\n",
    "    ses._open_data()  # TODO: implement a better way than using \"private\" function\n",
    "    ses_segments = df_stim[df_stim[\"nd2\"]==row[\"nd2\"]]  # get all segments from the same file\n",
    "    for index2, row2 in ses_segments.iterrows():\n",
    "        uid = uuid.uuid1()  # unique ID of segment, for matching segment labview data with dataframe row\n",
    "        t0 = int(row2[\"frame_begin\"] - 1)  # correct 1-indexing to 0-indexing, convert to int\n",
    "        t1 = int(row2[\"frame_end\"])  # list[a:b] returns elements a to (b-1), so no need to subtract here\n",
    "        \n",
    "        # Check if dictionary entries exist\n",
    "        #if row2[\"interval_type\"] not in stim_segments_speed_dict.keys():\n",
    "        #    stim_segments_speed_dict[row2[\"interval_type\"]] = []\n",
    "        #if row2[\"interval_type\"] not in stim_segments_dist_dict.keys():   \n",
    "        #    stim_segments_dist_dict[row2[\"interval_type\"]] = []\n",
    "        #if row2[\"interval_type\"] not in stim_segments_totdist_dict.keys():     \n",
    "        #    stim_segments_totdist_dict[row2[\"interval_type\"]] = []\n",
    "        #if row2[\"interval_type\"] not in stim_segments_rounds_dict.keys():    \n",
    "        #    stim_segments_rounds_dict[row2[\"interval_type\"]] = []\n",
    "        #if row2[\"interval_type\"] not in stim_segments_tsscn_dict.keys():    \n",
    "        #    stim_segments_tsscn_dict[row2[\"interval_type\"]] = []\n",
    "        #if row2[\"interval_type\"] not in stim_segments_running_dict.keys():    \n",
    "        #    stim_segments_running_dict[row2[\"interval_type\"]] = []\n",
    "        \n",
    "        # append to dictionaries and nd2 list\n",
    "        stim_segments_speed_dict[uid.int] = deepcopy(ses.belt_scn_dict[\"speed\"][t0:t1])\n",
    "        stim_segments_dist_dict[uid.int] = deepcopy(ses.belt_scn_dict[\"distance\"][t0:t1])\n",
    "        stim_segments_totdist_dict[uid.int] = deepcopy(ses.belt_scn_dict[\"totdist\"][t0:t1])\n",
    "        stim_segments_rounds_dict[uid.int] = deepcopy(ses.belt_scn_dict[\"rounds\"][t0:t1])\n",
    "        stim_segments_tsscn_dict[uid.int] = deepcopy(ses.belt_scn_dict[\"tsscn\"][t0:t1])\n",
    "        stim_segments_running_dict[uid.int] = deepcopy(ses.belt_scn_dict[\"running\"][t0:t1])\n",
    "        \n",
    "        # append to dataframe columns\n",
    "        df_stim_res_cols[\"mouse_id\"].append(row[\"mouse_id\"])\n",
    "        df_stim_res_cols[\"experiment_type\"].append(row[\"experiment_type\"])\n",
    "        df_stim_res_cols[\"interval_type\"].append(row2[\"interval_type\"])\n",
    "        df_stim_res_cols[\"distance\"].append(ses.belt_scn_dict[\"totdist\"][t1-1] - ses.belt_scn_dict[\"totdist\"][t0])  # t1 is 1-indexed, t0 0-indexed, see above\n",
    "        df_stim_res_cols[\"d_frames\"].append(t1 - 1 - t0)  # t1 is 1-indexed, t0 0-indexed, see above\n",
    "        # dt: in ms\n",
    "        df_stim_res_cols[\"dt\"].append(ses.belt_scn_dict[\"tsscn\"][t1-1] - ses.belt_scn_dict[\"tsscn\"][t0]) # t1 is 1-indexed, t0 0-indexed, see above\n",
    "        df_stim_res_cols[\"uid\"].append(uid.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df from dict:\n",
    "df_stim_res = pd.DataFrame.from_dict(df_stim_res_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize distance by the interval length \n",
    "# also take absolute value; especially during shorter intervals, mice might step backwards a few times and that's it \n",
    "df_stim_res[\"dist_norm\"] = abs(df_stim_res[\"distance\"]/df_stim_res[\"dt\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9b0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_res[\"dist_norm\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e8f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_res[\"experiment_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746f1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_res[\"experiment_type_renamed\"] = df_stim_res[\"experiment_type\"].replace({\"chr2_ctl\": \"Control\", \"chr2_szsd\": \"Sz+SD\", \"chr2_sd\": \"SD\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7430e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ec666",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "# use standard error or standard deviation for uncertainty/spread, or confidence interval or percentile interval\n",
    "# se/sd/ci/pi\n",
    "# see https://seaborn.pydata.org/tutorial/error_bars.html\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=df_stim_res, kind=\"bar\",\n",
    "    x=\"interval_type\", y=\"distance\", hue=\"experiment_type_renamed\",\n",
    "    errorbar=(\"pi\", 50), height=12, aspect=1.3 #, alpha=0.6,\n",
    ")\n",
    "\n",
    "#g = sns.catplot(\n",
    "#    data=df_stim_res, kind=\"box\",\n",
    "#    x=\"interval_type\", y=\"dist_norm\", hue=\"experiment_type\",\n",
    "#    errorbar=\"se\", palette=\"dark\", height=10, aspect=1.3\n",
    "#)\n",
    "#sns.stripplot(\n",
    "#    data=df_stim_res,\n",
    "#    x=\"interval_type\", y=\"dist_norm\", hue=\"experiment_type\", size=12,\n",
    "#)\n",
    "\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"(distance) / (interval length)\", fontsize=22)\n",
    "#g.set_xticklabels([\"Baseline\", \"Stimulation\", \"Aftermath\", \"SD extinciton\", \"Seizure\", \"SD Wave\",], fontsize=18)\n",
    "g.set_xticklabels(fontsize=18)\n",
    "g.set_yticklabels(fontsize=18)\n",
    "g._legend.set_title(\"Experiment type\")\n",
    "plt.setp(g._legend.get_title(), fontsize=20);\n",
    "plt.setp(g._legend.get_texts(),  fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe4ffc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g2 = sns.catplot(\n",
    "    data=df_stim_res, kind=\"strip\",\n",
    "    x=\"interval_type\", y=\"dist_norm\", hue=\"experiment_type_renamed\", height=12, aspect=1.3, size=12\n",
    ")\n",
    "g2.despine(left=True)\n",
    "g2.set_axis_labels(\"\", \"(distance) / (interval length)\", fontsize=22)\n",
    "#g2.set_xticklabels([\"Baseline\", \"Stimulation\", \"Aftermath\", \"Seizure\", \"SD Wave\", \"SD Extinction\"], fontsize=18)\n",
    "g2.set_xticklabels( fontsize=18)\n",
    "g2.set_yticklabels(fontsize=18)\n",
    "g2._legend.set_title(\"Experiment type\")\n",
    "plt.setp(g2._legend.get_title(), fontsize=20);\n",
    "plt.setp(g2._legend.get_texts(),  fontsize=18);\n",
    "g2.set(ylim=(-0.01,0.16));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f86d6",
   "metadata": {},
   "source": [
    "# Plot individual sessions over each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b356a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  make a plot of individual movement \n",
    "g_exptype_itype = df_stim_res.groupby([\"experiment_type\", \"interval_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_ctl = g_exptype_itype.get_group((\"chr2_ctl\", \"baseline\"))[\"uid\"]\n",
    "bl_sd  = g_exptype_itype.get_group((\"chr2_sd\", \"baseline\"))[\"uid\"]\n",
    "bl_szsd= g_exptype_itype.get_group((\"chr2_szsd\",\"baseline\"))[\"uid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ef25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_ctl_tsscn = dict()\n",
    "for uid_ctl in bl_ctl:\n",
    "    bl_ctl_tsscn[uid_ctl] = stim_segments_tsscn_dict[uid_ctl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min =  9000000000  # will be first recorded time point in subset of data\n",
    "t_max = -9000000000  # latest time point in subset of data\n",
    "for key, value in bl_ctl_tsscn.items():\n",
    "    if min(value) < t_min:\n",
    "        t_min = min(value)\n",
    "    if max(value) > t_max:\n",
    "        t_max = max(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_ctl = sorted(bl_ctl, key= lambda uid: sum(stim_segments_running_dict[uid]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3747c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match recordings in time by shifting so that last data point has the same time in all cases\n",
    "stim_segments_t_matched_dict = dict()\n",
    "for uid in bl_ctl:\n",
    "    dt = t_max - stim_segments_tsscn_dict[uid][-1]\n",
    "    stim_segments_t_matched_dict[uid] = dt + deepcopy(stim_segments_tsscn_dict[uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_segments_tsscn_dict[bl_ctl[0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('viridis', len(bl_ctl))\n",
    "fig = plt.figure(figsize=(18,24))\n",
    "for i_session, ctl_session in enumerate(bl_ctl):\n",
    "    plt.plot(stim_segments_t_matched_dict[ctl_session],i_session*0.7 + stim_segments_speed_dict[ctl_session], color=cmap.colors[i_session])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a UID for individual recordings (to match various segments in the dictionaries).\n",
    "# TODO: plot movement starting with stimulation. How long it should be plotted? Match color map with baseline,\n",
    "#       sort by movement amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751db466",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('viridis', len(bl_ctl))\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "for i_session, ctl_session in enumerate(bl_ctl):\n",
    "    plt.plot(i_session*0.5 + stim_segments_speed_dict[ctl_session], color=cmap.colors[i_session])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deaeba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stim_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_stim_res[(df_stim_res[\"experiment_type\"] == \"chr2_sd\") & (df_stim_res[\"interval_type\"] == \"baseline\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dcda1b",
   "metadata": {},
   "source": [
    "# TMEV running over days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e60c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4ff65bb",
   "metadata": {},
   "source": [
    "# Unorganized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys of belt_scn_dict: 'tsscn', 'rounds', 'speed', 'distance', 'totdist', 'running'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fac5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# think about data to quantify (integrated velocity/distance per interval? divided by interval length)\n",
    "# maybe need nd2 to extract mean, check if zones correspond to imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65489ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = dict()\n",
    "for interval_type in segments_totdist_dict.keys():\n",
    "    res_dict[interval_type] = []\n",
    "    for dist_lis in segments_totdist_dict[interval_type]:\n",
    "        assert dist_lis[-1] >= 0\n",
    "        assert dist_lis[0] >= 0\n",
    "        totdist_interval = (dist_lis[-1] - dist_lis[0])/len(dist_lis)\n",
    "        res_dict[interval_type].append(totdist_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94bbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get results also for control animal, make a dataframe including all these \n",
    "# (columns: \n",
    "#    tmev/chr2/ctl (exp_type?), \n",
    "#    interval_type ('baseline', 'sz', 'sd_wave', 'sd_extinction', 'normal'),\n",
    "#    total distance,\n",
    "#    etc. (other data like dist, for comparison. But I think totdist is the one I need)\n",
    "\n",
    "# Then plot as seaborn catplot (grouped barplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "# Draw a nested barplot by species and sex\n",
    "g = sns.catplot(\n",
    "    data=a, kind=\"bar\",\n",
    "    x=\"\", y=\"body_mass_g\", hue=\"sex\",\n",
    "    errorbar=\"sd\", palette=\"dark\", alpha=.6, height=6\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"Body mass (g)\")\n",
    "g.legend.set_title(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0318da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

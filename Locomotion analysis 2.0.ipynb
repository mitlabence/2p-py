{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fda4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labrotation.file_handling as fh\n",
    "import h5py\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps\n",
    "import seaborn as sns\n",
    "import uuid  # for unique labeling of sessions and coupling arrays (mouse velocity, distance, ...) to sessions in dataframe \n",
    "from matplotlib import cm  # colormap\n",
    "import datadoc_util\n",
    "from labrotation import two_photon_session as tps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819367b",
   "metadata": {},
   "source": [
    "# If exists, load environmental variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e04e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb38a7a",
   "metadata": {},
   "source": [
    "# Set up data documentation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: inside the documentation folder, the subfolders carry the id of each mouse (not exact necessarily, but they \n",
    "# can be identified by the name of the subfolder). \n",
    "# Inside the subfolder xy (for mouse xy), xy_grouping.xlsx and xy_segmentation.xlsx can be found.\n",
    "# xy_grouping.xlsx serves the purpose of finding the recordings belonging together, and has columns:\n",
    "# folder, nd2, labview, lfp, face_cam_last, nikon_meta, experiment_type, day\n",
    "# xy_segmentation.xlsx contains frame-by-frame (given by a set of disjoint intervals forming a cover for the whole recording) \n",
    "# classification of the events in the recording (\"normal\", seizure (\"sz\"), sd wave (\"sd_wave\") etc.). The columns:\n",
    "# folder, interval_type, frame_begin, frame_end.\n",
    "\n",
    "# TODO: write documentation on contents of xlsx files (what the columns are etc.)\n",
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    docu_folder = fh.open_dir(\"Choose folder containing folders for each mouse!\")\n",
    "print(f\"Selected folder:\\n\\t{docu_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281247a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"documentation\" in os.listdir(docu_folder):\n",
    "    mouse_folder = os.path.join(docu_folder, \"documentation\")\n",
    "else:\n",
    "    mouse_folder = docu_folder\n",
    "mouse_names = os.listdir(mouse_folder)\n",
    "print(f\"Mice detected:\")\n",
    "for mouse in mouse_names:\n",
    "    print(f\"\\t{mouse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d19fcd",
   "metadata": {},
   "source": [
    "### Load matlab-2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"MATLAB_2P_FOLDER\" in env_dict.keys():\n",
    "    matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]\n",
    "else:\n",
    "    matlab_2p_folder = fh.open_dir(\"Choose matlab-2p folder\")\n",
    "print(f\"matlab-2p folder set to:\\n\\t{matlab_2p_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg_complete = pd.DataFrame(columns = [\"nd2\", \"interval_type\", \"frame_begin\", \"frame_end\"])\n",
    "df_grouping_complete = pd.DataFrame(columns = [\"folder\", \"nd2\", \"labview\", \"lfp\", \"face_cam_last\", \"nikon_meta\", \"experiment_type\", \"mouse_id\", \"day\"])\n",
    "\n",
    "for mouse_id in mouse_names:\n",
    "    print(mouse_id)\n",
    "    seg_fpath = os.path.join(mouse_folder, mouse_id, mouse_id + '_segmentation.xlsx')\n",
    "    grouping_fpath = os.path.join(mouse_folder, mouse_id, mouse_id + '_grouping.xlsx')\n",
    "    if os.path.exists(seg_fpath) and os.path.exists(grouping_fpath):\n",
    "        df_seg = pd.read_excel(seg_fpath)\n",
    "        df_grouping = pd.read_excel(grouping_fpath)\n",
    "        df_grouping[\"mouse_id\"] = mouse_id\n",
    "        # select only tmev, chr2_szsd, chr2_sd, chr2_ctl experiment data first\n",
    "        df_grouping = df_grouping[df_grouping[\"experiment_type\"].isin([\"tmev\", \"tmev_ctl\", \"chr2_sd\", \"chr2_szsd\", \"chr2_ctl\"])]\n",
    "        # merge into large dataframes\n",
    "        # print(f\"\\tseg bef: {len(df_seg_complete['nd2'])}\")\n",
    "        df_seg_complete = pd.concat([df_seg_complete, df_seg])\n",
    "        # print(f\"\\tseg aft: {len(df_seg_complete['nd2'])}\")\n",
    "        # print(f\"\\tgro bef: {len(df_grouping_complete['nd2'])}\")\n",
    "        df_grouping_complete = pd.concat([df_grouping_complete, df_grouping])\n",
    "        # print(f\"\\tgro aft: {len(df_grouping_complete['nd2'])}\")\n",
    "    else:\n",
    "        print(f\"Check if you set the correct folder (folder containing all subfolders with mouse names):\")\n",
    "        if not os.path.exists(seg_fpath):\n",
    "            print(f\"\\t{seg_fpath} not found\")\n",
    "        if not os.path.exists(grouping_fpath):\n",
    "            print(f\"\\t{grouping_fpath} not found\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = datadoc_util.DataDocumentation(docu_folder)\n",
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ea948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only recordings that were classified as \"tmev\" (experiment type)\n",
    "df_seg_complete.where(df_seg_complete[\"nd2\"].isin(df_grouping_complete[\"nd2\"].unique()), inplace=True)\n",
    "# wrong recording types changed to NaN; drop them\n",
    "df_seg_complete.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e18c2",
   "metadata": {},
   "source": [
    "# Pre-/post-ictal locomotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only videos with seizure\n",
    "df_sz_movies = df_seg_complete.groupby(\"nd2\").filter(lambda group: \"sz\" in group[\"interval_type\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c519773",
   "metadata": {},
   "source": [
    "## Add uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies = pd.merge(df_sz_movies, ddoc.getNikonFileNameUuid().dropna(), on=\"nd2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a3797",
   "metadata": {},
   "source": [
    "### Filter for only tmev-type recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies[\"type\"] = df_sz_movies.apply(lambda row: df_grouping_complete[df_grouping_complete[\"uuid\"] == row[\"uuid\"]].experiment_type.values[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies = df_sz_movies[df_sz_movies[\"type\"] == \"tmev\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461984c",
   "metadata": {},
   "source": [
    "## Add seizure-uuid\n",
    "See 4 Directionality analysis for original context. This code should be the same as there! (If update needed, need to extract into third file!)\n",
    "In this analysis, the purpose is to make each seizure unique (to deal with seizures split-up in two videos, for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d88079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies[\"uuid_sz\"] = df_sz_movies[\"uuid\"]\n",
    "# following two recordings contain 1 seizure-sd event\n",
    "df_sz_movies[\"uuid_sz\"] = df_sz_movies[\"uuid_sz\"].replace(\"65bff16a4cf04930a5cb14f489a8f99b\", \"30dc55d1a5dc4b0286d132e72f208ca6\")\n",
    "# following recordings do not have sz\n",
    "#qdf = qdf[qdf[\"uuid_matched\"] != \"171693d0988c458a96c8198c7b8cfc28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals = df_sz_movies[df_sz_movies[\"interval_type\"] == \"sz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9410391",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_g, g in df_sz_intervals.sort_values([\"nd2\"]).groupby(\"uuid_sz\"):  # assume seizures cut in two have incremented names\n",
    "    print(f'{g[g[\"interval_type\"] == \"sz\"].frame_begin.values}: {g[g[\"interval_type\"] == \"sz\"].uuid.values}')\n",
    "    # check if one recording contained several seizures:\n",
    "    n_seizures = len(g[g[\"interval_type\"] == \"sz\"].uuid_sz.unique())\n",
    "    n_recordings = len(g[g[\"interval_type\"] == \"sz\"].uuid.unique())\n",
    "    print(f\"{n_seizures} sz: {n_recordings} recs\")\n",
    "    \n",
    "    \n",
    "    # group by uuid_sz?\n",
    "    # TODO: need some way to sort by recording starting time too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each seizure. Find recording, find 5 minutes before beginning of sz, during sz + sd, and 5 minutes after end of sz\n",
    "# 1. for each sz (uuid_sz), find ordered recordings\n",
    "# 2. find beginning of sz = first recording with a \"sz\" category\n",
    "# 3. find uuid of the recording, open loco data, extract locomotion of 5 min before sz begin\n",
    "# 4. find end of sz = last recording with a \"sz\" or \"sd_wave\" category\n",
    "# 5. find uuid of the recording, open loco data, extract locomotion of 5 min after sz end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals[\"i_sz\"] = df_sz_intervals.groupby(\"uuid\").cumcount() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5500c87",
   "metadata": {},
   "source": [
    "### Sort by recordings (ASSUMPTION: recording indexing is incremental)\n",
    "Once using groupby uuid_sz, the recordings where the same seizure is present should then be ordered from the first recording it appears in to the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals = df_sz_intervals.sort_values(\"nd2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7c5df",
   "metadata": {},
   "source": [
    "### Make uuid_sz truly unique\n",
    "Append the index of the seizure, i.e. uuid -> uuid_1, uuid_2 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals[\"uuid_sz\"] = df_sz_intervals.apply(lambda row: row.uuid_sz + \"_\" +  str(row.i_sz), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6b7fd",
   "metadata": {},
   "source": [
    "### Create data structure of intervals\n",
    "For each seizure, the entry should contain the baseline (5 min), sz+sd, post-sz (5 min) periods. If one period spreads over multiple recordings, then this will be an array.\n",
    "The data structure:\n",
    "\n",
    "A dictionary of the uuid_sz values, each has as its value another dictionary, with keys \"baseline\", \"sz\", \"aftermath\". The corresponding values are lists of tuples. Each tuple contains the uuid of the session, the beginning frame (1-indexing) and end frame in that session (both inclusive! i.e. in case of 1 and 10, the segment is 1 to 10 inclusive, the segment having a length of 10 frames). If the list of tuples has more than one entry, it means that the given interval (baseline, sz, aftermath) spreads over multiple sessions (i.e. recordings).\n",
    "\n",
    "Example:\n",
    "\n",
    "{\n",
    "\n",
    "\\<uuid_sz1\\>: \n",
    "\n",
    "{\n",
    "\n",
    "  \"baseline\": \\[ (\\<uuid1\\>, \\<begin_frame\\>, \\<end_frame\\>), (\\<uuid2\\>, \\<begin_frame\\>, \\<end_frame\\>)  \\],\n",
    "\n",
    "  \"sz\": \\[ ( \\<uuid\\>, \\<begin_frame\\>, \\<end_frame\\> ) \\],\n",
    "  \n",
    "  \"aftermath\": \\[ ( \\<uuid\\>, \\<begin_frame\\>, \\<end_frame\\> ) \\],\n",
    "  \n",
    "  }\n",
    "  \n",
    "  \n",
    "  \\<uuid_sz2\\>: {...}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d239ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = df_sz_intervals.sort_values(\"nd2\").groupby([\"uuid_sz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7efec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr2 = gr.get_group(\"30dc55d1a5dc4b0286d132e72f208ca6_1\")  # has 2 recordings\n",
    "gr1 = gr.get_group(\"3dd896d33a0f42c698228fbe254ebd60_1\")  # has 1 recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr1.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfafa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_FRAMERATE = 15.0  # in Hz\n",
    "BL_LEN_S = 5*60  # baseline desired (approximate) length, in seconds\n",
    "AM_LEN_S = 5*60  # aftermath desired (approximate) in seconds\n",
    "\n",
    "bl_len_frames = RECORDING_FRAMERATE * BL_LEN_S\n",
    "am_len_frames = RECORDING_FRAMERATE * AM_LEN_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cefad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouping_complete[df_grouping_complete.uuid == \"3dd896d33a0f42c698228fbe254ebd60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e7c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies[df_sz_movies.uuid == \"3dd896d33a0f42c698228fbe254ebd60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d6b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sz_intervals_dict = dict()\n",
    "for uuid_sz, g in df_sz_intervals.sort_values(\"nd2\").groupby([\"uuid_sz\"]):\n",
    "    sz_entry = []\n",
    "    bl_entry = []  # baseline\n",
    "    am_entry = []  # aftermath\n",
    "    \n",
    "    # 1. get sz data.\n",
    "    assert len(g) <= 2  # for now, only deal with cases where segment is in single recording or in two recordings. \n",
    "    # If more recordings (highly unlikely), need to switch to array-based approach\n",
    "    sz_begin_uuid = g.iloc[0].uuid\n",
    "    sz_end_uuid = g.iloc[-1].uuid  # assume len(g) == 1 or == 2!!!\n",
    "    # Assume only seizure is split up, the baseline and aftermath never span over two recordings\n",
    "    sz_begin_session = df_grouping_complete.loc[df_grouping_complete[\"uuid\"] == sz_begin_uuid]\n",
    "    sz_end_session = df_grouping_complete.loc[df_grouping_complete[\"uuid\"] == sz_end_uuid]\n",
    "    # define seizure begin and end frames (might be from different recordings!) to aid acquiring baseline and aftermath frames\n",
    "    sz_begin_frame = g.iloc[0].frame_begin\n",
    "    sz_end_frame = g.iloc[-1].frame_end\n",
    "    \n",
    "    if sz_begin_uuid == sz_end_uuid:  # seizure entirely in a single recording\n",
    "        sz_entry.append((sz_begin_uuid, sz_begin_frame, sz_end_frame))\n",
    "    else:\n",
    "        assert len(g) == 2  # make sure only up to 2 recordings, as this is the only other case handled\n",
    "        sz_entry.append((sz_begin_uuid, sz_begin_frame, g.iloc[0].frame_end))\n",
    "        sz_entry.append((sz_end_uuid, g.iloc[1].frame_begin, sz_end_frame))\n",
    "    # get baseline\n",
    "    bl_uuid = sz_begin_uuid\n",
    "    bl_end_frame = sz_begin_frame - 1\n",
    "    bl_begin_frame = sz_begin_frame - bl_len_frames\n",
    "    if bl_begin_frame < 1:  # not enough baseline available in recording\n",
    "        # TODO: modify exception to warning? No way to add baseline in front anyway... Recordings are never\n",
    "        # directly after another; it might be possible to take previous recording somehow, and \n",
    "        raise Exception(f\"Error: not enough baseline available for {sz_begin_uuid}. Seizure begins on frame {sz_begin_frame}. Need at least {bl_len_frames} frames before for {BL_LEN_S} seconds of baseline\")\n",
    "        # bl_begin_frame = 1\n",
    "    bl_entry.append((bl_uuid, bl_begin_frame, bl_end_frame))\n",
    "    # get aftermath\n",
    "    am_uuid = sz_end_uuid\n",
    "    am_begin_frame = sz_end_frame + 1\n",
    "    am_end_frame = sz_end_frame + am_len_frames\n",
    "    # test if aftermath would fall outside last \"normal\" interval in recording:\n",
    "    if am_end_frame > df_sz_movies[(df_sz_movies[\"uuid\"] == am_uuid) & (df_sz_movies[\"interval_type\"] == \"normal\")].frame_end.max():\n",
    "        raise Exception(f\"Error: not enough aftermath available for {sz_end_uuid}. Seizure ends on frame {sz_end_frame}. Need {am_len_frames} frames after for {AM_LEN_S} seconds of aftermath\")\n",
    "    am_entry.append((am_uuid, am_begin_frame, am_end_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6680440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

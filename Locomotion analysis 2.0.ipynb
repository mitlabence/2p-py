{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fda4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auto-reload modules (used to develop functions outside this notebook)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import labrotation.file_handling as fh\n",
    "import h5py\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from labrotation import file_handling as fh\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import labrotation.two_photon_session as tps\n",
    "import seaborn as sns\n",
    "import uuid  # for unique labeling of sessions and coupling arrays (mouse velocity, distance, ...) to sessions in dataframe \n",
    "from matplotlib import cm  # colormap\n",
    "import datadoc_util\n",
    "from labrotation import two_photon_session as tps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7819367b",
   "metadata": {},
   "source": [
    "# If exists, load environmental variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e04e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_dict = dict()\n",
    "if not os.path.exists(\"./.env\"):\n",
    "    print(\".env does not exist\")\n",
    "else:\n",
    "    with open(\"./.env\", \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            l = line.rstrip().split(\"=\")\n",
    "            env_dict[l[0]] = l[1]\n",
    "print(env_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb38a7a",
   "metadata": {},
   "source": [
    "# Set up data documentation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: inside the documentation folder, the subfolders carry the id of each mouse (not exact necessarily, but they \n",
    "# can be identified by the name of the subfolder). \n",
    "# Inside the subfolder xy (for mouse xy), xy_grouping.xlsx and xy_segmentation.xlsx can be found.\n",
    "# xy_grouping.xlsx serves the purpose of finding the recordings belonging together, and has columns:\n",
    "# folder, nd2, labview, lfp, face_cam_last, nikon_meta, experiment_type, day\n",
    "# xy_segmentation.xlsx contains frame-by-frame (given by a set of disjoint intervals forming a cover for the whole recording) \n",
    "# classification of the events in the recording (\"normal\", seizure (\"sz\"), sd wave (\"sd_wave\") etc.). The columns:\n",
    "# folder, interval_type, frame_begin, frame_end.\n",
    "\n",
    "# TODO: write documentation on contents of xlsx files (what the columns are etc.)\n",
    "if \"DATA_DOCU_FOLDER\" in env_dict.keys():\n",
    "    docu_folder = env_dict[\"DATA_DOCU_FOLDER\"]\n",
    "else:\n",
    "    docu_folder = fh.open_dir(\"Choose folder containing folders for each mouse!\")\n",
    "print(f\"Selected folder:\\n\\t{docu_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281247a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"documentation\" in os.listdir(docu_folder):\n",
    "    mouse_folder = os.path.join(docu_folder, \"documentation\")\n",
    "else:\n",
    "    mouse_folder = docu_folder\n",
    "mouse_names = os.listdir(mouse_folder)\n",
    "print(f\"Mice detected:\")\n",
    "for mouse in mouse_names:\n",
    "    print(f\"\\t{mouse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d19fcd",
   "metadata": {},
   "source": [
    "### Load matlab-2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d00a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"MATLAB_2P_FOLDER\" in env_dict.keys():\n",
    "    matlab_2p_folder = env_dict[\"MATLAB_2P_FOLDER\"]\n",
    "else:\n",
    "    matlab_2p_folder = fh.open_dir(\"Choose matlab-2p folder\")\n",
    "print(f\"matlab-2p folder set to:\\n\\t{matlab_2p_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg_complete = pd.DataFrame(columns = [\"nd2\", \"interval_type\", \"frame_begin\", \"frame_end\"])\n",
    "df_grouping_complete = pd.DataFrame(columns = [\"folder\", \"nd2\", \"labview\", \"lfp\", \"face_cam_last\", \"nikon_meta\", \"experiment_type\", \"mouse_id\", \"day\"])\n",
    "\n",
    "for mouse_id in mouse_names:\n",
    "    print(mouse_id)\n",
    "    seg_fpath = os.path.join(mouse_folder, mouse_id, mouse_id + '_segmentation.xlsx')\n",
    "    grouping_fpath = os.path.join(mouse_folder, mouse_id, mouse_id + '_grouping.xlsx')\n",
    "    if os.path.exists(seg_fpath) and os.path.exists(grouping_fpath):\n",
    "        df_seg = pd.read_excel(seg_fpath)\n",
    "        df_grouping = pd.read_excel(grouping_fpath)\n",
    "        df_grouping[\"mouse_id\"] = mouse_id\n",
    "        # select only tmev, chr2_szsd, chr2_sd, chr2_ctl experiment data first\n",
    "        df_grouping = df_grouping[df_grouping[\"experiment_type\"].isin([\"tmev\", \"tmev_ctl\", \"chr2_sd\", \"chr2_szsd\", \"chr2_ctl\"])]\n",
    "        # merge into large dataframes\n",
    "        # print(f\"\\tseg bef: {len(df_seg_complete['nd2'])}\")\n",
    "        df_seg_complete = pd.concat([df_seg_complete, df_seg])\n",
    "        # print(f\"\\tseg aft: {len(df_seg_complete['nd2'])}\")\n",
    "        # print(f\"\\tgro bef: {len(df_grouping_complete['nd2'])}\")\n",
    "        df_grouping_complete = pd.concat([df_grouping_complete, df_grouping])\n",
    "        # print(f\"\\tgro aft: {len(df_grouping_complete['nd2'])}\")\n",
    "    else:\n",
    "        print(f\"Check if you set the correct folder (folder containing all subfolders with mouse names):\")\n",
    "        if not os.path.exists(seg_fpath):\n",
    "            print(f\"\\t{seg_fpath} not found\")\n",
    "        if not os.path.exists(grouping_fpath):\n",
    "            print(f\"\\t{grouping_fpath} not found\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddoc = datadoc_util.DataDocumentation(docu_folder)\n",
    "ddoc.loadDataDoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ea948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only recordings that were classified as \"tmev\" (experiment type)\n",
    "df_seg_complete.where(df_seg_complete[\"nd2\"].isin(df_grouping_complete[\"nd2\"].unique()), inplace=True)\n",
    "# wrong recording types changed to NaN; drop them\n",
    "df_seg_complete.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e18c2",
   "metadata": {},
   "source": [
    "# Pre-/post-ictal locomotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only videos with seizure\n",
    "df_sz_movies = df_seg_complete.groupby(\"nd2\").filter(lambda group: \"sz\" in group[\"interval_type\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c519773",
   "metadata": {},
   "source": [
    "## Add uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies = pd.merge(df_sz_movies, ddoc.getNikonFileNameUuid().dropna(), on=\"nd2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a3797",
   "metadata": {},
   "source": [
    "### Filter for only tmev-type recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies[\"type\"] = df_sz_movies.apply(lambda row: df_grouping_complete[df_grouping_complete[\"uuid\"] == row[\"uuid\"]].experiment_type.values[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies = df_sz_movies[df_sz_movies[\"type\"] == \"tmev\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62fd10",
   "metadata": {},
   "source": [
    "### Add previous recording to cases where seizure starts on frame 1 (or not enough baseline before sz start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599fd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3dd896d33a0f42c698228fbe254ebd60 contains seizure from frame 1; previous recording is 21c83d0b69ec4585a9a11f4ce6c24b99\n",
    "#pd.merge(df_sz_movies, ddoc.getNikonFileNameUuid().dropna(), on=\"nd2\")\n",
    "# list of (previous recording, sz recording)\n",
    "uuids_to_add = [(\"21c83d0b69ec4585a9a11f4ce6c24b99\", \"3dd896d33a0f42c698228fbe254ebd60\"),  # sz starts on frame 1\n",
    "                (\"0bb9054922664ee3a148618e99da1c6a\", \"44ca941252064dcabb0fe3d24a8dab49\")  # sz starts on frame 131\n",
    "               ]  # pairs of (uuid of previous recording, uuid of sz recording)\n",
    "for uuid, uuid_sz in uuids_to_add:\n",
    "    nd2_to_add = df_grouping_complete[df_grouping_complete[\"uuid\"] == uuid].nd2.values[0]\n",
    "    group_to_add = df_seg_complete[df_seg_complete[\"nd2\"] == nd2_to_add].to_dict()\n",
    "    group_to_add[\"uuid\"] = uuid\n",
    "    group_to_add[\"uuid_sz\"] = uuid_sz\n",
    "    group_to_add = pd.DataFrame(group_to_add)\n",
    "    group_to_add[\"type\"] = group_to_add.apply(lambda row: df_grouping_complete.loc[df_grouping_complete[\"uuid\"] == row[\"uuid\"]].experiment_type.values[0], axis=1)\n",
    "    df_sz_movies = pd.concat([df_sz_movies, group_to_add])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c70b71d",
   "metadata": {},
   "source": [
    "### Add following recording to cases where not enough aftermath available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa879080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of (sz recording, aftermath_recording)\n",
    "uuids_to_add = [(\"92062a977958443e83011619b34eabb8\", \"3cb9934ddcc24cf7a922dca01bdb9448\"),  # sz ends on frame 15934/17978\n",
    "               ]  # pairs of (uuid of previous recording, uuid of sz recording)\n",
    "for uuid_sz, uuid in uuids_to_add:\n",
    "    nd2_to_add = df_grouping_complete[df_grouping_complete[\"uuid\"] == uuid].nd2.values[0]\n",
    "    group_to_add = df_seg_complete[df_seg_complete[\"nd2\"] == nd2_to_add].to_dict()\n",
    "    group_to_add[\"uuid\"] = uuid\n",
    "    group_to_add[\"uuid_sz\"] = uuid_sz\n",
    "    group_to_add = pd.DataFrame(group_to_add)\n",
    "    group_to_add[\"type\"] = group_to_add.apply(lambda row: df_grouping_complete.loc[df_grouping_complete[\"uuid\"] == row[\"uuid\"]].experiment_type.values[0], axis=1)\n",
    "    df_sz_movies = pd.concat([df_sz_movies, group_to_add])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe1af3",
   "metadata": {},
   "source": [
    "### Remove recording with not sufficient aftermath recorded\n",
    "Unfortunately, the video is too short, and no subsequent recordings were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363cf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies = df_sz_movies[df_sz_movies[\"uuid\"] != \"b8f31023d2c042c2a7f95b54d9807cb7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c461984c",
   "metadata": {},
   "source": [
    "## Add seizure-uuid\n",
    "See 4 Directionality analysis for original context. This code should be the same as there! (If update needed, need to extract into third file!)\n",
    "In this analysis, the purpose is to make each seizure unique (to deal with seizures split-up in two videos, for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d88079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_movies[\"uuid_sz\"] = df_sz_movies[\"uuid\"]\n",
    "# following two recordings contain 1 seizure-sd event. Make first video uuid the uuid_sz\n",
    "df_sz_movies[\"uuid_sz\"] = df_sz_movies[\"uuid_sz\"].replace( \"30dc55d1a5dc4b0286d132e72f208ca6\", \"65bff16a4cf04930a5cb14f489a8f99b\")\n",
    "# following recordings do not have sz\n",
    "#qdf = qdf[qdf[\"uuid_matched\"] != \"171693d0988c458a96c8198c7b8cfc28\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69e9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals = df_sz_movies[df_sz_movies[\"interval_type\"] == \"sz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9410391",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_g, g in df_sz_intervals.sort_values([\"nd2\"]).groupby(\"uuid_sz\"):  # assume seizures cut in two have incremented names\n",
    "    print(f'{g[g[\"interval_type\"] == \"sz\"].frame_begin.values}: {g[g[\"interval_type\"] == \"sz\"].uuid.values}')\n",
    "    # check if one recording contained several seizures:\n",
    "    n_seizures = len(g[g[\"interval_type\"] == \"sz\"].uuid_sz.unique())\n",
    "    n_recordings = len(g[g[\"interval_type\"] == \"sz\"].uuid.unique())\n",
    "    print(f\"{n_seizures} sz: {n_recordings} recs\")\n",
    "    \n",
    "    \n",
    "    # group by uuid_sz?\n",
    "    # TODO: need some way to sort by recording starting time too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each seizure. Find recording, find 5 minutes before beginning of sz, during sz + sd, and 5 minutes after end of sz\n",
    "# 1. for each sz (uuid_sz), find ordered recordings\n",
    "# 2. find beginning of sz = first recording with a \"sz\" category\n",
    "# 3. find uuid of the recording, open loco data, extract locomotion of 5 min before sz begin\n",
    "# 4. find end of sz = last recording with a \"sz\" or \"sd_wave\" category\n",
    "# 5. find uuid of the recording, open loco data, extract locomotion of 5 min after sz end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals[\"i_sz\"] = df_sz_intervals.groupby(\"uuid\").cumcount() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5500c87",
   "metadata": {},
   "source": [
    "### Sort by recordings (ASSUMPTION: recording indexing is incremental)\n",
    "Once using groupby uuid_sz, the recordings where the same seizure is present should then be ordered from the first recording it appears in to the last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals = df_sz_intervals.sort_values(\"nd2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7c5df",
   "metadata": {},
   "source": [
    "### Make uuid_sz truly unique\n",
    "Append the index of the seizure, i.e. uuid -> uuid_1, uuid_2 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sz_intervals[\"uuid_sz\"] = df_sz_intervals.apply(lambda row: row.uuid_sz + \"_\" +  str(row.i_sz), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6b7fd",
   "metadata": {},
   "source": [
    "### Create data structure of intervals\n",
    "For each seizure, the entry should contain the baseline (5 min), sz+sd, post-sz (5 min) periods. If one period spreads over multiple recordings, then this will be an array.\n",
    "The data structure:\n",
    "\n",
    "A dictionary of the uuid_sz values, each has as its value another dictionary, with keys \"baseline\", \"sz\", \"aftermath\". The corresponding values are lists of tuples. Each tuple contains the uuid of the session, the beginning frame (1-indexing) and end frame in that session (both inclusive! i.e. in case of 1 and 10, the segment is 1 to 10 inclusive, the segment having a length of 10 frames). If the list of tuples has more than one entry, it means that the given interval (baseline, sz, aftermath) spreads over multiple sessions (i.e. recordings).\n",
    "\n",
    "Example:\n",
    "\n",
    "{\n",
    "\n",
    "\\<uuid_sz1\\>: \n",
    "\n",
    "{\n",
    "\n",
    "  \"baseline\": \\[ (\\<uuid1\\>, \\<begin_frame\\>, \\<end_frame\\>), (\\<uuid2\\>, \\<begin_frame\\>, \\<end_frame\\>)  \\],\n",
    "\n",
    "  \"sz\": \\[ ( \\<uuid\\>, \\<begin_frame\\>, \\<end_frame\\> ) \\],\n",
    "  \n",
    "  \"sd\": \\[ ( \\<uuid1\\>, \\<begin_frame\\>, \\<end_frame\\> ), ... \\],\n",
    " \n",
    "  \"aftermath\": \\[ ( \\<uuid1\\>, \\<begin_frame\\>, \\<end_frame\\> ), ... \\],\n",
    "  \n",
    "  }\n",
    "  \n",
    "  \n",
    "  \\<uuid_sz2\\>: {...}\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfafa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_FRAMERATE = 15.0  # in Hz\n",
    "BL_LEN_S = 5*60  # baseline desired (approximate) length, in seconds\n",
    "AM_LEN_S = 5*60  # aftermath desired (approximate) in seconds\n",
    "\n",
    "bl_len_frames = RECORDING_FRAMERATE * BL_LEN_S\n",
    "am_len_frames = RECORDING_FRAMERATE * AM_LEN_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d6b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sz_intervals_dict = dict()\n",
    "for uuid_sz, g in df_sz_intervals.sort_values(\"nd2\").groupby([\"uuid_sz\"]):\n",
    "    sz_entry = []\n",
    "    sd_entry = []  # keep sd separate from sz at this point. The plan is to combine them when looking at locomotion, though.\n",
    "    bl_entry = []  # baseline\n",
    "    am_entry = []  # aftermath\n",
    "    \n",
    "    # 1. get sz data.\n",
    "    assert len(g) <= 2  # for now, only deal with cases where segment is in single recording or in two recordings. \n",
    "    # If more recordings (highly unlikely), need to switch to array-based approach\n",
    "    g_sz = g[(g[\"interval_type\"] == \"sz\")]\n",
    "    sz_begin_uuid = g_sz[g_sz[\"uuid_sz\"] == uuid_sz].iloc[0].uuid\n",
    "    sz_end_uuid = g_sz[g_sz[\"uuid_sz\"] == uuid_sz].iloc[-1].uuid  # assume len(g[\"sz\"]) == 1 or == 2!!!\n",
    "    # Assume only seizure is split up, the baseline and aftermath never span over two recordings\n",
    "    sz_begin_session = df_grouping_complete.loc[df_grouping_complete[\"uuid\"] == sz_begin_uuid]\n",
    "    sz_end_session = df_grouping_complete.loc[df_grouping_complete[\"uuid\"] == sz_end_uuid]\n",
    "    # define seizure begin and end frames (might be from different recordings!) to aid acquiring baseline and aftermath frames\n",
    "    sz_begin_frame = g_sz.iloc[0].frame_begin\n",
    "    sz_end_frame = g_sz.iloc[-1].frame_end\n",
    "    \n",
    "    # TODO: add sd_wave to these intervals as well\n",
    "    if sz_begin_uuid == sz_end_uuid:  # seizure entirely in a single recording\n",
    "        sz_entry.append((sz_begin_uuid, sz_begin_frame, sz_end_frame))\n",
    "    else:\n",
    "        assert len(g) == 2  # make sure only up to 2 recordings, as this is the only other case handled\n",
    "        sz_entry.append((sz_begin_uuid, sz_begin_frame, g.iloc[0].frame_end))\n",
    "        sz_entry.append((sz_end_uuid, g.iloc[1].frame_begin, sz_end_frame))\n",
    "    \n",
    "    # assumption: sd wave comes after seizure, and both waves are in same movie as sz end.\n",
    "    last_frame = df_sz_movies[(df_sz_movies[\"uuid\"] == sz_end_uuid)].frame_end.max() \n",
    "    current_frame = sz_end_frame + 1\n",
    "    if not sz_end_frame == last_frame:  # more segments after seizure\n",
    "        for i_row, row in df_sz_movies[(df_sz_movies[\"uuid\"] == sz_end_uuid) & ((df_sz_movies[\"interval_type\"] == \"sd_wave\") | (df_sz_movies[\"interval_type\"] == \"sd_wave_cx\"))].iterrows():\n",
    "            if row.interval_type == \"normal\":\n",
    "                break\n",
    "            elif row.interval_type == \"sd_wave\":\n",
    "                if row.frame_begin == current_frame:  # look for segment that comes just after sz (or sd wave)\n",
    "                    sd_entry.append((sz_end_uuid, row.frame_begin, row.frame_end))\n",
    "                    current_frame = row.frame_end + 1\n",
    "                \n",
    "    else:\n",
    "        raise Exception(f\"Rare condition: seizure seems to have ended just at the end of the recording. Might be a bug (next recording containing rest incl. sd waves not included in list)?\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # get baseline\n",
    "    if sz_begin_frame == 1:  # seizure begins with recording; happens at least once\n",
    "        print(f\"Frame 1 sz: {uuid_sz}\")\n",
    "        # need to take previous recording end as baseline.\n",
    "        # Just assume that the very first recording is the previous recording. It should be, in any case.\n",
    "        bl_uuid = g.iloc[0].uuid\n",
    "        print(f\"\\tBL uuid: {bl_uuid}\")\n",
    "        len_bl_movie = df_sz_movies[(df_sz_movies[\"uuid\"] == bl_uuid) & (df_sz_movies[\"interval_type\"] == \"normal\")].frame_end.max()\n",
    "        bl_end_frame = len_bl_movie\n",
    "        bl_begin_frame = bl_end_frame - bl_len_frames\n",
    "    else:  # if seizure was not in beginning, assume we have enough frames before sz start in same video (in this version of the code)\n",
    "        bl_uuid = sz_begin_uuid\n",
    "        bl_end_frame = sz_begin_frame - 1\n",
    "        bl_begin_frame = sz_begin_frame - bl_len_frames\n",
    "    if bl_begin_frame < 1:  # not enough baseline available in recording\n",
    "        # TODO: modify exception to warning? No way to add baseline in front anyway... Recordings are never\n",
    "        # directly after another; it might be possible to take previous recording somehow, and \n",
    "        print(f\"Baseline: Not enough baseline available for {sz_begin_uuid}. Seizure begins on frame {sz_begin_frame}. Need at least {bl_len_frames} frames before for {BL_LEN_S} seconds of baseline. Using part of previous recording\")\n",
    "        bl_end_frame_sz_movie = sz_begin_frame - 1  # 1 to (sz_begin_frame - 1) is second part of baseline\n",
    "        bl_begin_frame_sz_movie = 1\n",
    "        bl_len_rest = bl_len_frames - bl_end_frame_sz_movie  # this many frames to take from previous recording\n",
    "        \n",
    "        # assume movie before sz is present, and the first recording in the ordered-by-filename list \n",
    "        bl_uuid = g.iloc[0].uuid\n",
    "        len_bl_movie = df_sz_movies[(df_sz_movies[\"uuid\"] == bl_uuid) & (df_sz_movies[\"interval_type\"] == \"normal\")].frame_end.max()\n",
    "        bl_end_frame_prev_movie = len_bl_movie\n",
    "        bl_begin_frame_prev_movie = len_bl_movie - bl_len_rest\n",
    "        \n",
    "        bl_entry.append((bl_uuid, int(bl_begin_frame_prev_movie), int(bl_end_frame_prev_movie)))\n",
    "        bl_entry.append((sz_begin_uuid, int(bl_begin_frame_sz_movie), int(bl_end_frame_sz_movie)))\n",
    "    else:\n",
    "        bl_entry.append((bl_uuid, int(bl_begin_frame), int(bl_end_frame)))\n",
    "    # get aftermath\n",
    "    am_uuid = sz_end_uuid\n",
    "    am_begin_frame = sz_end_frame + 1\n",
    "    am_end_frame = sz_end_frame + am_len_frames\n",
    "    # test if aftermath would fall outside last \"normal\" interval in recording:\n",
    "    # TODO: aftermath should be usually either normal or sd_extinction!\n",
    "    len_sz_movie = df_sz_movies[(df_sz_movies[\"uuid\"] == am_uuid) & (df_sz_movies[\"interval_type\"] == \"normal\")].frame_end.max()\n",
    "    if am_end_frame > len_sz_movie:\n",
    "        print(f\"Aftermath: Not enough aftermath available for {sz_end_uuid}. Seizure ends on frame {sz_end_frame}, total {len_sz_movie} frames. Need {am_len_frames} frames after for {AM_LEN_S} seconds of aftermath\")\n",
    "        am_len_sz_movie = len_sz_movie - am_begin_frame + 1  # length of aftermath in sz movie\n",
    "        am_len_next_movie = am_len_frames - am_len_sz_movie  # length of aftermath we need from next movie\n",
    "        # take last movie in group, , take first am_len_next_movie frames, append both intervals\n",
    "        next_movie_uuid = g.iloc[-1].uuid  # assume last movie in group is aftermath movie\n",
    "        am_begin_frame_next_movie = 1\n",
    "        am_end_frame_next_movie = am_len_next_movie\n",
    "        am_entry.append((am_uuid, int(am_begin_frame), int(len_sz_movie)))\n",
    "        am_entry.append((next_movie_uuid, int(am_begin_frame_next_movie), int(am_end_frame_next_movie)))\n",
    "    else:\n",
    "        am_entry.append((am_uuid, int(am_begin_frame), int(am_end_frame)))\n",
    "    sz_intervals_dict[uuid_sz] = {\"sz\": sz_entry, \"sd\": sd_entry, \"baseline\": bl_entry, \"aftermath\": am_entry}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c1b1d",
   "metadata": {},
   "source": [
    "# Create dictionary of locomotion data\n",
    "{uuid1: \\{ \"baseline\": \\[ loco data \\], \"sz\": \\[ loco data \\], \"aftermath\": \\[ loco data \\] \\}, uuid2: {...}, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluolv_dir = fh.open_dir(\"Choose FluLV directory (directory with fluorescence & labview extracted)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6680440",
   "metadata": {},
   "outputs": [],
   "source": [
    "loco_dict = dict()\n",
    "types_list = [\"baseline\", \"sz\", \"sd\", \"aftermath\"]\n",
    "for uuid_sz, intervals in sz_intervals_dict.items():\n",
    "    # open locomotion data for each uuid\n",
    "    # for each type (bl, sz, am), for each fragment of the interval, extract the locomotion data\n",
    "    # dictionary looks like:\n",
    "    # \"<uuid1>\": { \n",
    "    #   \"baseline\": {\n",
    "    #     \"speed\": [[speed_segment1], [speed_segment2], ...],\n",
    "    #     \"running_binary\": [[running_binary_segment1], ...],\n",
    "    #     \"total_distance_mm\": [[total_distance_mm_segment1], ...],\n",
    "    #     \"time_ms\": [[time_ms_segment1], ...],\n",
    "    #     },\n",
    "    #   \"sz\":\n",
    "    #      {...},\n",
    "    #   \"aftermath\":\n",
    "    #      {...},\n",
    "    #   },\n",
    "    # \"<uuid2>\": {...},\n",
    "    # ...\n",
    "    \n",
    "    # add uuid entry\n",
    "    loco_dict[uuid_sz] = dict()\n",
    "    for interval_type in types_list:  # baseline, sz, aftermath\n",
    "        #add baseline, sz, aftermath entry\n",
    "        loco_dict[uuid_sz][interval_type] = dict()\n",
    "        # fill baseline entry with empty arrays\n",
    "        loco_dict[uuid_sz][interval_type][\"speed\"] = []\n",
    "        loco_dict[uuid_sz][interval_type][\"running_binary\"] = []\n",
    "        loco_dict[uuid_sz][interval_type][\"total_distance_mm\"] = []\n",
    "        loco_dict[uuid_sz][interval_type][\"time_ms\"] = []\n",
    "        tuples = intervals[interval_type]\n",
    "        for uuid, begin_frame, end_frame in tuples:\n",
    "            fpath = os.path.join(fluolv_dir, uuid + \"_FluLoco.h5\")\n",
    "            if not os.path.exists(fpath):\n",
    "                raise Error(f\"Error: {fpath} does not exist!\")\n",
    "            with h5py.File(fpath, \"r\") as f:\n",
    "                speed = f[\"speed_scn\"][begin_frame-1:end_frame]  # _scn data are matched to Nikon frames; 0-indexing!\n",
    "                running_binary = f[\"running_scn\"][begin_frame-1:end_frame]#\n",
    "                total_distance_mm = f[\"totdistscn\"][begin_frame-1:end_frame]#[begin_frame-1:end_frame]\n",
    "                time_ms = f[\"tsscn\"][begin_frame-1:end_frame]#[begin_frame-1:end_frame]\n",
    "                loco_dict[uuid_sz][interval_type][\"speed\"].append(speed)\n",
    "                loco_dict[uuid_sz][interval_type][\"running_binary\"].append(running_binary)\n",
    "                loco_dict[uuid_sz][interval_type][\"total_distance_mm\"].append(total_distance_mm)\n",
    "                loco_dict[uuid_sz][interval_type][\"time_ms\"].append(time_ms)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3bf25d",
   "metadata": {},
   "source": [
    "# Create summary statistic for movement, put into dataframe\n",
    "Column names: uuid_sz, baseline_totdist, sz_totdist, aftermath_totdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d9445",
   "metadata": {},
   "source": [
    "### Create uuid_sz - mouse ID relation\n",
    "Useful for grouping per mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id_uuid = ddoc.getIdUuid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f03c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_uuid_sz_id = dict() \n",
    "for uuid_sz in loco_dict.keys():\n",
    "    uuid = uuid_sz.split(\"_\")[0]\n",
    "    mouse_id = df_id_uuid[df_id_uuid[\"uuid\"] == uuid].mouse_id.values[0]\n",
    "    dict_uuid_sz_id[uuid_sz] = mouse_id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1095d35",
   "metadata": {},
   "source": [
    "### Calculate total distance run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04449a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dist_dict = {segment_type: dict() for segment_type in types_list}\n",
    "for uuid in loco_dict.keys():\n",
    "    for interval_type in types_list:\n",
    "        tot_dist_mm = 0.0\n",
    "        for segment in loco_dict[uuid][interval_type][\"total_distance_mm\"]:  # interval might be broken up in multiple recordings/segments\n",
    "            tot_dist_mm += abs(segment[-1] - segment[0])\n",
    "        total_dist_dict[interval_type][uuid] = tot_dist_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_dist_mm = pd.DataFrame.from_dict(total_dist_dict).reset_index().rename(columns={\"index\": \"uuid_sz\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4830a",
   "metadata": {},
   "source": [
    "### Calculate percent of time spent running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_binary_dict = {segment_type: dict() for segment_type in types_list}\n",
    "for uuid in loco_dict.keys():\n",
    "    for interval_type in types_list:\n",
    "        running_frames = 0\n",
    "        all_frames = 0\n",
    "        for segment in loco_dict[uuid][interval_type][\"running_binary\"]:  # interval might be broken up in multiple recordings/segments\n",
    "            running_frames += sum(segment)\n",
    "            all_frames += len(segment)\n",
    "        if all_frames > 0:\n",
    "            running_binary_dict[interval_type][uuid] = float(running_frames)/all_frames\n",
    "        else:\n",
    "            assert running_frames == 0.0\n",
    "            running_binary_dict[interval_type][uuid] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b55309",
   "metadata": {},
   "source": [
    "### Combine sz + sd into single \"seizure\" interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106babdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_dist_mm[\"seizure\"] = df_total_dist_mm[\"sz\"] + df_total_dist_mm[\"sd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02f6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_dist_mm[\"mouse_id\"] = df_total_dist_mm.apply(lambda row: dict_uuid_sz_id[row[\"uuid_sz\"]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc584b",
   "metadata": {},
   "source": [
    "## Reshape dataframe into (uuid_sz, total_distance, interval_type) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23177b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_dist_melted = pd.melt(df_total_dist_mm, id_vars=[\"uuid_sz\", \"mouse_id\"], value_vars=[\"baseline\", \"seizure\", \"aftermath\"], var_name=\"type\", value_name=\"total_dist_mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7183603",
   "metadata": {},
   "source": [
    "## Exploratory plotting\n",
    "Two dataframes are helpful: df_total_dist_mm, df_total_dist_melted. First has columns \"uuid_sz\", \"baseline\", \"seizure\", \"aftermath\" (+ \"sz\", \"sd\", which are combined into \"seizure\"). Second has columns \"uuid_sz\", \"interval_type\", \"total_dist_mm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca895a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "sns.pairplot(data=df_total_dist_melted, y_vars=\"total_dist_mm\", x_vars = \"type\", height=5, aspect=.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3365e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "sns.lineplot(data=df_total_dist_melted, x=\"type\", y=\"total_dist_mm\", hue=\"mouse_id\", size=\"uuid_sz\", sizes=(2,2), errorbar=None, legend=False, markers=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "sns.lineplot(data=df_total_dist_melted[df_total_dist_melted[\"type\"] != \"seizure\"], x=\"type\", y=\"total_dist_mm\", hue=\"mouse_id\", size=\"uuid_sz\", sizes=(2,2), errorbar=None, legend=False)\n",
    "#plt.savefig('D:\\\\Downloads\\\\foo.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af274238",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "sns.pointplot(data=df_total_dist_melted[df_total_dist_melted[\"type\"] != \"seizure\"], x=\"type\", y=\"total_dist_mm\", hue=\"mouse_id\", errorbar=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fba1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
